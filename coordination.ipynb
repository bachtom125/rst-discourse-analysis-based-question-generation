{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_tree_dict(pickle_path):\n",
    "    try: \n",
    "        with open(pickle_path, 'rb') as file:\n",
    "            tree = pickle.load(file)\n",
    "            return tree\n",
    "    except:\n",
    "        print(\"Can't open file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_id(tree_dict):\n",
    "    for key, item in tree_dict.items():\n",
    "        if item['pnode_id'] == -1:\n",
    "            root_id = key\n",
    "    return root_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treelib\n",
    "\n",
    "def visualize_rst_tree(tree_dict, root_id, edu_list, new_relation=False, get_edu_text=False):\n",
    "    rst_tree = treelib.Tree()\n",
    "    relation_key = 'relation' if not new_relation else 'new_relation'\n",
    "    node_list = [root_id]\n",
    "\n",
    "    while node_list:\n",
    "        id = node_list.pop()\n",
    "        node = tree_dict[id]\n",
    "        if (tree_dict.get(node['lnode_id']) is None) and (tree_dict.get(node['rnode_id']) is None):\n",
    "            node_text = \" EDU \" + str(node['edu_span'])\n",
    "            if get_edu_text:\n",
    "                node_text += \": \" + edu_list[node['edu_span'][0] - 1]\n",
    "            rst_tree.create_node(node_text, id, parent=node['pnode_id'])\n",
    "        else:\n",
    "            node_text = node['node_form']\n",
    "\n",
    "            if node['node_form'] == 'NN':\n",
    "                node_text += \"-\" + tree_dict[node['rnode_id']][relation_key]\n",
    "            elif node['node_form'] == 'NS':\n",
    "                node_text += \"-\" + tree_dict[node['rnode_id']][relation_key]\n",
    "            elif node['node_form'] == 'SN':\n",
    "                node_text += \"-\" + tree_dict[node['lnode_id']][relation_key]\n",
    "            else:\n",
    "                raise ValueError(\"Unrecognized N-S form\")\n",
    "            \n",
    "            if rst_tree.get_node(node['pnode_id']) is not None:\n",
    "                rst_tree.create_node(node_text, id, parent=node['pnode_id'])\n",
    "            else:\n",
    "                rst_tree.create_node(node_text, id)\n",
    "                print(\"\\nNo parent at node: \", node_text, '\\n')\n",
    "\n",
    "        if tree_dict.get(node['rnode_id']) is not None:\n",
    "            node_list.append(node['rnode_id'])\n",
    "        if tree_dict.get(node['lnode_id']) is not None:\n",
    "            node_list.append(node['lnode_id'])\n",
    "\n",
    "    return rst_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edus_from_file(edu_path):\n",
    "    \"\"\"Get EDUs from .edu file and return a list of EDUs\n",
    "    \"\"\"\n",
    "    edus = []\n",
    "    try: \n",
    "        with open(edu_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                edus.append(line.rstrip('\\n'))\n",
    "        return edus    \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(edu_list, tree_dict, root_id): # use this when unpickling\n",
    "    \"\"\"Extract text segments from (1 or several EDUs) for relation labeller to read from (and make predictions)\n",
    "\n",
    "    Args:\n",
    "        edu_list: list containing EDUs (list)\n",
    "        tree_dict: dict containing tree (dict)\n",
    "\n",
    "    Return:\n",
    "        Dict containing text of nucleus, satellite, and original relation from StageDP (dict)\n",
    "    \"\"\"\n",
    "\n",
    "    segments = {'pnode_id': [], 'nucleus': [], 'satellite': [], 'original_relation': []} # if multi-nuclear, satellite represent second nucleus\n",
    "    node_list = [root_id]\n",
    "    while node_list:\n",
    "        id = node_list.pop()\n",
    "        node = tree_dict[id]\n",
    "\n",
    "        if (tree_dict.get(node['lnode_id']) is None) and (tree_dict.get(node['rnode_id']) is None): # node is EDU\n",
    "            continue\n",
    "    \n",
    "        left_edu_span = tree_dict[node['lnode_id']]['edu_span'] # tuple: (from, to)\n",
    "        right_edu_span = tree_dict[node['rnode_id']]['edu_span'] # tuple: (from, to)\n",
    "        \n",
    "        # get corresponding text segments\n",
    "        left_segment = \"\"\n",
    "        for edu in range(left_edu_span[0], left_edu_span[1] + 1):\n",
    "            left_segment += edu_list[edu - 1].strip() + ' '\n",
    "\n",
    "        right_segment = \"\"\n",
    "        for edu in range(right_edu_span[0], right_edu_span[1] + 1):\n",
    "            right_segment += edu_list[edu - 1].strip() + ' '\n",
    "\n",
    "        if node['node_form'] == 'NN':\n",
    "            nucleus = left_segment\n",
    "            satellite = right_segment\n",
    "            relation = tree_dict[node['rnode_id']]['relation']\n",
    "        elif node['node_form'] == 'NS':\n",
    "            nucleus = left_segment\n",
    "            satellite = right_segment\n",
    "            relation = tree_dict[node['rnode_id']]['relation']\n",
    "        elif node['node_form'] == 'SN':\n",
    "            nucleus = right_segment\n",
    "            satellite = left_segment\n",
    "            relation = tree_dict[node['lnode_id']]['relation']\n",
    "\n",
    "        segments['nucleus'].append(nucleus)\n",
    "        segments['satellite'].append(satellite)\n",
    "        segments['original_relation'].append(relation)\n",
    "        segments['pnode_id'].append(id)  \n",
    "        \n",
    "        if tree_dict.get(node['lnode_id']) is not None:\n",
    "            node_list.append(node['lnode_id'])\n",
    "        if tree_dict.get(node['rnode_id']) is not None:\n",
    "            node_list.append(node['rnode_id'])\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def add_new_relations_to_tree_dict(tree_dict, new_relations):\n",
    "    \"\"\"Extract text segments from (1 or several EDUs) for relation labeller to read from (and make predictions)\n",
    "\n",
    "    Args:\n",
    "        tree_dict: dict containing tree (dict)\n",
    "        new_relations: df containing parent id and new relations (and other components no considered in this method)\n",
    "\n",
    "    Return:\n",
    "        New modified tree_dict according to new relations identified\n",
    "    \"\"\"\n",
    "    tree_dict_c = copy.deepcopy(tree_dict)\n",
    "    for _, r in new_relations.iterrows():\n",
    "        p_id = r['pnode_id']\n",
    "        rel = r['new_relation']\n",
    "        if tree_dict_c[p_id]['node_form'] == 'NN':\n",
    "            tree_dict_c[tree_dict_c[p_id]['rnode_id']]['new_relation'] = rel\n",
    "            tree_dict_c[tree_dict_c[p_id]['lnode_id']]['new_relation'] = rel\n",
    "        elif tree_dict_c[p_id]['node_form'] == 'NS':\n",
    "            tree_dict_c[tree_dict_c[p_id]['rnode_id']]['new_relation'] = rel\n",
    "        elif tree_dict_c[p_id]['node_form'] == 'SN':\n",
    "            tree_dict_c[tree_dict_c[p_id]['lnode_id']]['new_relation'] = rel\n",
    "        \n",
    "    return tree_dict_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text_file(text_path, text):\n",
    "    \"\"\"Write string in text to text_path. The text is to be analyzed using RST and generated questions from. \n",
    "\n",
    "    Args:\n",
    "        text_path (str): path of file to write to\n",
    "        text (str): text to write to (informational text to extract questions from)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(text_path, 'w') as f:\n",
    "            f.write(text)\n",
    "    except:\n",
    "        print(\"Can't open text file!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to start processing text\n",
    "\n",
    "raw_original_text = \"\"\"Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on the using data and algorithms to enable AI to imitate the way that humans learn, gradually improving its accuracy.\n",
    "How does machine learning work?\n",
    "UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts.\n",
    "\n",
    "A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data.\n",
    "An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model.\n",
    "A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative “evaluate and optimize” process, updating weights autonomously until a threshold of accuracy has been met. \n",
    "\n",
    "Machine learning versus deep learning versus neural networks\n",
    "Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.\n",
    "\n",
    "The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).\n",
    "\n",
    "Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured dat\n",
    "o learn.\n",
    "\n",
    "Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network.\n",
    "\n",
    "Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.\n",
    "\n",
    "Machine learning methods\n",
    "Machine learning models fall into three primary categories.\n",
    "\n",
    "Supervised machine learning            \n",
    "Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naïve bayes, linear regression, logistic regression, random forest, and support vector machine (SVM).\n",
    "\n",
    "Unsupervised machine learning\n",
    "Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method’s ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It’s also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods.\n",
    "\n",
    "Semi-supervised learning \n",
    "Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it’s too costly to label enough data.\"\"\" \n",
    "raw_original_text = raw_original_text.replace(u\"\\u2018\", \"'\").replace(u\"\\u2019\", \"'\").replace(u\"\\u2013\", \"-\").replace(u\"\\u2014\", \"-\").replace(u\"\\u201C\", \"-\").replace(u\"\\u201D\", \"-\") \n",
    "text_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample\"\n",
    "\n",
    "write_to_text_file(text_path, raw_original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_original_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No parent at node:  NS-Elaboration \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to process new data, adjust paths if necessary\n",
    "\n",
    "pickle_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample.pickle\"\n",
    "edu_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample.edus\"\n",
    "\n",
    "tree_dict = get_tree_dict(pickle_path)\n",
    "root_id = get_root_id(tree_dict)\n",
    "edus = get_edus_from_file(edu_path)\n",
    "rst_tree = visualize_rst_tree(tree_dict, root_id, edus, get_edu_text=True)\n",
    "\n",
    "# print(rst_tree.show(stdout=False, sorting=False)) # uncomment to visualize RST tree\n",
    "# print(edus)\n",
    "\n",
    "segments = extract_segments(edus, tree_dict, root_id)\n",
    "df = pd.DataFrame(segments)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembly the whole piece of text from EDUs, to ensure allignment\n",
    "\n",
    "original_text = \"\"\n",
    "for edu in edus:\n",
    "    original_text += edu.strip() + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map \"Comparison\" to \"Join\" since GUM does not contain \"Comparison\"\n",
    "for row in df[df['original_relation'] == 'Comparison'].iterrows():\n",
    "    df.at[row[0], 'original_relation'] = \"Joint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell only once\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"output_train_all_with_additional_reverse_dataset1/checkpoint-45000\"\n",
    "if 'tokenizer' not in locals(): # prevent accidental re-run of cell\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if 'model' not in locals(): # prevent accidental re-run of cell\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_text = ['Attribution', 'Background', 'Cause', 'Condition', 'Contrast',\n",
    "       'Elaboration', 'Enablement', 'Evaluation', 'Explanation', 'Joint',\n",
    "       'Manner-Means', 'Same-Unit', 'Summary', 'Temporal',\n",
    "       'Textual-Organization', 'Topic-Change', 'Topic-Comment']\n",
    "\n",
    "label_shorthand = ['Attr', 'Bckg', 'Cause', 'Cond', 'Contst',\n",
    "       'Elab', 'Enab', 'Eval', 'Expl', 'Joint',\n",
    "       'Man-Mean', 'Same-Un', 'Sum', 'Temp',\n",
    "       'Text-Org', 'Top-Chang', 'Top-Com']\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(label_text)\n",
    "labels = le.transform(df.original_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding <sep> token between nucleus and satellite\n",
    "separation_token = \"[SEP]\"\n",
    "input_sentences = df.apply(lambda x: ''.join([x['nucleus'], separation_token, x['satellite']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge input sentence and labels onto one list (to form dataset object later)\n",
    "data = []\n",
    "for text in input_sentences:\n",
    "    datapoint = {'text': text}\n",
    "    data.append(datapoint)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "import datasets\n",
    "\n",
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "batch_size = 32\n",
    "dataset = datasets.Dataset.from_list(list(data))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        tokens = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        output = model(**tokens)\n",
    "        logits = torch.Tensor.cpu(output.logits)\n",
    "        pred_labels.extend(np.argmax(logits, axis=-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = le.inverse_transform(pred_labels)\n",
    "df['new_relation'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 changed relations out of 90 (0.52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140222578434288</td>\n",
       "      <td>Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on the using data and algorithms to enable AI to imitate the way that humans learn, gradually improving its accuracy.</td>\n",
       "      <td>How does machine learning work? UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140222578434624</td>\n",
       "      <td>How does machine learning work?</td>\n",
       "      <td>UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140222578435128</td>\n",
       "      <td>UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts.</td>\n",
       "      <td>A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140222578435072</td>\n",
       "      <td>A Decision Process:</td>\n",
       "      <td>In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140222578435352</td>\n",
       "      <td>In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data.</td>\n",
       "      <td>An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>140222578434176</td>\n",
       "      <td>An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model.</td>\n",
       "      <td>A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Topic-Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>140222578435464</td>\n",
       "      <td>A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140222578434344</td>\n",
       "      <td>If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.</td>\n",
       "      <td>Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140222578435296</td>\n",
       "      <td>Otherwise, no data is passed along to the next layer of the network by that node.</td>\n",
       "      <td>The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140222578434400</td>\n",
       "      <td>The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.</td>\n",
       "      <td>A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>140222578434904</td>\n",
       "      <td>A neural network that only has three layers is just a basic neural network.</td>\n",
       "      <td>Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140222578434960</td>\n",
       "      <td>Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.</td>\n",
       "      <td>Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140222578388384</td>\n",
       "      <td>Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately.</td>\n",
       "      <td>As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>140222578388272</td>\n",
       "      <td>Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM).</td>\n",
       "      <td>Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Joint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>140222578387936</td>\n",
       "      <td>These algorithms discover hidden patterns or data groupings without the need for human intervention.</td>\n",
       "      <td>This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>140222578388104</td>\n",
       "      <td>Semi-supervised learning</td>\n",
       "      <td>Semi-supervised learning offers a happy medium between supervised and unsupervised learning.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>140222578388720</td>\n",
       "      <td>Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this.</td>\n",
       "      <td>Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Joint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>140222578388832</td>\n",
       "      <td>This method's ability to discover similarities and differences in information</td>\n",
       "      <td>make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition.</td>\n",
       "      <td>Cause</td>\n",
       "      <td>Same-Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>140222578387208</td>\n",
       "      <td>uses machine learning algorithms</td>\n",
       "      <td>to analyze and cluster unlabeled datasets (subsets called clusters).</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Enablement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>140222578387376</td>\n",
       "      <td>Unsupervised machine learning</td>\n",
       "      <td>Unsupervised learning, also known as unsupervised machine learning,</td>\n",
       "      <td>Attribution</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>140222578385248</td>\n",
       "      <td>Unsupervised learning,</td>\n",
       "      <td>also known as unsupervised machine learning,</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>140222578388328</td>\n",
       "      <td>As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately.</td>\n",
       "      <td>This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting.</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>140222578387152</td>\n",
       "      <td>Machine learning methods Machine learning models fall into three primary categories.</td>\n",
       "      <td>Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>140222578387040</td>\n",
       "      <td>is defined by its use of labeled datasets</td>\n",
       "      <td>to train algorithms to classify data or predict outcomes accurately.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Enablement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>140222578384968</td>\n",
       "      <td>to train algorithms</td>\n",
       "      <td>to classify data or predict outcomes accurately.</td>\n",
       "      <td>Enablement</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>140222578387488</td>\n",
       "      <td>Supervised machine learning</td>\n",
       "      <td>Supervised learning, also known as supervised machine learning,</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>140222578386592</td>\n",
       "      <td>Supervised learning,</td>\n",
       "      <td>also known as supervised machine learning,</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>140222578385416</td>\n",
       "      <td>Machine learning methods</td>\n",
       "      <td>Machine learning models fall into three primary categories.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>140222578387992</td>\n",
       "      <td>The -deep- in deep learning is just referring to the number of layers in a neural network.</td>\n",
       "      <td>A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>140222578388664</td>\n",
       "      <td>Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two.</td>\n",
       "      <td>Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>140222578385864</td>\n",
       "      <td>Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence.</td>\n",
       "      <td>However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>140222578386704</td>\n",
       "      <td>and deep learning is a sub-field of neural networks.</td>\n",
       "      <td>The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>140222578387600</td>\n",
       "      <td>The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset.</td>\n",
       "      <td>The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>140222578388216</td>\n",
       "      <td>The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another.</td>\n",
       "      <td>This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>140222578386144</td>\n",
       "      <td>This eliminates some of the human intervention required and enables the use of large amounts of data.</td>\n",
       "      <td>You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>140222578387264</td>\n",
       "      <td>You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).</td>\n",
       "      <td>Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>140222578385304</td>\n",
       "      <td>Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn.</td>\n",
       "      <td>Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>140222578386312</td>\n",
       "      <td>Human experts determine the set of features to understand the differences between data inputs,</td>\n",
       "      <td>usually requiring more structured data to learn.</td>\n",
       "      <td>Cause</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>140222578387768</td>\n",
       "      <td>You can think of deep learning as \"scalable machine learning\"</td>\n",
       "      <td>as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>140222578386368</td>\n",
       "      <td>as Lex Fridman notes in this MIT lecture</td>\n",
       "      <td>(link resides outside ibm.com).</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>140222578386536</td>\n",
       "      <td>Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably,</td>\n",
       "      <td>it's worth noting the nuances between the two.</td>\n",
       "      <td>Same-Unit</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>140222578385920</td>\n",
       "      <td>Machine learning versus deep learning versus neural networks</td>\n",
       "      <td>Since deep learning and machine learning tend to be used interchangeably,</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>140222578386984</td>\n",
       "      <td>The algorithm will repeat this iterative - evaluate and optimize- process,</td>\n",
       "      <td>updating weights autonomously until a threshold of accuracy has been met.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Manner-Means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140222578386760</td>\n",
       "      <td>A Model Optimization Process:</td>\n",
       "      <td>If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate.</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>140222578385584</td>\n",
       "      <td>your algorithm will produce an estimate about a pattern in the data.</td>\n",
       "      <td>Based on some input data, which can be labeled or unlabeled,</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Manner-Means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>140222578360216</td>\n",
       "      <td>that focuses on the using data and algorithms to enable AI to imitate the way that humans learn,</td>\n",
       "      <td>gradually improving its accuracy.</td>\n",
       "      <td>Same-Unit</td>\n",
       "      <td>Manner-Means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>140222578360160</td>\n",
       "      <td>that focuses on the using data and algorithms</td>\n",
       "      <td>to enable AI to imitate the way that humans learn,</td>\n",
       "      <td>Enablement</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pnode_id  \\\n",
       "0   140222578434288   \n",
       "1   140222578434624   \n",
       "2   140222578435128   \n",
       "3   140222578435072   \n",
       "4   140222578435352   \n",
       "6   140222578434176   \n",
       "7   140222578435464   \n",
       "9   140222578434344   \n",
       "10  140222578435296   \n",
       "11  140222578434400   \n",
       "12  140222578434904   \n",
       "13  140222578434960   \n",
       "14  140222578388384   \n",
       "17  140222578388272   \n",
       "19  140222578387936   \n",
       "28  140222578388104   \n",
       "29  140222578388720   \n",
       "31  140222578388832   \n",
       "33  140222578387208   \n",
       "34  140222578387376   \n",
       "35  140222578385248   \n",
       "36  140222578388328   \n",
       "40  140222578387152   \n",
       "42  140222578387040   \n",
       "43  140222578384968   \n",
       "44  140222578387488   \n",
       "45  140222578386592   \n",
       "46  140222578385416   \n",
       "47  140222578387992   \n",
       "54  140222578388664   \n",
       "55  140222578385864   \n",
       "57  140222578386704   \n",
       "58  140222578387600   \n",
       "59  140222578388216   \n",
       "60  140222578386144   \n",
       "61  140222578387264   \n",
       "62  140222578385304   \n",
       "63  140222578386312   \n",
       "65  140222578387768   \n",
       "66  140222578386368   \n",
       "73  140222578386536   \n",
       "74  140222578385920   \n",
       "75  140222578386984   \n",
       "77  140222578386760   \n",
       "84  140222578385584   \n",
       "88  140222578360216   \n",
       "89  140222578360160   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                nucleus  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on the using data and algorithms to enable AI to imitate the way that humans learn, gradually improving its accuracy.    \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      How does machine learning work?    \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts.    \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  A Decision Process:    \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data.    \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model.    \n",
       "7   A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.    \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Otherwise, no data is passed along to the next layer of the network by that node.    \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.    \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A neural network that only has three layers is just a basic neural network.    \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.    \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately.    \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM).    \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                These algorithms discover hidden patterns or data groupings without the need for human intervention.    \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Semi-supervised learning    \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this.    \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       This method's ability to discover similarities and differences in information    \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    uses machine learning algorithms    \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Unsupervised machine learning    \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Unsupervised learning,    \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately.    \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Machine learning methods Machine learning models fall into three primary categories.    \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           is defined by its use of labeled datasets    \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 to train algorithms    \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Supervised machine learning    \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Supervised learning,    \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Machine learning methods    \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The -deep- in deep learning is just referring to the number of layers in a neural network.    \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two.    \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence.    \n",
       "57                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                and deep learning is a sub-field of neural networks.    \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset.    \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another.    \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               This eliminates some of the human intervention required and enables the use of large amounts of data.    \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).    \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn.    \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Human experts determine the set of features to understand the differences between data inputs,    \n",
       "65                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       You can think of deep learning as \"scalable machine learning\"    \n",
       "66                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            as Lex Fridman notes in this MIT lecture    \n",
       "73                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably,    \n",
       "74                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Machine learning versus deep learning versus neural networks    \n",
       "75                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The algorithm will repeat this iterative - evaluate and optimize- process,    \n",
       "77                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A Model Optimization Process:    \n",
       "84                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                your algorithm will produce an estimate about a pattern in the data.    \n",
       "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    that focuses on the using data and algorithms to enable AI to imitate the way that humans learn,    \n",
       "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       that focuses on the using data and algorithms    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      satellite  \\\n",
       "0   How does machine learning work? UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "1                                   UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "2                                                                                                                                                                    A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "3                                                                                                                                                                                        In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                   An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative - evaluate and optimize- process, updating weights autonomously until a threshold of accuracy has been met. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it's worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Semi-supervised learning offers a happy medium between supervised and unsupervised learning.    \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods.    \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition.    \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        to analyze and cluster unlabeled datasets (subsets called clusters).    \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Unsupervised learning, also known as unsupervised machine learning,    \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                also known as unsupervised machine learning,    \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting.    \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately.    \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        to train algorithms to classify data or predict outcomes accurately.    \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            to classify data or predict outcomes accurately.    \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Supervised learning, also known as supervised machine learning,    \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  also known as supervised machine learning,    \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Machine learning models fall into three primary categories.    \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.    \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "57                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            usually requiring more structured data to learn.    \n",
       "65                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).    \n",
       "66                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (link resides outside ibm.com).    \n",
       "73                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              it's worth noting the nuances between the two.    \n",
       "74                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Since deep learning and machine learning tend to be used interchangeably,    \n",
       "75                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   updating weights autonomously until a threshold of accuracy has been met.    \n",
       "77                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate.    \n",
       "84                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Based on some input data, which can be labeled or unlabeled,    \n",
       "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           gradually improving its accuracy.    \n",
       "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          to enable AI to imitate the way that humans learn,    \n",
       "\n",
       "   original_relation          new_relation  \n",
       "0        Elaboration            Background  \n",
       "1              Joint  Textual-Organization  \n",
       "2           Temporal  Textual-Organization  \n",
       "3        Elaboration  Textual-Organization  \n",
       "4              Joint           Elaboration  \n",
       "6              Joint          Topic-Change  \n",
       "7              Joint           Elaboration  \n",
       "9        Elaboration              Contrast  \n",
       "10       Elaboration              Contrast  \n",
       "11       Elaboration              Contrast  \n",
       "12       Elaboration            Background  \n",
       "13       Elaboration            Background  \n",
       "14             Joint           Elaboration  \n",
       "17       Elaboration                 Joint  \n",
       "19       Explanation           Elaboration  \n",
       "28       Elaboration  Textual-Organization  \n",
       "29       Elaboration                 Joint  \n",
       "31             Cause             Same-Unit  \n",
       "33       Elaboration            Enablement  \n",
       "34       Attribution               Summary  \n",
       "35       Elaboration               Summary  \n",
       "36       Explanation           Elaboration  \n",
       "40       Elaboration  Textual-Organization  \n",
       "42       Elaboration            Enablement  \n",
       "43        Enablement           Elaboration  \n",
       "44       Elaboration               Summary  \n",
       "45       Elaboration               Summary  \n",
       "46             Joint  Textual-Organization  \n",
       "47       Elaboration            Background  \n",
       "54       Elaboration  Textual-Organization  \n",
       "55       Elaboration              Contrast  \n",
       "57       Elaboration            Background  \n",
       "58       Elaboration              Contrast  \n",
       "59       Elaboration                 Cause  \n",
       "60       Elaboration                 Cause  \n",
       "61       Elaboration              Contrast  \n",
       "62       Elaboration              Contrast  \n",
       "63             Cause           Elaboration  \n",
       "65       Elaboration           Explanation  \n",
       "66       Elaboration           Explanation  \n",
       "73         Same-Unit            Background  \n",
       "74       Elaboration           Explanation  \n",
       "75       Elaboration          Manner-Means  \n",
       "77         Condition  Textual-Organization  \n",
       "84         Condition          Manner-Means  \n",
       "88         Same-Unit          Manner-Means  \n",
       "89        Enablement           Elaboration  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate porportion of changed labels\n",
    "\n",
    "diff = df.apply(lambda x: x['original_relation'] != x['new_relation'], axis=1)\n",
    "print(diff.sum(), \"changed relations out of\", df.shape[0], '(' + str(round(float(diff.sum()/df.shape[0]), 2)) + ')')\n",
    "df[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No parent at node:  NS-Background \n",
      "\n",
      "NS-Background\n",
      "├── NS-Elaboration\n",
      "│   ├──  EDU (1, 1): Machine learning (ML) is a branch of artificial intelligence (AI) and computer science\n",
      "│   └── NS-Manner-Means\n",
      "│       ├── NS-Elaboration\n",
      "│       │   ├──  EDU (2, 2): that focuses on the using data and algorithms\n",
      "│       │   └──  EDU (3, 3): to enable AI to imitate the way that humans learn,\n",
      "│       └──  EDU (4, 4): gradually improving its accuracy.\n",
      "└── NN-Textual-Organization\n",
      "    ├──  EDU (5, 5): How does machine learning work?\n",
      "    └── NN-Textual-Organization\n",
      "        ├──  EDU (6, 6): UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts.\n",
      "        └── NS-Textual-Organization\n",
      "            ├──  EDU (7, 7): A Decision Process:\n",
      "            └── NN-Elaboration\n",
      "                ├── NS-Elaboration\n",
      "                │   ├── NS-Enablement\n",
      "                │   │   ├──  EDU (8, 8): In general, machine learning algorithms are used\n",
      "                │   │   └──  EDU (9, 9): to make a prediction or classification.\n",
      "                │   └── SN-Manner-Means\n",
      "                │       ├── NS-Elaboration\n",
      "                │       │   ├──  EDU (10, 10): Based on some input data,\n",
      "                │       │   └──  EDU (11, 11): which can be labeled or unlabeled,\n",
      "                │       └──  EDU (12, 12): your algorithm will produce an estimate about a pattern in the data.\n",
      "                └── NN-Textual-Organization\n",
      "                    ├──  EDU (13, 13): An Error Function:\n",
      "                    └── NN-Topic-Change\n",
      "                        ├── NS-Elaboration\n",
      "                        │   ├──  EDU (14, 14): An error function evaluates the prediction of the model.\n",
      "                        │   └── SN-Condition\n",
      "                        │       ├──  EDU (15, 15): If there are known examples,\n",
      "                        │       └── NS-Enablement\n",
      "                        │           ├──  EDU (16, 16): an error function can make a comparison\n",
      "                        │           └──  EDU (17, 17): to assess the accuracy of the model.\n",
      "                        └── NN-Elaboration\n",
      "                            ├── NS-Elaboration\n",
      "                            │   ├── NS-Textual-Organization\n",
      "                            │   │   ├──  EDU (18, 18): A Model Optimization Process:\n",
      "                            │   │   └── SN-Condition\n",
      "                            │   │       ├──  EDU (19, 19): If the model can fit better to the data points in the training set,\n",
      "                            │   │       └── NS-Enablement\n",
      "                            │   │           ├──  EDU (20, 20): then weights are adjusted\n",
      "                            │   │           └──  EDU (21, 21): to reduce the discrepancy between the known example and the model estimate.\n",
      "                            │   └── NS-Elaboration\n",
      "                            │       ├── NS-Manner-Means\n",
      "                            │       │   ├──  EDU (22, 22): The algorithm will repeat this iterative - evaluate and optimize- process,\n",
      "                            │       │   └── NS-Background\n",
      "                            │       │       ├──  EDU (23, 23): updating weights autonomously\n",
      "                            │       │       └──  EDU (24, 24): until a threshold of accuracy has been met.\n",
      "                            │       └── NS-Textual-Organization\n",
      "                            │           ├── NN-Background\n",
      "                            │           │   ├── NS-Explanation\n",
      "                            │           │   │   ├──  EDU (25, 25): Machine learning versus deep learning versus neural networks\n",
      "                            │           │   │   └──  EDU (26, 26): Since deep learning and machine learning tend to be used interchangeably,\n",
      "                            │           │   └──  EDU (27, 27): it's worth noting the nuances between the two.\n",
      "                            │           └── NS-Contrast\n",
      "                            │               ├──  EDU (28, 28): Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence.\n",
      "                            │               └── NN-Joint\n",
      "                            │                   ├──  EDU (29, 29): However, neural networks is actually a sub-field of machine learning,\n",
      "                            │                   └── NS-Background\n",
      "                            │                       ├──  EDU (30, 30): and deep learning is a sub-field of neural networks.\n",
      "                            │                       └── NS-Contrast\n",
      "                            │                           ├── NS-Elaboration\n",
      "                            │                           │   ├──  EDU (31, 31): The way in which deep learning and machine learning differ is in how each algorithm learns.\n",
      "                            │                           │   └── NN-Contrast\n",
      "                            │                           │       ├── NS-Enablement\n",
      "                            │                           │       │   ├── NS-Elaboration\n",
      "                            │                           │       │   │   ├──  EDU (32, 32): \"Deep\" machine learning can use labeled datasets,\n",
      "                            │                           │       │   │   └──  EDU (33, 33): also known as supervised learning,\n",
      "                            │                           │       │   └──  EDU (34, 34): to inform its algorithm,\n",
      "                            │                           │       └──  EDU (35, 35): but it doesn't necessarily require a labeled dataset.\n",
      "                            │                           └── NS-Cause\n",
      "                            │                               ├── NN-Joint\n",
      "                            │                               │   ├──  EDU (36, 36): The deep learning process can ingest unstructured data in its raw form (e.g., text or images),\n",
      "                            │                               │   └── NS-Elaboration\n",
      "                            │                               │       ├──  EDU (37, 37): and it can automatically determine the set of features\n",
      "                            │                               │       └──  EDU (38, 38): which distinguish different categories of data from one another.\n",
      "                            │                               └── NS-Cause\n",
      "                            │                                   ├──  EDU (39, 39): This eliminates some of the human intervention required and enables the use of large amounts of data.\n",
      "                            │                                   └── NS-Contrast\n",
      "                            │                                       ├── NS-Explanation\n",
      "                            │                                       │   ├──  EDU (40, 40): You can think of deep learning as \"scalable machine learning\"\n",
      "                            │                                       │   └── NS-Explanation\n",
      "                            │                                       │       ├──  EDU (41, 41): as Lex Fridman notes in this MIT lecture\n",
      "                            │                                       │       └──  EDU (42, 42): (link resides outside ibm.com).\n",
      "                            │                                       └── NS-Contrast\n",
      "                            │                                           ├──  EDU (43, 43): Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn.\n",
      "                            │                                           └── NS-Elaboration\n",
      "                            │                                               ├── NS-Enablement\n",
      "                            │                                               │   ├──  EDU (44, 44): Human experts determine the set of features\n",
      "                            │                                               │   └──  EDU (45, 45): to understand the differences between data inputs,\n",
      "                            │                                               └──  EDU (46, 46): usually requiring more structured data to learn.\n",
      "                            └── NS-Elaboration\n",
      "                                ├── NS-Elaboration\n",
      "                                │   ├──  EDU (47, 47): Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer.\n",
      "                                │   └──  EDU (48, 48): Each node, or artificial neuron, connects to another and has an associated weight and threshold.\n",
      "                                └── NS-Contrast\n",
      "                                    ├── SN-Condition\n",
      "                                    │   ├──  EDU (49, 49): If the output of any individual node is above the specified threshold value,\n",
      "                                    │   └──  EDU (50, 50): that node is activated, sending data to the next layer of the network.\n",
      "                                    └── NS-Contrast\n",
      "                                        ├──  EDU (51, 51): Otherwise, no data is passed along to the next layer of the network by that node.\n",
      "                                        └── NS-Contrast\n",
      "                                            ├── NS-Background\n",
      "                                            │   ├──  EDU (52, 52): The -deep- in deep learning is just referring to the number of layers in a neural network.\n",
      "                                            │   └── NN-Same-Unit\n",
      "                                            │       ├── NS-Elaboration\n",
      "                                            │       │   ├──  EDU (53, 53): A neural network that consists of more than three layers\n",
      "                                            │       │   └──  EDU (54, 54): -which would be inclusive of the input and the output-\n",
      "                                            │       └──  EDU (55, 55): can be considered a deep learning algorithm or a deep neural network.\n",
      "                                            └── NS-Background\n",
      "                                                ├──  EDU (56, 56): A neural network that only has three layers is just a basic neural network.\n",
      "                                                └── NS-Background\n",
      "                                                    ├──  EDU (57, 57): Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.\n",
      "                                                    └── NN-Elaboration\n",
      "                                                        ├── NS-Textual-Organization\n",
      "                                                        │   ├── NN-Textual-Organization\n",
      "                                                        │   │   ├──  EDU (58, 58): Machine learning methods\n",
      "                                                        │   │   └──  EDU (59, 59): Machine learning models fall into three primary categories.\n",
      "                                                        │   └── NN-Same-Unit\n",
      "                                                        │       ├── NS-Summary\n",
      "                                                        │       │   ├──  EDU (60, 60): Supervised machine learning\n",
      "                                                        │       │   └── NS-Summary\n",
      "                                                        │       │       ├──  EDU (61, 61): Supervised learning,\n",
      "                                                        │       │       └──  EDU (62, 62): also known as supervised machine learning,\n",
      "                                                        │       └── NS-Enablement\n",
      "                                                        │           ├──  EDU (63, 63): is defined by its use of labeled datasets\n",
      "                                                        │           └── NS-Elaboration\n",
      "                                                        │               ├──  EDU (64, 64): to train algorithms\n",
      "                                                        │               └──  EDU (65, 65): to classify data or predict outcomes accurately.\n",
      "                                                        └── NS-Elaboration\n",
      "                                                            ├── NS-Elaboration\n",
      "                                                            │   ├── SN-Background\n",
      "                                                            │   │   ├──  EDU (66, 66): As input data is fed into the model,\n",
      "                                                            │   │   └── NS-Background\n",
      "                                                            │   │       ├──  EDU (67, 67): the model adjusts its weights\n",
      "                                                            │   │       └──  EDU (68, 68): until it has been fitted appropriately.\n",
      "                                                            │   └── NS-Enablement\n",
      "                                                            │       ├──  EDU (69, 69): This occurs as part of the cross validation process\n",
      "                                                            │       └──  EDU (70, 70): to ensure that the model avoids overfitting or underfitting.\n",
      "                                                            └── NS-Elaboration\n",
      "                                                                ├──  EDU (71, 71): Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox.\n",
      "                                                                └── NS-Joint\n",
      "                                                                    ├──  EDU (72, 72): Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM).\n",
      "                                                                    └── NS-Elaboration\n",
      "                                                                        ├── NN-Same-Unit\n",
      "                                                                        │   ├── NS-Summary\n",
      "                                                                        │   │   ├──  EDU (73, 73): Unsupervised machine learning\n",
      "                                                                        │   │   └── NS-Summary\n",
      "                                                                        │   │       ├──  EDU (74, 74): Unsupervised learning,\n",
      "                                                                        │   │       └──  EDU (75, 75): also known as unsupervised machine learning,\n",
      "                                                                        │   └── NS-Enablement\n",
      "                                                                        │       ├──  EDU (76, 76): uses machine learning algorithms\n",
      "                                                                        │       └──  EDU (77, 77): to analyze and cluster unlabeled datasets (subsets called clusters).\n",
      "                                                                        └── NS-Elaboration\n",
      "                                                                            ├──  EDU (78, 78): These algorithms discover hidden patterns or data groupings without the need for human intervention.\n",
      "                                                                            └── NN-Joint\n",
      "                                                                                ├── NN-Same-Unit\n",
      "                                                                                │   ├──  EDU (79, 79): This method's ability to discover similarities and differences in information\n",
      "                                                                                │   └──  EDU (80, 80): make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition.\n",
      "                                                                                └── NS-Elaboration\n",
      "                                                                                    ├── NS-Enablement\n",
      "                                                                                    │   ├──  EDU (81, 81): It's also used\n",
      "                                                                                    │   └──  EDU (82, 82): to reduce the number of features in a model through the process of dimensionality reduction.\n",
      "                                                                                    └── NS-Elaboration\n",
      "                                                                                        ├── NS-Joint\n",
      "                                                                                        │   ├──  EDU (83, 83): Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this.\n",
      "                                                                                        │   └──  EDU (84, 84): Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods.\n",
      "                                                                                        └── NS-Elaboration\n",
      "                                                                                            ├── NS-Textual-Organization\n",
      "                                                                                            │   ├──  EDU (85, 85): Semi-supervised learning\n",
      "                                                                                            │   └──  EDU (86, 86): Semi-supervised learning offers a happy medium between supervised and unsupervised learning.\n",
      "                                                                                            └── NS-Elaboration\n",
      "                                                                                                ├── NS-Enablement\n",
      "                                                                                                │   ├──  EDU (87, 87): During training, it uses a smaller labeled data set\n",
      "                                                                                                │   └──  EDU (88, 88): to guide classification and feature extraction from a larger, unlabeled data set.\n",
      "                                                                                                └── NN-Joint\n",
      "                                                                                                    ├──  EDU (89, 89): Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm.\n",
      "                                                                                                    └── NS-Condition\n",
      "                                                                                                        ├──  EDU (90, 90): It also helps \n",
      "                                                                                                        └──  EDU (91, 91): if it's too costly to label enough data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fix old tree with new relations\n",
    "\n",
    "new_tree_dict = add_new_relations_to_tree_dict(tree_dict, df)\n",
    "new_rst_tree = visualize_rst_tree(new_tree_dict, get_root_id(new_tree_dict), edus, new_relation=True, get_edu_text=True)\n",
    "\n",
    "print(new_rst_tree.show(stdout=False, sorting=False)) # for visualizing rst_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 13 artists>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_cnt = pd.Series(pred_labels).value_counts()\n",
    "indices = pd.Series(label_shorthand).reindex(label_cnt.index, fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.yticks(np.arange(1, max(label_cnt) + 1))\n",
    "plt.bar(indices, label_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>140222578388832</td>\n",
       "      <td>This method's ability to discover similarities and differences in information</td>\n",
       "      <td>make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition.</td>\n",
       "      <td>Cause</td>\n",
       "      <td>Same-Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>140222578386312</td>\n",
       "      <td>Human experts determine the set of features to understand the differences between data inputs,</td>\n",
       "      <td>usually requiring more structured data to learn.</td>\n",
       "      <td>Cause</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pnode_id  \\\n",
       "31  140222578388832   \n",
       "63  140222578386312   \n",
       "\n",
       "                                                                                            nucleus  \\\n",
       "31                   This method's ability to discover similarities and differences in information    \n",
       "63  Human experts determine the set of features to understand the differences between data inputs,    \n",
       "\n",
       "                                                                                                                            satellite  \\\n",
       "31  make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition.    \n",
       "63                                                                                  usually requiring more structured data to learn.    \n",
       "\n",
       "   original_relation new_relation  \n",
       "31             Cause    Same-Unit  \n",
       "63             Cause  Elaboration  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find occurences of a specific relation\n",
    "\n",
    "df[df[\"original_relation\"] == \"Cause\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140222578434344</td>\n",
       "      <td>If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.</td>\n",
       "      <td>Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140222578435296</td>\n",
       "      <td>Otherwise, no data is passed along to the next layer of the network by that node.</td>\n",
       "      <td>The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140222578434400</td>\n",
       "      <td>The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.</td>\n",
       "      <td>A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>140222578385864</td>\n",
       "      <td>Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence.</td>\n",
       "      <td>However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>140222578387600</td>\n",
       "      <td>The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset.</td>\n",
       "      <td>The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>140222578387264</td>\n",
       "      <td>You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).</td>\n",
       "      <td>Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>140222578385304</td>\n",
       "      <td>Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn.</td>\n",
       "      <td>Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>140222578385528</td>\n",
       "      <td>\"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm,</td>\n",
       "      <td>but it doesn't necessarily require a labeled dataset.</td>\n",
       "      <td>Contrast</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pnode_id  \\\n",
       "9   140222578434344   \n",
       "10  140222578435296   \n",
       "11  140222578434400   \n",
       "55  140222578385864   \n",
       "58  140222578387600   \n",
       "61  140222578387264   \n",
       "62  140222578385304   \n",
       "70  140222578385528   \n",
       "\n",
       "                                                                                                                                                                                                                                                                              nucleus  \\\n",
       "9                                                                                                                                If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.    \n",
       "10                                                                                                                                                                                                 Otherwise, no data is passed along to the next layer of the network by that node.    \n",
       "11  The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network.    \n",
       "55                                                                                                                                                                               Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence.    \n",
       "58                   The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset.    \n",
       "61                                                                                                                                            You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).    \n",
       "62                                                                                                                                                                                      Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn.    \n",
       "70                                                                                                                                                                     \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm,    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        satellite  \\\n",
       "9   Otherwise, no data is passed along to the next layer of the network by that node. The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "10                                                                                    The -deep- in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers -which would be inclusive of the input and the output- can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "11                                                                                                                                                                                                                                                                                                                                                                     A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. Machine learning methods Machine learning models fall into three primary categories. Supervised machine learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naive bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised machine learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method's ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It's also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it's too costly to label enough data.    \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.    \n",
       "70                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         but it doesn't necessarily require a labeled dataset.    \n",
       "\n",
       "   original_relation new_relation  \n",
       "9        Elaboration     Contrast  \n",
       "10       Elaboration     Contrast  \n",
       "11       Elaboration     Contrast  \n",
       "55       Elaboration     Contrast  \n",
       "58       Elaboration     Contrast  \n",
       "61       Elaboration     Contrast  \n",
       "62       Elaboration     Contrast  \n",
       "70          Contrast     Contrast  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find occurences of a specific relation\n",
    "\n",
    "df[df[\"new_relation\"] == \"Contrast\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9cdb434748d54424820bf00e66c21d7d-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">happy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">see</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">you.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9cdb434748d54424820bf00e66c21d7d-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9cdb434748d54424820bf00e66c21d7d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9cdb434748d54424820bf00e66c21d7d-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9cdb434748d54424820bf00e66c21d7d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9cdb434748d54424820bf00e66c21d7d-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9cdb434748d54424820bf00e66c21d7d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9cdb434748d54424820bf00e66c21d7d-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9cdb434748d54424820bf00e66c21d7d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9cdb434748d54424820bf00e66c21d7d-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9cdb434748d54424820bf00e66c21d7d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "if 'nlp' not in locals(): # prevent accidental re-run of cell\n",
    "    nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "sent = \"I am happy to see you.\"\n",
    "doc = nlp(sent)\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP - I -  - nsubj\n",
      "VBP - am -  - ROOT\n",
      "JJ - happy -  - acomp\n",
      "TO - to -  - aux\n",
      "VB - see -  - xcomp\n",
      "PRP - you -  - dobj\n",
      ". - . -  - punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.tag_, '-', token.text, '-', token.ent_type_ , '-', token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I - I\n",
      "you - you\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.root, '-', chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverbial clause modifier'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('advcl')\n",
    "# , 'ccomp', 'advcl', 'xcomp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End Helper Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enablement'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "sep = tokenizer.sep_token\n",
    "text_n = \"She used the tool in the garden, \"\n",
    "text_s = \"in order to win.\"\n",
    "text = text_n + sep + text_s\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    output = model(**tokens)\n",
    "    logits = torch.Tensor.cpu(output.logits)\n",
    "    single_pred = int(np.argmax(logits, axis=-1))\n",
    "    \n",
    "le.inverse_transform([single_pred])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_PRONOUNS = ['who', 'that', 'whose', 'which']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "nlp_small = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj(clause, accept_pron=True, accept_expl=False):\n",
    "    \"\"\"Return subject of clause, None of none found\n",
    "\n",
    "    Args:\n",
    "        clause (str): \n",
    "        accept_expl (bool, optional): If take expletive as subject. Defaults to False.\n",
    "        accept_expl (bool, optional): If take pronoun as subject. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: The subject\n",
    "    \"\"\"\n",
    "    doc = nlp(clause)\n",
    "\n",
    "    for token in doc:\n",
    "        if 'nsubj' in token.dep_:\n",
    "            if token.pos_ == \"PRON\" and not accept_pron:\n",
    "                continue\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if chunk.start <= token.i and token.i < chunk.end:\n",
    "                    return chunk.text\n",
    "        if accept_expl:\n",
    "            if 'expl' in token.dep_:\n",
    "                return token.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING: make a more fool proof method of checking relative clause: inputing both source sents and text, and use pos tags to determine, refer to : is_dependent_clause()\n",
    "def check_relative_clause(text):\n",
    "    \"\"\"Return if the text (has to contain only one clause) is a relative clause, \n",
    "    relative clauses can start with \"which\", \"Ving, \"Ved\" (not including adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        text\n",
    "    Return\n",
    "        boolean\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.dep_ == \"nsubj\"):\n",
    "                if (token.text.lower() in RELATIVE_PRONOUNS):\n",
    "                    return 1 # relative clause starting with relative pronouns\n",
    "                break\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.pos_ == \"VERB\") and (token.tag_ in ['VBG', 'VBN']):\n",
    "                # WORKING: Change way to check tense, use tag_ instead of morph\n",
    "                if len(token.morph.get('Tense')) == 0:\n",
    "                    return 0 # not relative clause\n",
    "                if (token.text.endswith('ing')) or (token.tag_ ==  'VBN'):\n",
    "                    return 2 # shortened relative clause (ending with Ving or Ved)\n",
    "            else: \n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundary(sent_doc, text_doc):\n",
    "    \"\"\"Find boundary indices of text_doc in sent_doc (given that text_doc is in sent_doc)\n",
    "\n",
    "    Args:\n",
    "        sent_doc (nlp Doc): \n",
    "        text_doc (nlp Doc): \n",
    "    \"\"\"\n",
    "    start_ind = 0\n",
    "    while start_ind < len(sent_doc):\n",
    "        if text_doc.text not in sent_doc[start_ind:].text:\n",
    "            break\n",
    "        start_ind += 1\n",
    "    start_ind -= 1\n",
    "\n",
    "    end_ind = len(sent_doc)\n",
    "    while end_ind > 0:\n",
    "        if (text_doc.text not in sent_doc[:end_ind].text) or (end_ind <= start_ind):\n",
    "            break\n",
    "        end_ind -= 1\n",
    "    end_ind += 1\n",
    "\n",
    "    return start_ind, end_ind\n",
    "\n",
    "def is_dependent_clause(src_sent, text):\n",
    "    # WORKING: may use this way to check relative clause as well\n",
    "    sent_doc = nlp(src_sent)\n",
    "    text_doc = nlp(text)   \n",
    "\n",
    "    start_ind, end_ind = find_boundary(sent_doc, text_doc)\n",
    "    if start_ind < 0 or end_ind > len(sent_doc):\n",
    "        print(\"\\nText not found in source sentence!\\n\")\n",
    "        return None\n",
    "\n",
    "    for token in sent_doc[start_ind:end_ind]:\n",
    "        if token.dep_ in ['acl', 'advcl', 'xcomp']: # omitted \"ccomp\", put back again if needed\n",
    "            if token.head.i in range(start_ind, end_ind):\n",
    "                return False\n",
    "            return True\n",
    "    return False     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def unshorten_relative_clause(original_sent, clause):\n",
    "    \"\"\"Unshorten relative clause (make sure it's a relative clause before calling this method) ending with Ving or Ved, convert them to which/who + V\n",
    "\n",
    "    Args:\n",
    "        clause (str): relative clause containing Ving or Ved\n",
    "        original_sent (str): original sentence containing that clause\n",
    "    Return:\n",
    "        tuple(str, str): modified clause and source sentence\n",
    "    \"\"\"\n",
    "\n",
    "    clause_doc = nlp(clause)\n",
    "    text_doc = nlp(original_sent)\n",
    "    vb = \"\"\n",
    "\n",
    "    for token in clause_doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.pos_ == \"VERB\") and (token.tag_ in ['VBG', 'VBN']): # finds Ving or Ved\n",
    "                vb = token\n",
    "\n",
    "    for v_token in text_doc:\n",
    "        # find verb in original sentence\n",
    "        if v_token.text == vb.text.strip():\n",
    "            c_i = vb.i\n",
    "            t_i = v_token.i\n",
    "            is_verb = True\n",
    "            while c_i < len(clause_doc) and t_i < len(text_doc):\n",
    "                if clause_doc[c_i].text.strip() != text_doc[t_i].text.strip():\n",
    "                    is_verb = False\n",
    "                    break\n",
    "                c_i += 1\n",
    "                t_i += 1\n",
    "            if is_verb:\n",
    "                break\n",
    "    \n",
    "    pointed_noun = v_token.head\n",
    "    pointed_noun_chunk = None\n",
    "    for chunk in text_doc.noun_chunks:\n",
    "        if chunk.start <= pointed_noun.i and pointed_noun.i < chunk.end:\n",
    "            pointed_noun_chunk = chunk\n",
    "    \n",
    "    if pointed_noun_chunk:\n",
    "        pointed_root_noun = pointed_noun_chunk.root\n",
    "    else:\n",
    "        pointed_root_noun = pointed_noun\n",
    "    \n",
    "    rel_pro = \"which\" \n",
    "    # not a fool-proof way to determine if noun is person\n",
    "    if pointed_root_noun.ent_type_:\n",
    "        if pointed_root_noun.ent_type_ == \"PERSON\":\n",
    "            rel_pro = \"who\"\n",
    "\n",
    "    # check plurality of noun/pronoun and conjugate accordingly\n",
    "    # only applicable for Present Tense, not for past or others\n",
    "    if pointed_root_noun.pos_.startswith(\"NOUN\"): # noun\n",
    "        plurality = pointed_root_noun.tag_ == \"NNS\"\n",
    "    elif \"PRON\" in pointed_root_noun.pos_:  # pronoun\n",
    "        plurality = (pointed_root_noun.lemma_ == \"we\") or (pointed_root_noun.lemma_ == \"you\") or (pointed_root_noun.lemma_ == \"they\") or ((pointed_root_noun.lemma_ == \"I\"))\n",
    "    else: # WORKING: for other cases where relative pronoun does not point to a noun, but a verb or a clause\n",
    "        plurality = False # temporary solution\n",
    "\n",
    "    if not plurality:\n",
    "        if vb.tag_ == 'VBG':\n",
    "            conj_vb = p.plural_noun(vb.lemma_) # get singular conjugation (plural_noun() method works with verbs too)\n",
    "        else:\n",
    "            if pointed_root_noun.text.strip() == \"I\":\n",
    "                aux = 'am'\n",
    "            else:\n",
    "                aux = 'is'\n",
    "            conj_vb = aux + ' ' + vb.text\n",
    "    else:\n",
    "        if vb.tag_ == 'VGB':\n",
    "            conj_vb = p.plural_verb(vb.lemma_) # get plural conjugation\n",
    "        else:\n",
    "            if pointed_root_noun.text.strip() == \"I\":\n",
    "                aux = 'am'\n",
    "            else:\n",
    "                aux = 'are'\n",
    "            conj_vb = aux + ' ' + vb.text\n",
    "\n",
    "    fixed_clause = clause.replace(vb.text, rel_pro + ' ' +  conj_vb, 1)# replace only the first occurence of the verb\n",
    "    fixed_sent = original_sent.replace(clause.strip(), fixed_clause.strip(), 1)\n",
    "    return  (fixed_sent, fixed_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I saw Tom which walks at midnight', 'which walks at midnight')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshorten_relative_clause(\"I saw Tom walking at midnight\", \"walking at midnight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING: Need to handle all types of shortened relative clauses, for now, only Ving and Ved is covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_clause(text, count_relative_clause=True):\n",
    "    \"\"\"Check if input text is one clause or multiple.\n",
    "        NOTE: If not multiple clause, the method returns true, so does not account for the case of not a full clause, just check whether multiple clauses or not, cause a EDU is usually at least a clause semantically. \n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # check how many subjects\n",
    "    has_subj = False\n",
    "    for token in doc:\n",
    "        if \"nsubj\" in token.dep_:\n",
    "            if not count_relative_clause:\n",
    "                if token.text.lower() in ['who', 'whom', 'whose', 'which', 'that']:\n",
    "                    continue\n",
    "                if token.head.dep_ in ['relcl', 'acl', 'ccomp']:\n",
    "                    continue\n",
    "            if has_subj:\n",
    "                return False\n",
    "            else:\n",
    "                has_subj = True\n",
    "    return True # not return has_subj, so that even no subject will be 1 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_aux(sentence):\n",
    "    \"\"\"Check if sentence has auxiliary verb.\n",
    "    Input one sentence only.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if \"AUX\" in token.pos_:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_shorthand = {\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"had\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"n't\": \"not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_aux_to_beginning(sentence):\n",
    "    \"\"\"Move auxiliary verb to the beginning of sentence (to form question).\n",
    "    Input one sentence only. Make sure it has aux verb. Make sure sentence starts with subject.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    aux = \"\"\n",
    "    for token in doc:\n",
    "        if \"AUX\" in token.pos_:\n",
    "            aux = token.text\n",
    "            break\n",
    "    assert len(aux)\n",
    "\n",
    "    if aux.strip() in auxiliary_shorthand:\n",
    "        new_aux = auxiliary_shorthand[aux]\n",
    "        new_sent = new_aux + ' ' + sentence.strip().replace(aux, '', 1).replace(sentence[0], sentence[0].lower(), 1)\n",
    "    else:\n",
    "        new_sent = aux + ' ' + sentence.strip().replace(aux, '', 1).replace(sentence[0], sentence[0].lower(), 1)\n",
    "\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can the person on the right  be her father, I can do it if not.\n"
     ]
    }
   ],
   "source": [
    "# move aux test run\n",
    "\n",
    "txt = \"The person on the right can be her father, I can do it if not.\"\n",
    "if has_aux(txt):\n",
    "    print(move_aux_to_beginning(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_verb(sentence):\n",
    "    \"\"\"Check if sentence has normal verb.\n",
    "    Input one sentence only.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if \"VERB\" in token.pos_:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_and_replace_aux_for_verb(sentence):\n",
    "    \"\"\"Put appropriate aux at beginnging of clause \n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    main_verb = None\n",
    "\n",
    "    for token in doc:\n",
    "        if \"VERB\" in token.pos_:\n",
    "            main_verb = token\n",
    "            break\n",
    "            \n",
    "    if not main_verb:\n",
    "        print(\"\\nCan't find main verb in\", sentence, '!\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    # check plurality\n",
    "    pointed_noun = main_verb.head\n",
    "    if pointed_noun.pos_.startswith(\"NOUN\"): # noun\n",
    "        plurality = pointed_noun.tag_ == \"NNS\"\n",
    "    elif pointed_noun.pos_.startswith(\"PRP\"):  # pronoun\n",
    "        plurality = (pointed_noun.lemma_ == \"we\") or (pointed_noun.lemma_ == \"you\") or (pointed_noun.lemma_ == \"they\")\n",
    "    else: # WORKING: for other cases where relative pronoun does not point to a noun, but a verb or a clause\n",
    "        plurality = True # temporary solution\n",
    "\n",
    "    # check tense\n",
    "    tense = \"present\" if main_verb.tag_ in ['VBZ', 'VBP'] else 'past'\n",
    "    # get aux\n",
    "    aux = {\n",
    "      \"present\": \"do\" if plurality else \"does\",\n",
    "      \"past\": \"did\",\n",
    "    }.get(tense)\n",
    "\n",
    "    # replace appropriate auxilary\n",
    "    new_sent = sentence.replace(main_verb.text, main_verb.lemma_, 1)\n",
    "    new_sent = aux + ' ' + new_sent\n",
    "\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did he hit down.\n"
     ]
    }
   ],
   "source": [
    "# move verb test run\n",
    "\n",
    "txt = \"he hit down.\"\n",
    "if has_verb(txt):\n",
    "    print(choose_and_replace_aux_for_verb(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ending_special_chars(sentence):\n",
    "    \"\"\"Remove ending non-word characters of a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be stripped\n",
    "\n",
    "    Returns:\n",
    "        str: stripped sentence \n",
    "    \"\"\"\n",
    "    sen_len = len(sentence)\n",
    "    for i in range(sen_len - 1, -1, -1):\n",
    "        char = sentence[i]\n",
    "\n",
    "        # check if the character is a punctuation mark\n",
    "        if char.isalnum():\n",
    "            return sentence\n",
    "        else:\n",
    "            sentence = sentence[:i]\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_special_chars(sentence):\n",
    "    \"\"\"Remove leading non-word characters of a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be stripped\n",
    "\n",
    "    Returns:\n",
    "        str: stripped sentence \n",
    "    \"\"\"\n",
    "\n",
    "    start_ind = 0\n",
    "    for i in range(0, len(sentence)):\n",
    "        char = sentence[i]\n",
    "        # check if the character is a punctuation mark\n",
    "        if char.isalnum():\n",
    "            break\n",
    "        else:\n",
    "            start_ind = i + 1\n",
    "\n",
    "    return sentence[start_ind: ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentence\n",
    "\n",
    "    Args:\n",
    "        text (str): text to be plited\n",
    "    Return: \n",
    "        list[str]: spit text\n",
    "    \"\"\"\n",
    "    sents = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\", text)\n",
    "    sents = [sent for sent in sents if len(sent.strip())]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paras(text, deli):\n",
    "    paras = text.split(deli)\n",
    "    paras = [para.strip() for para in paras if len(para.strip()) != 0]\n",
    "    return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_id(paras, text):\n",
    "    \"\"\"Find paragraph index of text\n",
    "\n",
    "    Args:\n",
    "        paras (list[str]): list of paragraphs\n",
    "        text (str): text to find\n",
    "    Return:\n",
    "        int: para id, -1 if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for p_i in range(len(paras)):\n",
    "        if paras[p_i].find(text.strip()) != -1:\n",
    "            return p_i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_source_sents(sents, text, span=2):\n",
    "    \"\"\"Find the sentences of which the text is a part. \n",
    "\n",
    "    Args:\n",
    "        sents (str): \n",
    "        text (str): \n",
    "        span (int): span of sentences to the left to return\n",
    "    \"\"\"\n",
    "    start_ind = 0\n",
    "    while start_ind < len(sents):\n",
    "        if text not in ''.join(sents[start_ind:]):\n",
    "            break\n",
    "        start_ind += 1\n",
    "    start_ind -= 1\n",
    "\n",
    "    end_ind = len(sents) # exclusive\n",
    "    while end_ind > 0:\n",
    "        if (text not in ''.join(sents[:end_ind])) or (end_ind <= start_ind):\n",
    "            break\n",
    "        end_ind -= 1\n",
    "    end_ind += 1\n",
    "\n",
    "    if (start_ind < 0) or (end_ind > len(sents)):\n",
    "        print(f\"\\nCan't find source sentences of {text}\\n\")\n",
    "        return None\n",
    "    \n",
    "    src_sents = ''.join(sents[max(start_ind - span, 0):end_ind])\n",
    "    return src_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subject_to_relative_clause(original_sent, clause):\n",
    "    \"\"\"Find and Prepend (with modifications) the subject of relative clause that does not contain one\n",
    "\n",
    "    Args:\n",
    "        original_sent (str): sentence from which the clause is extracted\n",
    "        clause (str): clause for which to find subject\n",
    "    Return:\n",
    "        str: subject\n",
    "    \"\"\"\n",
    "    doc = nlp(original_sent)\n",
    "    subj = \"\"\n",
    "    clause_start_ind = original_sent.find(clause)\n",
    "    for token in doc:\n",
    "        if (len(subj)):\n",
    "            break\n",
    "        if (token.dep_ in ['relcl', 'acl']) and (token.idx >= clause_start_ind) and (token.idx < (clause_start_ind + len(clause))): # relative clause is noun modifier\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if token.head.i >= chunk.start and token.head.i < chunk.end:\n",
    "                    subj = chunk.text\n",
    "                    break\n",
    "        \n",
    "        # WORKING: relative clause is verb/adverb/adjective modifier, not sure if it's necessary tho\n",
    "        # 'cause adverbial clauses are often in relations that do not require unshortening of clause\n",
    "        if (token.dep_ in ['advcl', 'ccomp']) and (token.idx >= clause_start_ind) and (token.idx < (clause_start_ind + len(clause))): \n",
    "            print(\"\\nFound Adverbial Clause\\n\")\n",
    "            return None\n",
    "            # for chunk in doc.noun_chunks:\n",
    "            #     if token.head.i >= chunk.start and token.head.i < chunk.end:\n",
    "            #         subj = chunk.text\n",
    "            #         break\n",
    "                    \n",
    "    if not len(subj): # not found subject\n",
    "        print(\"\\nCan't find subject of\", original_sent, \"!\\n\")\n",
    "        return None         \n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"nsubj\") and (token.text.lower() in RELATIVE_PRONOUNS):\n",
    "            new_clause = clause.replace(token.text, subj) # contains more nuances (where -> in + N, which -> N, who -> N)\n",
    "            new_sent = original_sent.replace(clause.strip(), new_clause.strip(), 1)\n",
    "            return new_sent, new_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found Adverbial Clause\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add subject test run\n",
    "txt =\"For instance, on the MNLI task, the BERT_base accuracy improves by 1.0% when that trains on 1M steps (128,000 words batch size)\"\n",
    "txt_c = \"that trains on 1M steps (128,000 words batch size)\"\n",
    "add_subject_to_relative_clause(txt, txt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_conjunction(original_sent, text):\n",
    "    \"\"\"Remove leading conjunctions from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PUNCT', 'SYM']:\n",
    "            continue\n",
    "        if \"CONJ\" not in token.pos_:\n",
    "            return (original_sent, text)\n",
    "        conj = token.text\n",
    "        break\n",
    "\n",
    "    new_text = text.replace(conj.strip(), '', 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "\n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_adverb(original_sent, text):\n",
    "    \"\"\"Remove leading adverb from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PUNCT', 'SYM']:\n",
    "            continue\n",
    "        if token.pos_ != 'ADV':\n",
    "            return (original_sent, text)\n",
    "        adv = token.text\n",
    "        break\n",
    "\n",
    "    new_text = text.replace(adv.strip(), '', 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "\n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOURSE_MARKERS = [\n",
    "  'accordingly', 'additionally', 'afterward', 'also',\n",
    "  'although', 'as a final point', 'as a result', 'assuming that', 'because', 'this is because'\n",
    "  'besides', 'but also', 'compared to', 'consequently', 'conversely', 'despite',\n",
    "  'even though', 'finally', 'first', 'firstly', 'for example', 'for instance',\n",
    "  'for the purpose of', 'furthermore', 'hence', 'however', 'if', 'importantly',\n",
    "  'in addition', 'in case', 'in conclusion', 'in contrast', 'by contrast', 'in fact',\n",
    "  'in order to', 'in other words', 'in the event that', 'in the same way',\n",
    "  'indeed', 'just as', 'lastly', 'likewise', 'moreover', 'namely',\n",
    "  'nevertheless', 'next', 'nonetheless', 'not only', 'of course', 'on condition that',\n",
    "  'on the contrary', 'on the one hand', 'on the other hand', 'otherwise', 'plus', 'previously',\n",
    "  'provided that', 'second', 'secondly', 'similarly', 'similarly to', 'since',\n",
    "  'so', 'so that', 'specifically', 'subsequently', 'such as', 'that is to say', 'that is'\n",
    "  'then', 'therefore', 'third', 'thirdly', 'thus', 'to conclude', 'to illustrate',\n",
    "  'to put it differently', 'to sum up', 'ultimately', 'undoubtedly', 'unless',\n",
    "  'while', 'with the aim of', 'yet', 'then', 'and then'\n",
    "  'as a consequence', 'as a result',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_leading_discourse_marker(original_sent, text):\n",
    "    \"\"\"Remove leading discourse markers from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    discourse_marker = None\n",
    "    min_pos = len(text)\n",
    "    for dm in DISCOURSE_MARKERS:\n",
    "        find_result = text.lower().find(dm)\n",
    "        if find_result > -1:\n",
    "            if find_result < min_pos:\n",
    "                min_pos = find_result\n",
    "                discourse_marker = dm\n",
    "            if find_result == min_pos and len(dm) > len(discourse_marker):\n",
    "                discourse_marker = dm\n",
    "    \n",
    "    # check if found marker stand at the beginning of text\n",
    "        \n",
    "    if discourse_marker is not None:\n",
    "        for i in range(0, min_pos):\n",
    "            if text[i].isalnum() or text[min_pos + len(discourse_marker)].isalnum():\n",
    "                discourse_marker = None\n",
    "                break\n",
    "            \n",
    "    if not discourse_marker:\n",
    "        return (original_sent, text)\n",
    "\n",
    "    pattern = re.compile(discourse_marker, re.IGNORECASE)\n",
    "\n",
    "    new_text = pattern.sub(\"\", text, 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "    \n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be integrated\n",
    "\n",
    "def replace_substr(text, substring, start_ind, end_ind):\n",
    "  \"\"\"Replace part of text with specified index [start_ind, end_ind) with substring\n",
    "  \"\"\"\n",
    "  try:\n",
    "    assert(len(substring)  == end_ind - start_ind)\n",
    "  except:\n",
    "    print('Text:', text, '--', sep='')\n",
    "    print('Substring:', substring, '--', sep='')\n",
    "\n",
    "  text_l = list(text)\n",
    "  text_l[start_ind:end_ind] = list(substring)\n",
    "\n",
    "  return ''.join(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_ref(index, clusters):\n",
    "    \"\"\"Check if current index is in one of the references\n",
    "    \n",
    "    Args:\n",
    "        index (int): index to check\n",
    "        clusters (list(list(tuple))): list of cluster, each cluster containing a list of tuple correponding to indices of the references\n",
    "    Return:\n",
    "        tuple (verdict, (start, end), (ref_token_start, ref_token_end)): -1 both index if not found, ref_token is token to relace\n",
    "    \"\"\"\n",
    "    for cluster in clusters:\n",
    "        for token in cluster:\n",
    "            if cluster.index(token) == 0:\n",
    "                continue\n",
    "            if index >= token[0] and index < token[1]:\n",
    "                ref_token = (cluster[0][0], cluster[0][1])\n",
    "                return True, token, ref_token\n",
    "            \n",
    "    return False, (-1, -1), (-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_clause_type(clause):\n",
    "    \"\"\"Check which type of relative clause \"clause\" is: \n",
    "    - which + V + clause (present subject is sufficient for being clause)\n",
    "    - which + V + (not clause)\n",
    "\n",
    "    Args:\n",
    "        sent (str): \n",
    "        clause (str): \n",
    "    Return: 0 or 1, -1 if not relative clause expected (not start with which + V), then it could be an adverbial clause\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(clause.strip())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        token = doc[i]\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" not in token.pos_: \n",
    "                return -1\n",
    "            else:\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    i += 1 \n",
    "    while i < len(doc):\n",
    "        token = doc[i]\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"VERB\" not in token.pos_ and \"AUX\" not in token.pos_: \n",
    "                return -1        \n",
    "            else:\n",
    "                break\n",
    "        i += 1\n",
    "    \n",
    "    # if reach here, is expected relative clause type (which + V)\n",
    "    i += 1\n",
    "    t_i = i # use to this to check subject and not modify i\n",
    "    while t_i < len(doc):\n",
    "        token = doc[t_i]\n",
    "        if 'nsubj' in token.dep_:\n",
    "            return 0\n",
    "        t_i += 1\n",
    "\n",
    "    return 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2024 20:55:22 - INFO - \t missing_keys: []\n",
      "05/19/2024 20:55:22 - INFO - \t unexpected_keys: []\n",
      "05/19/2024 20:55:22 - INFO - \t mismatched_keys: []\n",
      "05/19/2024 20:55:22 - INFO - \t error_msgs: []\n",
      "05/19/2024 20:55:22 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n"
     ]
    }
   ],
   "source": [
    "# to be integrated\n",
    "from fastcoref import FCoref, LingMessCoref\n",
    "if 'coref_resolver' not in locals(): # prevent accidental re-run of cell\n",
    "    coref_resolver = LingMessCoref(device='cuda:0')\n",
    "\n",
    "def resolve_coreference(original_sent, text):\n",
    "    \"\"\"Perfrom coreference resolution and replace corresponding text.\n",
    "\n",
    "    Args:\n",
    "        original_sent (str): Sentence the text was derived froms\n",
    "        text (str): Target text\n",
    "    \"\"\"\n",
    "\n",
    "    text_ind = original_sent.find(text) # starting index of text in original text\n",
    "    coref_preds = coref_resolver.predict(texts=[original_sent])\n",
    "    coref_clusters = coref_preds[0].get_clusters(as_strings=False)\n",
    "    new_sent = []\n",
    "    new_text = []\n",
    "\n",
    "    # interate string left to right while appending current char to a new list\n",
    "    # if current index in one of the token in one of the clusters, add the replacement to the list, keep the text intact, to know what index are at\n",
    "    i = 0\n",
    "\n",
    "    # if referred word is a verb, use have to notice and discard the sentence.\n",
    "    while i < len(original_sent):\n",
    "        find_result = is_in_ref(i, coref_clusters)\n",
    "        if find_result[0]:\n",
    "            token = find_result[1]\n",
    "            token_ref = find_result[2]\n",
    "            new_sent.append(original_sent[token_ref[0]:token_ref[1]])\n",
    "            if (i >= text_ind and i < text_ind + len(text)):\n",
    "                if (text_ind <= token[0] and token[1] <= text_ind + len(text)):\n",
    "                    new_text.append(original_sent[token_ref[0]:token_ref[1]])\n",
    "                else:\n",
    "                    new_text.append(original_sent[i:text_ind + len(text)])\n",
    "            i = token[1]\n",
    "        else:\n",
    "            new_sent.append(original_sent[i])\n",
    "            if i >= text_ind and i < text_ind + len(text):\n",
    "                new_text.append(original_sent[i])\n",
    "            i += 1\n",
    "\n",
    "    return ''.join(new_sent), ''.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2024 20:55:22 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  1.44 examples/s]\n",
      "05/19/2024 20:55:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:04<00:00,  4.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CorefResult(text=\"Transformers process input sequences in parallel, ...\", clusters=[['Transformers', 'them']])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coref test run    \n",
    "txt = \"Transformers process input sequences in parallel, making the them highly efficient for training and inference\"\n",
    "# sents = split_into_sentences(original_text)\n",
    "# src = find_source_sents(sents, txt, 5)\n",
    "# resolve_coreference(src, txt)\n",
    "coref_preds = coref_resolver.predict(texts=[txt])\n",
    "coref_clusters = coref_preds[0].get_clusters(as_strings=False)\n",
    "coref_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(original_text, text, retain_dm=False, retain_conj=False, retain_adv=False, add_subject_to_rel_clause=False):\n",
    "    \"\"\"Tranform raw text into a full clause to be fed to the question generation pipeline\n",
    "\n",
    "    Args:\n",
    "        text (str): raw text\n",
    "    Return:\n",
    "        (str): full clause from text\n",
    "    \"\"\"\n",
    "    sents = split_into_sentences(original_text)\n",
    "\n",
    "    # coreferen ce resolution\n",
    "    src_3_sents = find_source_sents(sents, text, 3)\n",
    "    src_3_sents, text = resolve_coreference(src_3_sents, text)\n",
    "    src_sent = find_source_sents(split_into_sentences(src_3_sents), text, 0)\n",
    "\n",
    "    # removal of irrelavent components\n",
    "    if not retain_dm:\n",
    "        src_sent, text = remove_leading_discourse_marker(src_sent, text)    \n",
    "    if not retain_conj:\n",
    "        src_sent, text = remove_leading_conjunction(src_sent, text)\n",
    "    if not retain_adv: \n",
    "        src_sent, text = remove_leading_adverb(src_sent, text)\n",
    "    src_sent = remove_leading_special_chars(src_sent)\n",
    "    text = remove_leading_special_chars(text)\n",
    "    # src_3_sents = remove_ending_special_chars(src_3_sents)\n",
    "    # text = remove_ending_special_chars(text)\n",
    "\n",
    "    # handle single relative clause\n",
    "    if is_one_clause(text, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(text)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            if cl_type == 2:\n",
    "                print(\"\\nText here: \", src_sent, text)\n",
    "                src_sent, text = unshorten_relative_clause(src_sent, text)\n",
    "            if add_subject_to_rel_clause:\n",
    "                # WORKING: temporary solution before fixing add_subject_to_relative_clause()\n",
    "                if add_subject_to_relative_clause(src_sent, text):\n",
    "                    src_sent, text = add_subject_to_relative_clause(src_sent, text)\n",
    "\n",
    "    return src_sent, text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Training: Transformer models are trained using supervised learning',\n",
       " 'using which is supervised learning.')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshorten_relative_clause(\"Training: Transformer models are trained using supervised learning\", \"using supervised learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She was talking to me, a person which is tackled.',\n",
       " ' a person which is tackled.')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unshorten_relative_clause(\"She was talking to me, a person tackled.\", \" a person tackled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2024 20:55:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.78 examples/s]\n",
      "05/19/2024 20:55:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('She was talking to me, a person tackled.', 'a person tackled.')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline(\"She was talking to me, a person tackled.\", \" a person tackled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING: \n",
    "- Handle non-clause (maybe just keep all, discard \"which + V\" maybe)\n",
    "- Handle missing information (two EDUs still don't make a sentence) -> maybe segment longer texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "output_path = './questions_machine_learning'\n",
    "sents = split_into_sentences(original_text) # text split into sentences\n",
    "paras = split_into_paras(raw_original_text, deli='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cause_question_type_0(nucleus, satellite): # WORKING: nucleus cause satellite (but now model interpret both directions, needs fixing)\n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting:exactly the same as type_1\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def cause_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which caused the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def cause_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(satellite):\n",
    "        new_sate = move_aux_to_beginning(satellite)\n",
    "    else: \n",
    "        new_sate = choose_and_replace_aux_for_verb(satellite)\n",
    "    question = \"Why \" + new_sate.strip() + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "                                             \n",
    "def generate_cause_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    if is_one_clause(satellite, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(satellite)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(satellite)\n",
    "            if rel_type == 0:\n",
    "                return cause_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return cause_question_type_1(nucleus, satellite)\n",
    "    else:\n",
    "        return (\"\", \"\")\n",
    "    return cause_question_type_2(nucleus, satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast relation: ask what's different between two subjects.\n",
    "# retain discourse markers\n",
    "    \n",
    "def make_contrast_question_with_two_clauses(nucleus, satellite):\n",
    "    n_subj = get_subj(nucleus)\n",
    "    s_subj = get_subj(satellite)\n",
    "   \n",
    "    if (n_subj is None) or (s_subj is None):\n",
    "        print(\"\\nCan't find subject!\\n\")\n",
    "        return (\"\", \"\")\n",
    "     \n",
    "    if n_subj.strip().lower() == s_subj.strip().lower():\n",
    "        print(\"\\nSame subjects for nucleus and satellite!\\n\")\n",
    "        return (\"\", \"\")\n",
    "    \n",
    "    question = \"What is the difference between \" + n_subj + \" and \" + s_subj + '?'\n",
    "    answer = nucleus.strip() + ' ' + satellite.strip()\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_contrast_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(nucleus, count_relative_clause=False) and is_one_clause(satellite, count_relative_clause=False):\n",
    "        return make_contrast_question_with_two_clauses(nucleus, satellite)\n",
    "    return (\"\", \"\") # more than 1 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition relation\n",
    "\n",
    "def condition_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting:exactly the same as type_1\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What condition\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def condition_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which conditiond the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What condition\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def condition_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(satellite):\n",
    "        new_sate = move_aux_to_beginning(satellite)\n",
    "    else: \n",
    "        new_sate = choose_and_replace_aux_for_verb(satellite)\n",
    "    question = \"In what condition \" + new_sate.strip() + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "                                             \n",
    "def generate_condition_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(satellite, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(satellite)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(satellite)\n",
    "            if rel_type == 0:\n",
    "                return condition_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return condition_question_type_1(nucleus, satellite)\n",
    "        else: # 1 clause, not relative clause \n",
    "            return condition_question_type_2(nucleus, satellite)\n",
    "    else:\n",
    "        return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enablement relation\n",
    "# difference to manner-means: enablement encapsulate manner-means, as all means can \"enable\" the goal,\n",
    "# but enablement also contains situational aid, an event lead (may not intentionally) to another event\n",
    "    \n",
    "# enablement relation\n",
    "\n",
    "def enablement_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting: exactly the same as type_1\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def enablement_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which enablementd the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def enablement_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(nucleus):\n",
    "        new_nuc = move_aux_to_beginning(nucleus)\n",
    "    else: \n",
    "        new_nuc = choose_and_replace_aux_for_verb(nucleus)\n",
    "    question = \"How \" + new_nuc.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def enablement_question_type_3(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 2: satellite (result) is: relative clause but not start with relative pronoun (most probably adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    question = \"What can be done \" + nucleus.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_enablement_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "\n",
    "    if is_one_clause(nucleus, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(nucleus)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(nucleus)\n",
    "            if rel_type == 0:\n",
    "                return enablement_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return enablement_question_type_1(nucleus, satellite)\n",
    "        else:\n",
    "            if is_dependent_clause(nucleus_pair[0], nucleus):\n",
    "                return enablement_question_type_3(nucleus, satellite)\n",
    "            return enablement_question_type_2(nucleus, satellite)\n",
    "    return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manner-Means relation\n",
    "    \n",
    "# manner-means relation\n",
    "# difference to manner-means: manner-means encapsulate manner-means, as all means can \"enable\" the goal,\n",
    "# but manner-means also contains situational aid, an event lead (may not intentionally) to another event\n",
    "    \n",
    "# manner-means relation\n",
    "\n",
    "def means_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting: exactly the same as type_1\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What method \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def means_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which caused the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What method \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def means_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(nucleus):\n",
    "        new_nuc = move_aux_to_beginning(nucleus)\n",
    "    else: \n",
    "        new_nuc = choose_and_replace_aux_for_verb(nucleus)\n",
    "    question = \"By what method \" + new_nuc.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def means_question_type_3(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 2: satellite (result) is: relative clause but not start with relative pronoun (most probably adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    question = \"What strategy can be employed \" + nucleus.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_means_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(nucleus, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(nucleus)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(nucleus)\n",
    "            if rel_type == 0:\n",
    "                return means_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return means_question_type_1(nucleus, satellite)\n",
    "        else:\n",
    "            if is_dependent_clause(nucleus_pair[0], nucleus):\n",
    "                return means_question_type_3(nucleus, satellite)\n",
    "            return means_question_type_2(nucleus, satellite)\n",
    "    return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WORKING: for questions based on BACKGROUND relation, haven't adapted to new preprocessing pipeline, may not be suitable for question generation\n",
    "\n",
    "# def make_background_question_with_two_clauses(nucleus, satellite): \n",
    "#     question = \"Under what circumstance that \" + nucleus.strip() + '?'\n",
    "#     answer = satellite\n",
    "\n",
    "#     return (question, answer)\n",
    "\n",
    "# def generate_background_question(original_text, nucleus, satellite):\n",
    "#     nucleus = preprocessing_pipeline(original_text, nucleus, retain_dm=False, retain_conj=True, retain_adv=True) # NOTE: may not want to retain dm here, 'cause need only the dm between nuc and sate\n",
    "#     satellite = preprocessing_pipeline(original_text, satellite, retain_dm=False, retain_conj=True, retain_adv=True)\n",
    "    \n",
    "#     if nucleus is None or satellite is None:\n",
    "#         print(\"\\nCan't process nucleus and satellite!\\n\")\n",
    "#         return (\"\", \"\")\n",
    "    \n",
    "#     if is_one_clause(nucleus) and is_one_clause(satellite):\n",
    "#         return make_background_question_with_two_clauses(nucleus, satellite)\n",
    "#     else:\n",
    "#         return make_background_question_with_two_clauses(nucleus, satellite)\n",
    "#         return (\"\", \"\") # other cases, not case with two clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test run for Background\n",
    "# rel = 'Background'\n",
    "# for trip in df[df['new_relation'] == rel].iterrows():\n",
    "#     with open(output_path, 'a') as f:\n",
    "#         f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "\n",
    "#         f.write(\"\\nOriginal nucleus: \" + trip[1]['nucleus'] + '\\n')\n",
    "#         f.write(\"Original satellite: \" + trip[1]['satellite'] + '\\n')\n",
    "#         f.write('\\n')\n",
    "        \n",
    "#         ques, ans = generate_background_question(original_text, trip[1]['nucleus'], trip[1]['satellite'])\n",
    "#         if not ques.strip() or not ans.strip():\n",
    "#             continue\n",
    "        \n",
    "#         f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "#         f.write(\"Answer: \" + ans + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Question Generator (for random testings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_one_clause(\"This characteristic allows the model to learn the context of a word \", count_relative_clause=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2024 20:55:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.09 examples/s]\n",
      "05/19/2024 20:55:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
      "05/19/2024 20:55:31 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 87.26 examples/s]\n",
      "05/19/2024 20:55:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What condition is the condition to overfitting.?\n",
      "Answer: The model may learn too much about the dataset,.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# miscellaneous test run\n",
    "nuc = \"\"\"The model may learn too much about the dataset, \"\"\"\n",
    "sate = \"which is the condition to overfitting.\" \n",
    "org = nuc + sate\n",
    "\n",
    "nucleus_pair = preprocessing_pipeline(org, nuc, retain_dm=True, retain_adv=True, retain_conj=True)\n",
    "satellite_pair = preprocessing_pipeline(org, sate)\n",
    "\n",
    "if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "    print(\"Can't process nucleus and satellite!\\n\")\n",
    "\n",
    "ques, ans = generate_condition_question(nucleus_pair, satellite_pair)\n",
    "if not ques.strip() or not ans.strip():\n",
    "    print(\"Can't generate questions!\\n\")\n",
    "        \n",
    "print(\"\\nQuestion: \" + ques)\n",
    "print(\"Answer: \" + ans + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Incomplete Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INC_SOURCE_LENGTH = 256\n",
    "MAX_INC_TARGET_LENGTH = 64\n",
    "INC_PREFIX = \"complete incomplete question if it lacks information to be answered:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/TOM/HUST/20232/rst-relations-labeller/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "inc_model_path = \"models/t5_base_incomplete_questions_with_answer/checkpoint-3000\"\n",
    "inc_tokenizer = T5Tokenizer.from_pretrained(inc_model_path)\n",
    "inc_model = T5ForConditionalGeneration.from_pretrained(inc_model_path)\n",
    "\n",
    "inc_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_question(context, question, answer):\n",
    "    \"\"\"Complete question if needed, needs globally available model and tokenizer (\"inc_model\" and \"inc_tokenizer\")\n",
    "\n",
    "    Args:\n",
    "        context (str): \n",
    "        question (str): \n",
    "        answer (str): \n",
    "    Return:\n",
    "        str: new question\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = inc_tokenizer(text=f\"{INC_PREFIX} context: {context}, incomplete question: {question}, answer: {answer}\",\n",
    "                        max_length=MAX_INC_SOURCE_LENGTH,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt').to('cuda')\n",
    "        \n",
    "    output_sequences = inc_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=MAX_INC_TARGET_LENGTH\n",
    "    )\n",
    "\n",
    "    output = inc_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Why can computation take a long time?\n"
     ]
    }
   ],
   "source": [
    "# test run\n",
    "question = \"Why can computation take a long time?\"\n",
    "answer = \"They ompute each component of an input in sequence\"\n",
    "context = \"\"\"RNNs and LSTM date back to the 1920s and 1990s, respectively. These techniques compute each component of an input in sequence (e.g. word by word), so computation can take a long time. What's more, both approaches run into limitations in retaining context when the “distance” between pieces of information in an input is long.\"\"\"\n",
    "\n",
    "new_question = complete_question(context, question, answer)\n",
    "print(question.strip() != new_question)\n",
    "print(new_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distractors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SOURCE_LENGTH = 4400\n",
    "MAX_TARGET_LENGTH = 96\n",
    "PREFIX = \"generate 3 distractors:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongT5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): LongT5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): LongT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): LongT5LayerTransientGlobalSelfAttention(\n",
       "            (TransientGlobalSelfAttention): LongT5TransientGlobalAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "              (global_relative_attention_bias): Embedding(32, 12)\n",
       "              (global_input_layer_norm): LongT5LayerNorm()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LongT5LayerFF(\n",
       "            (DenseReluDense): LongT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x LongT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): LongT5LayerTransientGlobalSelfAttention(\n",
       "            (TransientGlobalSelfAttention): LongT5TransientGlobalAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (global_input_layer_norm): LongT5LayerNorm()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LongT5LayerFF(\n",
       "            (DenseReluDense): LongT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LongT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): LongT5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): LongT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): LongT5LayerSelfAttention(\n",
       "            (SelfAttention): LongT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LongT5LayerCrossAttention(\n",
       "            (EncDecAttention): LongT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LongT5LayerFF(\n",
       "            (DenseReluDense): LongT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x LongT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): LongT5LayerSelfAttention(\n",
       "            (SelfAttention): LongT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LongT5LayerCrossAttention(\n",
       "            (EncDecAttention): LongT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LongT5LayerFF(\n",
       "            (DenseReluDense): LongT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): LongT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LongT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, LongT5ForConditionalGeneration\n",
    "\n",
    "dis_model_path = \"models/longt5_base_distractors_with_truncated_QuALITY/checkpoint-2500\"\n",
    "dis_tokenizer = AutoTokenizer.from_pretrained(dis_model_path)\n",
    "dis_model = LongT5ForConditionalGeneration.from_pretrained(dis_model_path)\n",
    "\n",
    "dis_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3_distractors(context, question, answer):\n",
    "    \"\"\"Generate 3 distractors, needs globally available model and tokenizer (\"dis_tokenizer\" and \"dis_model\")\n",
    "\n",
    "    Args:\n",
    "        context (str): \n",
    "        question (str): \n",
    "        answer (str): \n",
    "    Return:\n",
    "        (dis1, dis2, dis3)\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = dis_tokenizer(text=f\"{PREFIX} context: {context}, question: {question}, answer: {answer}\", \n",
    "                        max_length=MAX_SOURCE_LENGTH,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt').to('cuda')\n",
    "        \n",
    "    output_sequences = dis_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=MAX_TARGET_LENGTH\n",
    "    )\n",
    "\n",
    "    output = dis_tokenizer.batch_decode(output_sequences)[-1]\n",
    "    print(output)\n",
    "    dis1_pos = output.find(\"distractor 1:\")\n",
    "    dis2_pos = output.find(\"distractor 2:\")\n",
    "    dis3_pos = output.find(\"distractor 3:\")\n",
    "    \n",
    "    dis1 = output[dis1_pos + len(\"distractor 1:\"):dis2_pos].strip()\n",
    "    dis2 = output[dis2_pos + len(\"distractor 2:\"):dis3_pos].strip()\n",
    "    dis3 = output[dis3_pos + len(\"distractor 3:\"):].strip()\n",
    "\n",
    "    return (dis1, dis2, dis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOKRING: Distractors are still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  5.09 examples/s]\n",
      "05/18/2024 19:03:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "05/18/2024 19:03:18 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.15 examples/s]\n",
      "05/18/2024 19:03:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Tesco, one of the world's top five retailers has not abandoned Tesco, one of the world's top five retailers traditional retail offering but augmented Tesco, one of the world's top five retailers business with these innovations,  infusing Tesco, one of the world's top five retailers value proposition with a green streak. infusing Tesco, one of the world's top five retailers value proposition with a green streak.\n",
      "distractor 1: None of the above choices., distractor 2: augmented Tesco, one of the world's top five retailers business with these innovations,., distractor 3: augmented Tesco, one of the world's top five retailers business with these innovations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: which infuses Tesco, one of the world's top five retailers value proposition with a green streak., distractor 3: which infuses Tesco, one of the world's top five retailers value proposition with a green streak.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.95 examples/s]\n",
      "05/18/2024 19:03:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
      "05/18/2024 19:03:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.91 examples/s]\n",
      "05/18/2024 19:03:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.90 examples/s]\n",
      "05/18/2024 19:03:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "05/18/2024 19:03:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Using these insights, The Coach brand launched the lower-priced Poppy handbags, which were in vibrant colors, and looked more youthful and playful than conventional The Coach brand products. Using these insights, The Coach brand launched the lower-priced Poppy handbags, which were in vibrant colors, and looked more youthful and playful than conventional The Coach brand products.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.71 examples/s]\n",
      "05/18/2024 19:03:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Creating the sub-brand allowed they to avert an across-the-board price cut. In contrast to the many companies that responded to the recession by cutting prices, they saw the new consumer mindset as an opportunity for innovation and renewal. Creating the sub-brand allowed they to avert an across-the-board price cut. In contrast to the many companies that responded to the recession by cutting prices, they saw the new consumer mindset as an opportunity for innovation and renewal.\n",
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.33 examples/s]\n",
      "05/18/2024 19:03:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
      "05/18/2024 19:03:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Creating the sub-brand allowed they to avert an across-the-board price cut. Creating the sub-brand allowed they to avert an across-the-board price cut.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 55.20 examples/s]\n",
      "05/18/2024 19:03:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n",
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    }
   ],
   "source": [
    "rel = 'Cause'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_cause_question(nucleus_pair, satellite_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        ques, ans = generate_cause_question(satellite_pair, nucleus_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"Distractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:43 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 20.17 examples/s]\n",
      "05/18/2024 19:03:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "05/18/2024 19:03:45 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.44 examples/s]\n",
      "05/18/2024 19:03:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: The ME2, a video game created by Canada's iToys, was a game that was designed to be played on a handheld device., distractor 2: The ME2, a video game created by Canada's iToys was designed to be played on a handheld device., distractor 3: The ME2, a video game created by Canada's iToys was designed to be played on a handheld device.\n",
      "distractor 1: None of the above choices., distractor 2:, distractor 3:\n"
     ]
    }
   ],
   "source": [
    "rel = 'Explanation'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_cause_question(nucleus_pair, satellite_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        ques, ans = generate_cause_question(satellite_pair, nucleus_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"Distractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:03:50 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.40 examples/s]\n",
      "05/18/2024 19:03:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
      "05/18/2024 19:03:51 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 109.19 examples/s]\n",
      "05/18/2024 19:03:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
      "05/18/2024 19:03:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Can't find subject!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 106.38 examples/s]\n",
      "05/18/2024 19:03:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
      "05/18/2024 19:03:52 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.57 examples/s]\n",
      "05/18/2024 19:03:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "05/18/2024 19:03:52 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.87 examples/s]\n",
      "05/18/2024 19:03:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n",
      "05/18/2024 19:03:53 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 104.42 examples/s]\n",
      "05/18/2024 19:03:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
      "05/18/2024 19:03:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Can't find subject!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 78.32 examples/s]\n",
      "05/18/2024 19:03:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
      "05/18/2024 19:03:54 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 78.40 examples/s]\n",
      "05/18/2024 19:03:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
      "05/18/2024 19:03:54 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.01 examples/s]\n",
      "05/18/2024 19:03:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
      "05/18/2024 19:03:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 89.54 examples/s]\n",
      "05/18/2024 19:03:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "05/18/2024 19:03:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 107.18 examples/s]\n",
      "05/18/2024 19:03:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
      "05/18/2024 19:03:56 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 104.36 examples/s]\n",
      "05/18/2024 19:03:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
      "05/18/2024 19:03:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 98.59 examples/s]\n",
      "05/18/2024 19:03:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
      "05/18/2024 19:03:59 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 100.46 examples/s]\n",
      "05/18/2024 19:03:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "05/18/2024 19:04:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Coach was able to create a new brand by incorporating the new trends into their existing products. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones. This strategy was a success because it allowed Coach to retain the attributes of its existing products while adding new ones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.59 examples/s]\n",
      "05/18/2024 19:04:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
      "05/18/2024 19:04:02 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 165.77 examples/s]\n",
      "05/18/2024 19:04:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# test run for Contrast\n",
    "rel = 'Contrast'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        \n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, retain_dm=True, add_subject_to_rel_clause=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite, retain_dm=True, retain_adv=True, retain_conj=True, add_subject_to_rel_clause=True)\n",
    "        \n",
    "        if nucleus_pair[1] is None or nucleus_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_contrast_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            continue\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:03 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.64 examples/s]\n",
      "05/18/2024 19:04:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]\n",
      "05/18/2024 19:04:03 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.52 examples/s]\n",
      "05/18/2024 19:04:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: you can't counteract undesired outcomes of a trend, such as associations with unhealthy lifestyles by reaffirming the core values of your category., distractor 3: you can't counteract undesired outcomes of a trend, such as associations with unhealthy lifestyles by reaffirming the core values of your category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: aspects of your category clash with undesired outcomes of a trend, such as associations with unhealthy lifestyles,., distractor 2: aspects of your category clash with undesired outcomes of a trend, such as associations with unhealthy lifestyles,., distractor 3: aspects of your category clash with undesired outcomes of a trend, such as associations with unhealthy lifestyles,.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 81.80 examples/s]\n",
      "05/18/2024 19:04:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
      "05/18/2024 19:04:10 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.59 examples/s]\n",
      "05/18/2024 19:04:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: your innovations need to be reaffirmed by reaffirming the core values of your category., distractor 2: your innovations need to be reaffirmed by reaffirming the core values of your category., distractor 3: your innovations need to be reaffirmed by reaffirming the core values of your category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: you are trying to create a new category., distractor 3: you are trying to create a new category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 92.35 examples/s]\n",
      "05/18/2024 19:04:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
      "05/18/2024 19:04:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 105.03 examples/s]\n",
      "05/18/2024 19:04:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: the infuse-and-augment strategy will allow you to reinvigorate your category., distractor 2: the infuse-and-augment strategy will allow you to reinvigorate your category., distractor 3: None of the above choices.\n",
      "distractor 1: your category basic value proposition is reaffirmed by the trend,., distractor 2: your category basic value proposition is reaffirmed by the trend,., distractor 3: your category basic value proposition is reaffirmed by the trend\n"
     ]
    }
   ],
   "source": [
    "# for Condition relation\n",
    "\n",
    "rel = 'Condition'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus[1] is None or satellite[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_condition_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        ques, ans = generate_condition_question(satellite_pair, nucleus_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:19 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.59 examples/s]\n",
      "05/18/2024 19:04:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
      "05/18/2024 19:04:19 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.31 examples/s]\n",
      "05/18/2024 19:04:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: The ME2 was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category. It was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: The ME2 was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category. It was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 118.42 examples/s]\n",
      "05/18/2024 19:04:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n",
      "05/18/2024 19:04:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  A more radical strategy entails combining aspects of the product's existing value proposition with attributes addressing changes arising from a trend, to create a novel experience - one that may land Tesco in an entirely new market space. addressing changes arising from a trend,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.33 examples/s]\n",
      "05/18/2024 19:04:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: Nike is a company that is a company that is a company, distractor 3: Nike is a company that is a company\n",
      "distractor 1: None of the above choices., distractor 2: Nike is a company that is a company that is a company, distractor 3: Nike is a company that is a company\n"
     ]
    }
   ],
   "source": [
    "# test run for Enablement\n",
    "rel = 'Enablement'\n",
    "\n",
    "with open(output_path, 'a') as f:\n",
    "    for trip in df[df['new_relation'] == rel].iterrows():\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, retain_dm=True, retain_conj=True, retain_adv=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "       \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_enablement_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "        \n",
    "        ques, ans = generate_enablement_question(satellite_pair, nucleus_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.88 examples/s]\n",
      "05/18/2024 19:04:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
      "05/18/2024 19:04:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 86.31 examples/s]\n",
      "05/18/2024 19:04:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: by reaffirming the core values of your category., distractor 2: by reaffirming the core values of your category., distractor 3: by reaffirming the core values of your category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: you can reaffirm the core values of your category by reaffirming the core values of your category., distractor 3: you can reaffirm the core values of your category by reaffirming the core values of your category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.19 examples/s]\n",
      "05/18/2024 19:04:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
      "05/18/2024 19:04:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 98.14 examples/s]\n",
      "05/18/2024 19:04:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: The ME2 was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category. It was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: The ME2 was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category. It was a product that was designed to counteract the negatives of the toy category, and to reaffirm the values associated with the category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.84 examples/s]\n",
      "05/18/2024 19:04:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
      "05/18/2024 19:04:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.12 examples/s]\n",
      "05/18/2024 19:04:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Nike+ sports kit and web interface were a way to combine and transcend the existing value proposition with attributes addressing changes arising from a trend, distractor 2: Nike+ sports kit and web interface were a way to combine and transcend the existing value proposition, distractor 3: Nike+ sports kit and web interface were a way to combine and transcend the existing value proposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: Nike+ sports kit and web interface moved Nike from a focus on athletic apparel to a new plane of engagement with its customers, distractor 2: Nike+ sports kit and web interface moved Nike from a focus on athletic apparel to a new plane of engagement with its customers, distractor 3: None of the above choices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.47 examples/s]\n",
      "05/18/2024 19:04:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s]\n",
      "05/18/2024 19:04:48 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.45 examples/s]\n",
      "05/18/2024 19:04:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: Like points earned on a credit card., distractor 3: Like points earned on a debit card.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: points can be redeemed for a gift card., distractor 2: points can be redeemed for a gift card., distractor 3: None of the above choices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 111.20 examples/s]\n",
      "05/18/2024 19:04:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
      "05/18/2024 19:04:52 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 100.57 examples/s]\n",
      "05/18/2024 19:04:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: by involving consumers in ways that produce intangible results., distractor 2: by involving consumers in ways that produce intangible results., distractor 3: None of the above choices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/18/2024 19:04:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2:, distractor 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 131.99 examples/s]\n",
      "05/18/2024 19:04:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "05/18/2024 19:04:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 102.82 examples/s]\n",
      "05/18/2024 19:04:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: by ignoring trends in their innovation strategies., distractor 2: by ignoring trends in their product development strategies., distractor 3: None of the above choices.\n",
      "distractor 1: None of the above choices., distractor 2: By letting competitors take the lead., distractor 3: By ignoring trends in their innovation strategies.\n"
     ]
    }
   ],
   "source": [
    "# test run for Manner-Means\n",
    "rel = 'Manner-Means'\n",
    "with open(output_path, 'a') as f:\n",
    "    for trip in df[df['new_relation'] == rel].iterrows():\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, add_subject_to_rel_clause=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "\n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_means_question(nucleus_pair, satellite_pair) \n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "        \n",
    "        ques, ans = generate_means_question(satellite_pair, nucleus_pair) \n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "            \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(para, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distractor 1: None of the above choices., distractor 2: By letting competitors take the lead., distractor 3: By ignoring trends in their innovation strategies.\n",
      "\n",
      "Distractor 1: None of the above choices.,\n",
      "Distractor 2: By letting competitors take the lead.,\n",
      "Distractor 3: By ignoring trends in their innovation strategies.\n"
     ]
    }
   ],
   "source": [
    "context = \"Many ignore trends in their innovation strategies or adopt a wait-and-see approach and let competitors take the lead. At a minimum, such responses mean missed profit opportunities. At the extreme, they can jeopardize a company by ceding to rivals the opportunity to transform the industry. The purpose of this article is twofold: to spur managers to think more expansively about how trends could engender new value propositions in their core markets, and to provide some high-level advice on how’ to make market research and product development personnel more adept at analyzing and exploiting trends.\"\n",
    "question = \"Why can ignore trends in their innovation strategies or adopt a wait-and-see approach and let competitors take the lead jeopardize a company?\"\n",
    "answer = \"Because the company then cedes to rivals the opportunity to transform the industry.\"\n",
    "\n",
    "dis1, dis2, dis3 = generate_3_distractors(context, ques, ans)\n",
    "print(\"\\nDistractor 1: \" + dis1)\n",
    "print(\"Distractor 2: \" + dis2)\n",
    "print(\"Distractor 3: \" + dis3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

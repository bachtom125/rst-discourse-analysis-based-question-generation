{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_tree_dict(pickle_path):\n",
    "    try: \n",
    "        with open(pickle_path, 'rb') as file:\n",
    "            tree = pickle.load(file)\n",
    "            return tree\n",
    "    except:\n",
    "        print(\"Can't open file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_id(tree_dict):\n",
    "    for key, item in tree_dict.items():\n",
    "        if item['pnode_id'] == -1:\n",
    "            root_id = key\n",
    "    return root_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treelib\n",
    "\n",
    "def visualize_rst_tree(tree_dict, root_id, edu_list, new_relation=False, get_edu_text=False):\n",
    "    rst_tree = treelib.Tree()\n",
    "    relation_key = 'relation' if not new_relation else 'new_relation'\n",
    "    node_list = [root_id]\n",
    "\n",
    "    while node_list:\n",
    "        id = node_list.pop()\n",
    "        node = tree_dict[id]\n",
    "        if (tree_dict.get(node['lnode_id']) is None) and (tree_dict.get(node['rnode_id']) is None):\n",
    "            node_text = \" EDU \" + str(node['edu_span'])\n",
    "            if get_edu_text:\n",
    "                node_text += \": \" + edu_list[node['edu_span'][0] - 1]\n",
    "            rst_tree.create_node(node_text, id, parent=node['pnode_id'])\n",
    "        else:\n",
    "            node_text = node['node_form']\n",
    "\n",
    "            if node['node_form'] == 'NN':\n",
    "                node_text += \"-\" + tree_dict[node['rnode_id']][relation_key]\n",
    "            elif node['node_form'] == 'NS':\n",
    "                node_text += \"-\" + tree_dict[node['rnode_id']][relation_key]\n",
    "            elif node['node_form'] == 'SN':\n",
    "                node_text += \"-\" + tree_dict[node['lnode_id']][relation_key]\n",
    "            else:\n",
    "                raise ValueError(\"Unrecognized N-S form\")\n",
    "            \n",
    "            if rst_tree.get_node(node['pnode_id']) is not None:\n",
    "                rst_tree.create_node(node_text, id, parent=node['pnode_id'])\n",
    "            else:\n",
    "                rst_tree.create_node(node_text, id)\n",
    "                print(\"\\nNo parent at node: \", node_text, '\\n')\n",
    "\n",
    "        if tree_dict.get(node['rnode_id']) is not None:\n",
    "            node_list.append(node['rnode_id'])\n",
    "        if tree_dict.get(node['lnode_id']) is not None:\n",
    "            node_list.append(node['lnode_id'])\n",
    "\n",
    "    return rst_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edus_from_file(edu_path):\n",
    "    \"\"\"Get EDUs from .edu file and return a list of EDUs\n",
    "    \"\"\"\n",
    "    edus = []\n",
    "    try: \n",
    "        with open(edu_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                edus.append(line.rstrip('\\n'))\n",
    "        return edus    \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(edu_list, tree_dict, root_id): # use this when unpickling\n",
    "    \"\"\"Extract text segments from (1 or several EDUs) for relation labeller to read from (and make predictions)\n",
    "\n",
    "    Args:\n",
    "        edu_list: list containing EDUs (list)\n",
    "        tree_dict: dict containing tree (dict)\n",
    "\n",
    "    Return:\n",
    "        Dict containing text of nucleus, satellite, and original relation from StageDP (dict)\n",
    "    \"\"\"\n",
    "\n",
    "    segments = {'pnode_id': [], 'nucleus': [], 'satellite': [], 'original_relation': []} # if multi-nuclear, satellite represent second nucleus\n",
    "    node_list = [root_id]\n",
    "    while node_list:\n",
    "        id = node_list.pop()\n",
    "        node = tree_dict[id]\n",
    "\n",
    "        if (tree_dict.get(node['lnode_id']) is None) and (tree_dict.get(node['rnode_id']) is None): # node is EDU\n",
    "            continue\n",
    "    \n",
    "        left_edu_span = tree_dict[node['lnode_id']]['edu_span'] # tuple: (from, to)\n",
    "        right_edu_span = tree_dict[node['rnode_id']]['edu_span'] # tuple: (from, to)\n",
    "        \n",
    "        # get corresponding text segments\n",
    "        left_segment = \"\"\n",
    "        for edu in range(left_edu_span[0], left_edu_span[1] + 1):\n",
    "            left_segment += edu_list[edu - 1].strip() + ' '\n",
    "\n",
    "        right_segment = \"\"\n",
    "        for edu in range(right_edu_span[0], right_edu_span[1] + 1):\n",
    "            right_segment += edu_list[edu - 1].strip() + ' '\n",
    "\n",
    "        if node['node_form'] == 'NN':\n",
    "            nucleus = left_segment\n",
    "            satellite = right_segment\n",
    "            relation = tree_dict[node['rnode_id']]['relation']\n",
    "        elif node['node_form'] == 'NS':\n",
    "            nucleus = left_segment\n",
    "            satellite = right_segment\n",
    "            relation = tree_dict[node['rnode_id']]['relation']\n",
    "        elif node['node_form'] == 'SN':\n",
    "            nucleus = right_segment\n",
    "            satellite = left_segment\n",
    "            relation = tree_dict[node['lnode_id']]['relation']\n",
    "\n",
    "        segments['nucleus'].append(nucleus)\n",
    "        segments['satellite'].append(satellite)\n",
    "        segments['original_relation'].append(relation)\n",
    "        segments['pnode_id'].append(id)  \n",
    "        \n",
    "        if tree_dict.get(node['lnode_id']) is not None:\n",
    "            node_list.append(node['lnode_id'])\n",
    "        if tree_dict.get(node['rnode_id']) is not None:\n",
    "            node_list.append(node['rnode_id'])\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def add_new_relations_to_tree_dict(tree_dict, new_relations):\n",
    "    \"\"\"Extract text segments from (1 or several EDUs) for relation labeller to read from (and make predictions)\n",
    "\n",
    "    Args:\n",
    "        tree_dict: dict containing tree (dict)\n",
    "        new_relations: df containing parent id and new relations (and other components no considered in this method)\n",
    "\n",
    "    Return:\n",
    "        New modified tree_dict according to new relations identified\n",
    "    \"\"\"\n",
    "    tree_dict_c = copy.deepcopy(tree_dict)\n",
    "    for _, r in new_relations.iterrows():\n",
    "        p_id = r['pnode_id']\n",
    "        rel = r['new_relation']\n",
    "        if tree_dict_c[p_id]['node_form'] == 'NN':\n",
    "            tree_dict_c[tree_dict_c[p_id]['rnode_id']]['new_relation'] = rel\n",
    "            tree_dict_c[tree_dict_c[p_id]['lnode_id']]['new_relation'] = rel\n",
    "        elif tree_dict_c[p_id]['node_form'] == 'NS':\n",
    "            tree_dict_c[tree_dict_c[p_id]['rnode_id']]['new_relation'] = rel\n",
    "        elif tree_dict_c[p_id]['node_form'] == 'SN':\n",
    "            tree_dict_c[tree_dict_c[p_id]['lnode_id']]['new_relation'] = rel\n",
    "        \n",
    "    return tree_dict_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text_file(text_path, text):\n",
    "    \"\"\"Write string in text to text_path. The text is to be analyzed using RST and generated questions from. \n",
    "\n",
    "    Args:\n",
    "        text_path (str): path of file to write to\n",
    "        text (str): text to write to (informational text to extract questions from)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(text_path, 'w') as f:\n",
    "            f.write(text)\n",
    "    except:\n",
    "        print(\"Can't open text file!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to start processing text\n",
    "\n",
    "raw_original_text = \"\"\"Depending on your budget, need for speed and precision required, each algorithm type—supervised, unsupervised, semi-supervised, or reinforcement—has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors. Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms—which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day:\n",
    "Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search—e.g. Siri—or improve accessibility for texting.\n",
    "Customer service:  Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants.\"\"\"\n",
    "raw_original_text = raw_original_text.replace(u\"\\u2018\", \"'\").replace(u\"\\u2019\", \"'\").replace(u\"\\u2013\", \"-\").replace(u\"\\u2014\", \"-\").replace(u\"\\u201C\", \"-\").replace(u\"\\u201D\", \"-\") \n",
    "text_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample\"\n",
    "\n",
    "write_to_text_file(text_path, raw_original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_original_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No parent at node:  NS-Elaboration \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to process new data, adjust paths if necessary\n",
    "\n",
    "pickle_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample.pickle\"\n",
    "edu_path = \"../parsers-from-github/StageDP_2/data/my_sample/sample.edus\"\n",
    "\n",
    "tree_dict = get_tree_dict(pickle_path)\n",
    "root_id = get_root_id(tree_dict)\n",
    "edus = get_edus_from_file(edu_path)\n",
    "rst_tree = visualize_rst_tree(tree_dict, root_id, edus, get_edu_text=True)\n",
    "\n",
    "# print(rst_tree.show(stdout=False, sorting=False)) # uncomment to visualize RST tree\n",
    "# print(edus)\n",
    "\n",
    "segments = extract_segments(edus, tree_dict, root_id)\n",
    "df = pd.DataFrame(segments)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembly the whole piece of text from EDUs, to ensure allignment\n",
    "\n",
    "original_text = \"\"\n",
    "for edu in edus:\n",
    "    original_text += edu.strip() + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map \"Comparison\" to \"Join\" since GUM does not contain \"Comparison\"\n",
    "for row in df[df['original_relation'] == 'Comparison'].iterrows():\n",
    "    df.at[row[0], 'original_relation'] = \"Joint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/TOM/HUST/20232/rst-relations-labeller/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# run this cell only once\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"output_train_all_with_additional_reverse_dataset1/checkpoint-45000\"\n",
    "if 'tokenizer' not in locals(): # prevent accidental re-run of cell\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if 'model' not in locals(): # prevent accidental re-run of cell\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_text = ['Attribution', 'Background', 'Cause', 'Condition', 'Contrast',\n",
    "       'Elaboration', 'Enablement', 'Evaluation', 'Explanation', 'Joint',\n",
    "       'Manner-Means', 'Same-Unit', 'Summary', 'Temporal',\n",
    "       'Textual-Organization', 'Topic-Change', 'Topic-Comment']\n",
    "\n",
    "label_shorthand = ['Attr', 'Bckg', 'Cause', 'Cond', 'Contst',\n",
    "       'Elab', 'Enab', 'Eval', 'Expl', 'Joint',\n",
    "       'Man-Mean', 'Same-Un', 'Sum', 'Temp',\n",
    "       'Text-Org', 'Top-Chang', 'Top-Com']\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(label_text)\n",
    "labels = le.transform(df.original_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding <sep> token between nucleus and satellite\n",
    "separation_token = \"[SEP]\"\n",
    "input_sentences = df.apply(lambda x: ''.join([x['nucleus'], separation_token, x['satellite']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge input sentence and labels onto one list (to form dataset object later)\n",
    "data = []\n",
    "for text in input_sentences:\n",
    "    datapoint = {'text': text}\n",
    "    data.append(datapoint)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "import datasets\n",
    "\n",
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "batch_size = 32\n",
    "dataset = datasets.Dataset.from_list(list(data))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        tokens = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        output = model(**tokens)\n",
    "        logits = torch.Tensor.cpu(output.logits)\n",
    "        pred_labels.extend(np.argmax(logits, axis=-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = le.inverse_transform(pred_labels)\n",
    "df['new_relation'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 changed relations out of 41 (0.51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140167423060288</td>\n",
       "      <td>For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors.</td>\n",
       "      <td>Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Topic-Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140167423060176</td>\n",
       "      <td>Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies.</td>\n",
       "      <td>These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140167423058608</td>\n",
       "      <td>These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all.</td>\n",
       "      <td>And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140167423060120</td>\n",
       "      <td>And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Topic-Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>140167423060792</td>\n",
       "      <td>Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person.</td>\n",
       "      <td>On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>140167423059280</td>\n",
       "      <td>On the downside, machine learning requires large training datasets that are accurate and unbiased.</td>\n",
       "      <td>GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Contrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>140167423059448</td>\n",
       "      <td>Gathering sufficient data and having a system robust enough to run it might also be a drain on resources.</td>\n",
       "      <td>Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Topic-Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>140167423058832</td>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140167423059392</td>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>140167423059840</td>\n",
       "      <td>Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "      <td>Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Joint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>140167423060456</td>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>Customer service:</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>140167423059000</td>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey,</td>\n",
       "      <td>changing the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>140167423060064</td>\n",
       "      <td>organizations should act on the answers</td>\n",
       "      <td>only when there is high confidence in the output.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>140167423060232</td>\n",
       "      <td>Machine learning can also be prone to error,</td>\n",
       "      <td>depending on the input.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>140167423059560</td>\n",
       "      <td>it might also be a drain on resources.</td>\n",
       "      <td>and having a system robust enough to run</td>\n",
       "      <td>Attribution</td>\n",
       "      <td>Same-Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>140167423058328</td>\n",
       "      <td>GIGO is the operative factor:</td>\n",
       "      <td>garbage in / garbage out.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Textual-Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>140167423058104</td>\n",
       "      <td>Customers and users can enjoy a more personalized experience</td>\n",
       "      <td>as the model learns more with every experience with that person.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>140167423058160</td>\n",
       "      <td>And this analysis requires little human intervention:</td>\n",
       "      <td>just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>140167423058272</td>\n",
       "      <td>just feed in the dataset of interest</td>\n",
       "      <td>and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>140167423025104</td>\n",
       "      <td>For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories.</td>\n",
       "      <td>Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors.</td>\n",
       "      <td>Joint</td>\n",
       "      <td>Elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>140167423025048</td>\n",
       "      <td>Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram.</td>\n",
       "      <td>A prime advantage of decision trees is that they are easier to validate and audit than a neural network.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Topic-Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pnode_id  \\\n",
       "1   140167423060288   \n",
       "2   140167423060176   \n",
       "3   140167423058608   \n",
       "4   140167423060120   \n",
       "5   140167423060792   \n",
       "6   140167423059280   \n",
       "8   140167423059448   \n",
       "10  140167423058832   \n",
       "11  140167423059392   \n",
       "15  140167423059840   \n",
       "18  140167423060456   \n",
       "19  140167423059000   \n",
       "23  140167423060064   \n",
       "25  140167423060232   \n",
       "27  140167423059560   \n",
       "28  140167423058328   \n",
       "30  140167423058104   \n",
       "31  140167423058160   \n",
       "32  140167423058272   \n",
       "36  140167423025104   \n",
       "38  140167423025048   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                              nucleus  \\\n",
       "1   For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors.    \n",
       "2                                                                                                                                                                                                                                                                                                                                          Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies.    \n",
       "3                                                                                                                                                                                                                                                                                                                       These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all.    \n",
       "4                                                                                                                                                                                                              And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.    \n",
       "5                                                                                                                                                                                                                                                                                                                      Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person.    \n",
       "6                                                                                                                                                                                                                                                                                                                                                 On the downside, machine learning requires large training datasets that are accurate and unbiased.    \n",
       "8                                                                                                                                                                                                                                                                                                                                          Gathering sufficient data and having a system robust enough to run it might also be a drain on resources.    \n",
       "10                                                                                                                                                                                                                                                                                                                           With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.    \n",
       "11                                                                                                                                                                                                                                                                                                       To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.    \n",
       "15                                                                                                                                                                                                                                                                                                     Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting.    \n",
       "18                                                                                                                                                                                                                                                                            Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms.    \n",
       "19                                                                                                                                                                                                                                                                                                                                                                            Online chatbots are replacing human agents along the customer journey,    \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                           organizations should act on the answers    \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                      Machine learning can also be prone to error,    \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                            it might also be a drain on resources.    \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                     GIGO is the operative factor:    \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                      Customers and users can enjoy a more personalized experience    \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                             And this analysis requires little human intervention:    \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                              just feed in the dataset of interest    \n",
       "36                                                                                                                                                                                                                                                                                                   For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories.    \n",
       "38                                                                                                                                                                                                                                                                                                                                          Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 satellite  \\\n",
       "1   Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "2                                                                                                             These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "3                                                                                                                                                                                                                                          And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.    \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Customer service:    \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        changing the way we think about customer engagement across websites and social media platforms.    \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      only when there is high confidence in the output.    \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                depending on the input.    \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               and having a system robust enough to run    \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              garbage in / garbage out.    \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       as the model learns more with every experience with that person.    \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.    \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.    \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors.    \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               A prime advantage of decision trees is that they are easier to validate and audit than a neural network.    \n",
       "\n",
       "   original_relation          new_relation  \n",
       "1              Joint          Topic-Change  \n",
       "2        Elaboration            Evaluation  \n",
       "3              Joint           Elaboration  \n",
       "4              Joint          Topic-Change  \n",
       "5              Joint              Contrast  \n",
       "6              Joint              Contrast  \n",
       "8              Joint          Topic-Change  \n",
       "10       Elaboration           Explanation  \n",
       "11       Elaboration           Explanation  \n",
       "15       Elaboration                 Joint  \n",
       "18       Elaboration  Textual-Organization  \n",
       "19       Elaboration                 Cause  \n",
       "23       Elaboration             Condition  \n",
       "25       Elaboration             Condition  \n",
       "27       Attribution             Same-Unit  \n",
       "28       Elaboration  Textual-Organization  \n",
       "30       Elaboration            Background  \n",
       "31       Elaboration           Explanation  \n",
       "32             Joint              Temporal  \n",
       "36             Joint           Elaboration  \n",
       "38       Elaboration          Topic-Change  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate porportion of changed labels\n",
    "\n",
    "diff = df.apply(lambda x: x['original_relation'] != x['new_relation'], axis=1)\n",
    "print(diff.sum(), \"changed relations out of\", df.shape[0], '(' + str(round(float(diff.sum()/df.shape[0]), 2)) + ')')\n",
    "df[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No parent at node:  NS-Elaboration \n",
      "\n",
      "NS-Elaboration\n",
      "├── NN-Background\n",
      "│   ├──  EDU (1, 1): Depending on your budget, need for speed and precision required,\n",
      "│   └──  EDU (2, 2): each algorithm type-supervised, unsupervised, semi-supervised, or reinforcement-has its own advantages and disadvantages.\n",
      "└── NN-Topic-Change\n",
      "    ├── NN-Elaboration\n",
      "    │   ├──  EDU (3, 3): For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories.\n",
      "    │   └── NN-Contrast\n",
      "    │       ├── NS-Topic-Change\n",
      "    │       │   ├── NS-Elaboration\n",
      "    │       │   │   ├──  EDU (4, 4): Decision trees use a branching sequence of linked decisions\n",
      "    │       │   │   └──  EDU (5, 5): that may be represented with a tree diagram.\n",
      "    │       │   └──  EDU (6, 6): A prime advantage of decision trees is that they are easier to validate and audit than a neural network.\n",
      "    │       └──  EDU (7, 7): The bad news is that they can be more unstable than other decision predictors.\n",
      "    └── NS-Evaluation\n",
      "        ├── NS-Elaboration\n",
      "        │   ├──  EDU (8, 8): Overall, there are many advantages to machine learning \n",
      "        │   └──  EDU (9, 9): that businesses can leverage for new efficiencies.\n",
      "        └── NN-Elaboration\n",
      "            ├── NS-Elaboration\n",
      "            │   ├──  EDU (10, 10): These include machine learning identifying patterns and trends in massive volumes of data\n",
      "            │   └──  EDU (11, 11): that humans might not spot at all.\n",
      "            └── NN-Topic-Change\n",
      "                ├── NS-Explanation\n",
      "                │   ├──  EDU (12, 12): And this analysis requires little human intervention: \n",
      "                │   └── NN-Temporal\n",
      "                │       ├──  EDU (13, 13): just feed in the dataset of interest\n",
      "                │       └── NS-Elaboration\n",
      "                │           ├──  EDU (14, 14): and let the machine learning system assemble and refine its own algorithms\n",
      "                │           └──  EDU (15, 15): -which will continually improve with more data input over time.\n",
      "                └── NN-Contrast\n",
      "                    ├── NS-Background\n",
      "                    │   ├──  EDU (16, 16): Customers and users can enjoy a more personalized experience\n",
      "                    │   └──  EDU (17, 17): as the model learns more with every experience with that person.\n",
      "                    └── NN-Contrast\n",
      "                        ├── NS-Elaboration\n",
      "                        │   ├──  EDU (18, 18): On the downside, machine learning requires large training datasets\n",
      "                        │   └──  EDU (19, 19): that are accurate and unbiased.\n",
      "                        └── NS-Elaboration\n",
      "                            ├── NS-Textual-Organization\n",
      "                            │   ├──  EDU (20, 20): GIGO is the operative factor: \n",
      "                            │   └──  EDU (21, 21): garbage in / garbage out.\n",
      "                            └── NN-Topic-Change\n",
      "                                ├── NN-Joint\n",
      "                                │   ├──  EDU (22, 22): Gathering sufficient data\n",
      "                                │   └── SN-Same-Unit\n",
      "                                │       ├──  EDU (23, 23): and having a system robust enough to run\n",
      "                                │       └──  EDU (24, 24): it might also be a drain on resources.\n",
      "                                └── NS-Elaboration\n",
      "                                    ├── NS-Condition\n",
      "                                    │   ├──  EDU (25, 25): Machine learning can also be prone to error, \n",
      "                                    │   └──  EDU (26, 26): depending on the input.\n",
      "                                    └── NS-Explanation\n",
      "                                        ├── NS-Elaboration\n",
      "                                        │   ├──  EDU (27, 27): With too small a sample, the system could produce a perfectly logical algorithm\n",
      "                                        │   └──  EDU (28, 28): that is completely wrong or misleading.\n",
      "                                        └── NS-Explanation\n",
      "                                            ├── SN-Enablement\n",
      "                                            │   ├──  EDU (29, 29): To avoid wasting budget or displeasing customers,\n",
      "                                            │   └── NS-Condition\n",
      "                                            │       ├──  EDU (30, 30): organizations should act on the answers \n",
      "                                            │       └──  EDU (31, 31): only when there is high confidence in the output.\n",
      "                                            └── NN-Textual-Organization\n",
      "                                                ├──  EDU (32, 32): Here are just a few examples of machine learning you might encounter every day:\n",
      "                                                └── NN-Textual-Organization\n",
      "                                                    ├──  EDU (33, 33): Speech recognition:\n",
      "                                                    └── NS-Elaboration\n",
      "                                                        ├── NS-Elaboration\n",
      "                                                        │   ├──  EDU (34, 34): It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability\n",
      "                                                        │   └──  EDU (35, 35): which uses natural language processing (NLP) to translate human speech into a written format.\n",
      "                                                        └── NS-Joint\n",
      "                                                            ├── NS-Enablement\n",
      "                                                            │   ├──  EDU (36, 36): Many mobile devices incorporate speech recognition into their systems\n",
      "                                                            │   └──  EDU (37, 37): to conduct voice search-e.g. Siri-or improve accessibility for texting.\n",
      "                                                            └── NS-Elaboration\n",
      "                                                                ├── SN-Textual-Organization\n",
      "                                                                │   ├──  EDU (38, 38): Customer service:\n",
      "                                                                │   └── NS-Cause\n",
      "                                                                │       ├──  EDU (39, 39): Online chatbots are replacing human agents along the customer journey,\n",
      "                                                                │       └──  EDU (40, 40): changing the way we think about customer engagement across websites and social media platforms.\n",
      "                                                                └── NS-Elaboration\n",
      "                                                                    ├──  EDU (41, 41): Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users.\n",
      "                                                                    └──  EDU (42, 42): Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fix old tree with new relations\n",
    "\n",
    "new_tree_dict = add_new_relations_to_tree_dict(tree_dict, df)\n",
    "new_rst_tree = visualize_rst_tree(new_tree_dict, get_root_id(new_tree_dict), edus, new_relation=True, get_edu_text=True)\n",
    "\n",
    "print(new_rst_tree.show(stdout=False, sorting=False)) # for visualizing rst_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 13 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_cnt = pd.Series(pred_labels).value_counts()\n",
    "indices = pd.Series(label_shorthand).reindex(label_cnt.index, fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.yticks(np.arange(1, max(label_cnt) + 1))\n",
    "plt.bar(indices, label_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pnode_id, nucleus, satellite, original_relation, new_relation]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find occurences of a specific relation\n",
    "\n",
    "df[df[\"original_relation\"] == \"Cause\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnode_id</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>original_relation</th>\n",
       "      <th>new_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>140167423059000</td>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey,</td>\n",
       "      <td>changing the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>Elaboration</td>\n",
       "      <td>Cause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pnode_id  \\\n",
       "19  140167423059000   \n",
       "\n",
       "                                                                    nucleus  \\\n",
       "19  Online chatbots are replacing human agents along the customer journey,    \n",
       "\n",
       "                                                                                           satellite  \\\n",
       "19  changing the way we think about customer engagement across websites and social media platforms.    \n",
       "\n",
       "   original_relation new_relation  \n",
       "19       Elaboration        Cause  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find occurences of a specific relation\n",
    "\n",
    "df[df[\"new_relation\"] == \"Cause\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enablement'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "sep = tokenizer.sep_token\n",
    "text_n = \"She used the tool in the garden, \"\n",
    "text_s = \"in order to win.\"\n",
    "text = text_n + sep + text_s\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    output = model(**tokens)\n",
    "    logits = torch.Tensor.cpu(output.logits)\n",
    "    single_pred = int(np.argmax(logits, axis=-1))\n",
    "    \n",
    "le.inverse_transform([single_pred])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_PRONOUNS = ['who', 'that', 'whose', 'which']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "nlp_small = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj(clause, accept_pron=True, accept_expl=False):\n",
    "    \"\"\"Return subject of clause, None of none found\n",
    "\n",
    "    Args:\n",
    "        clause (str): \n",
    "        accept_expl (bool, optional): If take expletive as subject. Defaults to False.\n",
    "        accept_expl (bool, optional): If take pronoun as subject. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: The subject\n",
    "    \"\"\"\n",
    "    doc = nlp(clause)\n",
    "\n",
    "    for token in doc:\n",
    "        if 'nsubj' in token.dep_:\n",
    "            if token.pos_ == \"PRON\" and not accept_pron:\n",
    "                continue\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if chunk.start <= token.i and token.i < chunk.end:\n",
    "                    return chunk.text\n",
    "        if accept_expl:\n",
    "            if 'expl' in token.dep_:\n",
    "                return token.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING: make a more fool proof method of checking relative clause: inputing both source sents and text, and use pos tags to determine, refer to : is_dependent_clause()\n",
    "def check_relative_clause(text):\n",
    "    \"\"\"Return if the text (has to contain only one clause) is a relative clause, \n",
    "    relative clauses can start with \"which\", \"Ving, \"Ved\" (not including adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        text\n",
    "    Return\n",
    "        boolean\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.dep_ == \"nsubj\"):\n",
    "                if (token.text.lower() in RELATIVE_PRONOUNS):\n",
    "                    return 1 # relative clause starting with relative pronouns\n",
    "                break\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.pos_ == \"VERB\") and (token.tag_ in ['VBG', 'VBN']):\n",
    "                # WORKING: Change way to check tense, use tag_ instead of morph\n",
    "                if len(token.morph.get('Tense')) == 0:\n",
    "                    return 0 # not relative clause\n",
    "                if (token.text.endswith('ing')) or (token.tag_ ==  'VBN'):\n",
    "                    return 2 # shortened relative clause (ending with Ving or Ved)\n",
    "            else: \n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundary(sent_doc, text_doc):\n",
    "    \"\"\"Find boundary indices of text_doc in sent_doc (given that text_doc is in sent_doc)\n",
    "\n",
    "    Args:\n",
    "        sent_doc (nlp Doc): \n",
    "        text_doc (nlp Doc): \n",
    "    \"\"\"\n",
    "    start_ind = 0\n",
    "    while start_ind < len(sent_doc):\n",
    "        if text_doc.text not in sent_doc[start_ind:].text:\n",
    "            break\n",
    "        start_ind += 1\n",
    "    start_ind -= 1\n",
    "\n",
    "    end_ind = len(sent_doc)\n",
    "    while end_ind > 0:\n",
    "        if (text_doc.text not in sent_doc[:end_ind].text) or (end_ind <= start_ind):\n",
    "            break\n",
    "        end_ind -= 1\n",
    "    end_ind += 1\n",
    "\n",
    "    return start_ind, end_ind\n",
    "\n",
    "def is_dependent_clause(src_sent, text):\n",
    "    # WORKING: may use this way to check relative clause as well\n",
    "    sent_doc = nlp(src_sent)\n",
    "    text_doc = nlp(text)   \n",
    "\n",
    "    start_ind, end_ind = find_boundary(sent_doc, text_doc)\n",
    "    if start_ind < 0 or end_ind > len(sent_doc):\n",
    "        print(\"\\nText not found in source sentence!\\n\")\n",
    "        return None\n",
    "\n",
    "    for token in sent_doc[start_ind:end_ind]:\n",
    "        if token.dep_ in ['acl', 'advcl', 'xcomp']: # omitted \"ccomp\", put back again if needed\n",
    "            if token.head.i in range(start_ind, end_ind):\n",
    "                return False\n",
    "            return True\n",
    "    return False     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def unshorten_relative_clause(original_sent, clause):\n",
    "    \"\"\"Unshorten relative clause (make sure it's a relative clause before calling this method) ending with Ving or Ved, convert them to which/who + V\n",
    "\n",
    "    Args:\n",
    "        clause (str): relative clause containing Ving or Ved\n",
    "        original_sent (str): original sentence containing that clause\n",
    "    Return:\n",
    "        tuple(str, str): modified clause and source sentence\n",
    "    \"\"\"\n",
    "\n",
    "    clause_doc = nlp(clause)\n",
    "    text_doc = nlp(original_sent)\n",
    "    vb = \"\"\n",
    "\n",
    "    for token in clause_doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if (token.pos_ == \"VERB\") and (token.tag_ in ['VBG', 'VBN']): # finds Ving or Ved\n",
    "                vb = token\n",
    "\n",
    "    for v_token in text_doc:\n",
    "        # find verb in original sentence\n",
    "        if v_token.text == vb.text.strip():\n",
    "            c_i = vb.i\n",
    "            t_i = v_token.i\n",
    "            is_verb = True\n",
    "            while c_i < len(clause_doc) and t_i < len(text_doc):\n",
    "                if clause_doc[c_i].text.strip() != text_doc[t_i].text.strip():\n",
    "                    is_verb = False\n",
    "                    break\n",
    "                c_i += 1\n",
    "                t_i += 1\n",
    "            if is_verb:\n",
    "                break\n",
    "    \n",
    "    pointed_noun = v_token.head\n",
    "    pointed_noun_chunk = None\n",
    "    for chunk in text_doc.noun_chunks:\n",
    "        if chunk.start <= pointed_noun.i and pointed_noun.i < chunk.end:\n",
    "            pointed_noun_chunk = chunk\n",
    "    \n",
    "    if pointed_noun_chunk:\n",
    "        pointed_root_noun = pointed_noun_chunk.root\n",
    "    else:\n",
    "        pointed_root_noun = pointed_noun\n",
    "    \n",
    "    rel_pro = \"which\" \n",
    "    # not a fool-proof way to determine if noun is person\n",
    "    if pointed_root_noun.ent_type_:\n",
    "        if pointed_root_noun.ent_type_ == \"PERSON\":\n",
    "            rel_pro = \"who\"\n",
    "\n",
    "    # check plurality of noun/pronoun and conjugate accordingly\n",
    "    # only applicable for Present Tense, not for past or others\n",
    "    if pointed_root_noun.pos_.startswith(\"NOUN\"): # noun\n",
    "        plurality = pointed_root_noun.tag_ == \"NNS\"\n",
    "    elif \"PRON\" in pointed_root_noun.pos_:  # pronoun\n",
    "        plurality = (pointed_root_noun.lemma_ == \"we\") or (pointed_root_noun.lemma_ == \"you\") or (pointed_root_noun.lemma_ == \"they\") or ((pointed_root_noun.lemma_ == \"I\"))\n",
    "    else: # WORKING: for other cases where relative pronoun does not point to a noun, but a verb or a clause\n",
    "        plurality = False # temporary solution\n",
    "\n",
    "    if not plurality:\n",
    "        if vb.tag_ == 'VBG':\n",
    "            conj_vb = p.plural_noun(vb.lemma_) # get singular conjugation (plural_noun() method works with verbs too)\n",
    "        else:\n",
    "            if pointed_root_noun.text.strip() == \"I\":\n",
    "                aux = 'am'\n",
    "            else:\n",
    "                aux = 'is'\n",
    "            conj_vb = aux + ' ' + vb.text\n",
    "    else:\n",
    "        if vb.tag_ == 'VGB':\n",
    "            conj_vb = p.plural_verb(vb.lemma_) # get plural conjugation\n",
    "        else:\n",
    "            if pointed_root_noun.text.strip() == \"I\":\n",
    "                aux = 'am'\n",
    "            else:\n",
    "                aux = 'are'\n",
    "            conj_vb = aux + ' ' + vb.text\n",
    "\n",
    "    fixed_clause = clause.replace(vb.text, rel_pro + ' ' +  conj_vb, 1)# replace only the first occurence of the verb\n",
    "    fixed_sent = original_sent.replace(clause.strip(), fixed_clause.strip(), 1)\n",
    "    return  (fixed_sent, fixed_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I saw Tom which walks at midnight', 'which walks at midnight')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshorten_relative_clause(\"I saw Tom walking at midnight\", \"walking at midnight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING: Need to handle all types of shortened relative clauses, for now, only Ving and Ved is covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_clause(text, count_relative_clause=True):\n",
    "    \"\"\"Check if input text is one clause or multiple.\n",
    "        NOTE: If not multiple clause, the method returns true, so does not account for the case of not a full clause, just check whether multiple clauses or not, cause a EDU is usually at least a clause semantically. \n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # check how many subjects\n",
    "    has_subj = False\n",
    "    for token in doc:\n",
    "        if \"nsubj\" in token.dep_:\n",
    "            if not count_relative_clause:\n",
    "                if token.text.lower() in ['who', 'whom', 'whose', 'which', 'that']:\n",
    "                    continue\n",
    "                if token.head.dep_ in ['relcl', 'acl', 'ccomp']:\n",
    "                    continue\n",
    "            if has_subj:\n",
    "                return False\n",
    "            else:\n",
    "                has_subj = True\n",
    "    return True # not return has_subj, so that even no subject will be 1 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_aux(sentence):\n",
    "    \"\"\"Check if sentence has auxiliary verb.\n",
    "    Input one sentence only.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if \"AUX\" in token.pos_:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_shorthand = {\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"had\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"n't\": \"not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_aux_to_beginning(sentence):\n",
    "    \"\"\"Move auxiliary verb to the beginning of sentence (to form question).\n",
    "    Input one sentence only. Make sure it has aux verb. Make sure sentence starts with subject.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    aux = \"\"\n",
    "    for token in doc:\n",
    "        if \"AUX\" in token.pos_:\n",
    "            aux = token.text\n",
    "            break\n",
    "    assert len(aux)\n",
    "\n",
    "    if aux.strip() in auxiliary_shorthand:\n",
    "        new_aux = auxiliary_shorthand[aux]\n",
    "        new_sent = new_aux + ' ' + sentence.strip().replace(aux, '', 1).replace(sentence[0], sentence[0].lower(), 1)\n",
    "    else:\n",
    "        new_sent = aux + ' ' + sentence.strip().replace(aux, '', 1).replace(sentence[0], sentence[0].lower(), 1)\n",
    "\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can the person on the right  be her father, I can do it if not.\n"
     ]
    }
   ],
   "source": [
    "# move aux test run\n",
    "\n",
    "txt = \"The person on the right can be her father, I can do it if not.\"\n",
    "if has_aux(txt):\n",
    "    print(move_aux_to_beginning(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_verb(sentence):\n",
    "    \"\"\"Check if sentence has normal verb.\n",
    "    Input one sentence only.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if \"VERB\" in token.pos_:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_and_replace_aux_for_verb(sentence):\n",
    "    \"\"\"Put appropriate aux at beginnging of clause \n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    main_verb = None\n",
    "\n",
    "    for token in doc:\n",
    "        if \"VERB\" in token.pos_:\n",
    "            main_verb = token\n",
    "            break\n",
    "            \n",
    "    if not main_verb:\n",
    "        print(\"\\nCan't find main verb in\", sentence, '!\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    # check plurality\n",
    "    pointed_noun = main_verb.head\n",
    "    if pointed_noun.pos_.startswith(\"NOUN\"): # noun\n",
    "        plurality = pointed_noun.tag_ == \"NNS\"\n",
    "    elif pointed_noun.pos_.startswith(\"PRP\"):  # pronoun\n",
    "        plurality = (pointed_noun.lemma_ == \"we\") or (pointed_noun.lemma_ == \"you\") or (pointed_noun.lemma_ == \"they\")\n",
    "    else: # WORKING: for other cases where relative pronoun does not point to a noun, but a verb or a clause\n",
    "        plurality = True # temporary solution\n",
    "\n",
    "    # check tense\n",
    "    tense = \"present\" if main_verb.tag_ in ['VBZ', 'VBP'] else 'past'\n",
    "    # get aux\n",
    "    aux = {\n",
    "      \"present\": \"do\" if plurality else \"does\",\n",
    "      \"past\": \"did\",\n",
    "    }.get(tense)\n",
    "\n",
    "    # replace appropriate auxilary\n",
    "    new_sent = sentence.replace(main_verb.text, main_verb.lemma_, 1)\n",
    "    new_sent = aux + ' ' + new_sent\n",
    "\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did he hit down.\n"
     ]
    }
   ],
   "source": [
    "# move verb test run\n",
    "\n",
    "txt = \"he hit down.\"\n",
    "if has_verb(txt):\n",
    "    print(choose_and_replace_aux_for_verb(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ending_special_chars(sentence):\n",
    "    \"\"\"Remove ending non-word characters of a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be stripped\n",
    "\n",
    "    Returns:\n",
    "        str: stripped sentence \n",
    "    \"\"\"\n",
    "    sen_len = len(sentence)\n",
    "    for i in range(sen_len - 1, -1, -1):\n",
    "        char = sentence[i]\n",
    "\n",
    "        # check if the character is a punctuation mark\n",
    "        if char.isalnum():\n",
    "            return sentence\n",
    "        else:\n",
    "            sentence = sentence[:i]\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_special_chars(sentence):\n",
    "    \"\"\"Remove leading non-word characters of a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be stripped\n",
    "\n",
    "    Returns:\n",
    "        str: stripped sentence \n",
    "    \"\"\"\n",
    "\n",
    "    start_ind = 0\n",
    "    for i in range(0, len(sentence)):\n",
    "        char = sentence[i]\n",
    "        # check if the character is a punctuation mark\n",
    "        if char.isalnum():\n",
    "            break\n",
    "        else:\n",
    "            start_ind = i + 1\n",
    "\n",
    "    return sentence[start_ind: ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentence\n",
    "\n",
    "    Args:\n",
    "        text (str): text to be plited\n",
    "    Return: \n",
    "        list[str]: spit text\n",
    "    \"\"\"\n",
    "    sents = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\", text)\n",
    "    sents = [sent for sent in sents if len(sent.strip())]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paras(text, deli):\n",
    "    paras = text.split(deli)\n",
    "    paras = [para.strip() for para in paras if len(para.strip()) != 0]\n",
    "    return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_id(paras, text):\n",
    "    \"\"\"Find paragraph index of text\n",
    "\n",
    "    Args:\n",
    "        paras (list[str]): list of paragraphs\n",
    "        text (str): text to find\n",
    "    Return:\n",
    "        int: para id, -1 if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for p_i in range(len(paras)):\n",
    "        if paras[p_i].find(text.strip()) != -1:\n",
    "            return p_i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_source_sents(sents, text, span=2):\n",
    "    \"\"\"Find the sentences of which the text is a part. \n",
    "\n",
    "    Args:\n",
    "        sents (str): \n",
    "        text (str): \n",
    "        span (int): span of sentences to the left to return\n",
    "    \"\"\"\n",
    "    start_ind = 0\n",
    "    while start_ind < len(sents):\n",
    "        if text not in ''.join(sents[start_ind:]):\n",
    "            break\n",
    "        start_ind += 1\n",
    "    start_ind -= 1\n",
    "\n",
    "    end_ind = len(sents) # exclusive\n",
    "    while end_ind > 0:\n",
    "        if (text not in ''.join(sents[:end_ind])) or (end_ind <= start_ind):\n",
    "            break\n",
    "        end_ind -= 1\n",
    "    end_ind += 1\n",
    "\n",
    "    if (start_ind < 0) or (end_ind > len(sents)):\n",
    "        print(f\"\\nCan't find source sentences of {text}\\n\")\n",
    "        return None\n",
    "    \n",
    "    src_sents = ''.join(sents[max(start_ind - span, 0):end_ind])\n",
    "    return src_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subject_to_relative_clause(original_sent, clause):\n",
    "    \"\"\"Find and Prepend (with modifications) the subject of relative clause that does not contain one\n",
    "\n",
    "    Args:\n",
    "        original_sent (str): sentence from which the clause is extracted\n",
    "        clause (str): clause for which to find subject\n",
    "    Return:\n",
    "        str: subject\n",
    "    \"\"\"\n",
    "    doc = nlp(original_sent)\n",
    "    subj = \"\"\n",
    "    clause_start_ind = original_sent.find(clause)\n",
    "    for token in doc:\n",
    "        if (len(subj)):\n",
    "            break\n",
    "        if (token.dep_ in ['relcl', 'acl']) and (token.idx >= clause_start_ind) and (token.idx < (clause_start_ind + len(clause))): # relative clause is noun modifier\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if token.head.i >= chunk.start and token.head.i < chunk.end:\n",
    "                    subj = chunk.text\n",
    "                    break\n",
    "        \n",
    "        # WORKING: relative clause is verb/adverb/adjective modifier, not sure if it's necessary tho\n",
    "        # 'cause adverbial clauses are often in relations that do not require unshortening of clause\n",
    "        if (token.dep_ in ['advcl', 'ccomp']) and (token.idx >= clause_start_ind) and (token.idx < (clause_start_ind + len(clause))): \n",
    "            print(\"\\nFound Adverbial Clause\\n\")\n",
    "            return None\n",
    "            # for chunk in doc.noun_chunks:\n",
    "            #     if token.head.i >= chunk.start and token.head.i < chunk.end:\n",
    "            #         subj = chunk.text\n",
    "            #         break\n",
    "                    \n",
    "    if not len(subj): # not found subject\n",
    "        print(\"\\nCan't find subject of\", original_sent, \"!\\n\")\n",
    "        return None         \n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"nsubj\") and (token.text.lower() in RELATIVE_PRONOUNS):\n",
    "            new_clause = clause.replace(token.text, subj) # contains more nuances (where -> in + N, which -> N, who -> N)\n",
    "            new_sent = original_sent.replace(clause.strip(), new_clause.strip(), 1)\n",
    "            return new_sent, new_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found Adverbial Clause\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add subject test run\n",
    "txt =\"For instance, on the MNLI task, the BERT_base accuracy improves by 1.0% when that trains on 1M steps (128,000 words batch size)\"\n",
    "txt_c = \"that trains on 1M steps (128,000 words batch size)\"\n",
    "add_subject_to_relative_clause(txt, txt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_conjunction(original_sent, text):\n",
    "    \"\"\"Remove leading conjunctions from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PUNCT', 'SYM']:\n",
    "            continue\n",
    "        if \"CONJ\" not in token.pos_:\n",
    "            return (original_sent, text)\n",
    "        conj = token.text\n",
    "        break\n",
    "\n",
    "    new_text = text.replace(conj.strip(), '', 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "\n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_adverb(original_sent, text):\n",
    "    \"\"\"Remove leading adverb from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in ['PUNCT', 'SYM']:\n",
    "            continue\n",
    "        if token.pos_ != 'ADV':\n",
    "            return (original_sent, text)\n",
    "        adv = token.text\n",
    "        break\n",
    "\n",
    "    new_text = text.replace(adv.strip(), '', 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "\n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOURSE_MARKERS = [\n",
    "  'accordingly', 'additionally', 'afterward', 'also',\n",
    "  'although', 'as a final point', 'as a result', 'assuming that', 'because', 'this is because'\n",
    "  'besides', 'but also', 'compared to', 'consequently', 'conversely', 'despite',\n",
    "  'even though', 'finally', 'first', 'firstly', 'for example', 'for instance',\n",
    "  'for the purpose of', 'furthermore', 'hence', 'however', 'if', 'importantly',\n",
    "  'in addition', 'in case', 'in conclusion', 'in contrast', 'by contrast', 'in fact',\n",
    "  'in order to', 'in other words', 'in the event that', 'in the same way',\n",
    "  'indeed', 'just as', 'lastly', 'likewise', 'moreover', 'namely',\n",
    "  'nevertheless', 'next', 'nonetheless', 'not only', 'of course', 'on condition that',\n",
    "  'on the contrary', 'on the one hand', 'on the other hand', 'otherwise', 'plus', 'previously',\n",
    "  'provided that', 'second', 'secondly', 'similarly', 'similarly to', 'since',\n",
    "  'so', 'so that', 'specifically', 'subsequently', 'such as', 'that is to say', 'that is'\n",
    "  'then', 'therefore', 'third', 'thirdly', 'thus', 'to conclude', 'to illustrate',\n",
    "  'to put it differently', 'to sum up', 'ultimately', 'undoubtedly', 'unless',\n",
    "  'while', 'with the aim of', 'yet', 'then', 'and then'\n",
    "  'as a consequence', 'as a result',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_leading_discourse_marker(original_sent, text):\n",
    "    \"\"\"Remove leading discourse markers from text, return intact if cannot find any\n",
    "\n",
    "    Args:\n",
    "        original_sent (_type_): _description_\n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    discourse_marker = None\n",
    "    min_pos = len(text)\n",
    "    for dm in DISCOURSE_MARKERS:\n",
    "        find_result = text.lower().find(dm)\n",
    "        if find_result > -1:\n",
    "            if find_result < min_pos:\n",
    "                min_pos = find_result\n",
    "                discourse_marker = dm\n",
    "            if find_result == min_pos and len(dm) > len(discourse_marker):\n",
    "                discourse_marker = dm\n",
    "    \n",
    "    # check if found marker stand at the beginning of text\n",
    "        \n",
    "    if discourse_marker is not None:\n",
    "        for i in range(0, min_pos):\n",
    "            if text[i].isalnum() or text[min_pos + len(discourse_marker)].isalnum():\n",
    "                discourse_marker = None\n",
    "                break\n",
    "            \n",
    "    if not discourse_marker:\n",
    "        return (original_sent, text)\n",
    "\n",
    "    pattern = re.compile(discourse_marker, re.IGNORECASE)\n",
    "\n",
    "    new_text = pattern.sub(\"\", text, 1)\n",
    "    new_sent = original_sent.replace(text, new_text)\n",
    "    \n",
    "    return (new_sent, new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be integrated\n",
    "\n",
    "def replace_substr(text, substring, start_ind, end_ind):\n",
    "  \"\"\"Replace part of text with specified index [start_ind, end_ind) with substring\n",
    "  \"\"\"\n",
    "  try:\n",
    "    assert(len(substring)  == end_ind - start_ind)\n",
    "  except:\n",
    "    print('Text:', text, '--', sep='')\n",
    "    print('Substring:', substring, '--', sep='')\n",
    "\n",
    "  text_l = list(text)\n",
    "  text_l[start_ind:end_ind] = list(substring)\n",
    "\n",
    "  return ''.join(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_ref(index, clusters):\n",
    "    \"\"\"Check if current index is in one of the references\n",
    "    \n",
    "    Args:\n",
    "        index (int): index to check\n",
    "        clusters (list(list(tuple))): list of cluster, each cluster containing a list of tuple correponding to indices of the references\n",
    "    Return:\n",
    "        tuple (verdict, (start, end), (ref_token_start, ref_token_end)): -1 both index if not found, ref_token is token to relace\n",
    "    \"\"\"\n",
    "    for cluster in clusters:\n",
    "        for token in cluster:\n",
    "            if cluster.index(token) == 0:\n",
    "                continue\n",
    "            if index >= token[0] and index < token[1]:\n",
    "                ref_token = (cluster[0][0], cluster[0][1])\n",
    "                return True, token, ref_token\n",
    "            \n",
    "    return False, (-1, -1), (-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_clause_type(clause):\n",
    "    \"\"\"Check which type of relative clause \"clause\" is: \n",
    "    - which + V + clause (present subject is sufficient for being clause)\n",
    "    - which + V + (not clause)\n",
    "\n",
    "    Args:\n",
    "        sent (str): \n",
    "        clause (str): \n",
    "    Return: 0 or 1, -1 if not relative clause expected (not start with which + V), then it could be an adverbial clause\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(clause.strip())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        token = doc[i]\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" not in token.pos_: \n",
    "                return -1\n",
    "            else:\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    i += 1 \n",
    "    while i < len(doc):\n",
    "        token = doc[i]\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"VERB\" not in token.pos_ and \"AUX\" not in token.pos_: \n",
    "                return -1        \n",
    "            else:\n",
    "                break\n",
    "        i += 1\n",
    "    \n",
    "    # if reach here, is expected relative clause type (which + V)\n",
    "    i += 1\n",
    "    t_i = i # use to this to check subject and not modify i\n",
    "    while t_i < len(doc):\n",
    "        token = doc[t_i]\n",
    "        if 'nsubj' in token.dep_:\n",
    "            return 0\n",
    "        t_i += 1\n",
    "\n",
    "    return 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:27:41 - INFO - \t missing_keys: []\n",
      "05/28/2024 18:27:41 - INFO - \t unexpected_keys: []\n",
      "05/28/2024 18:27:41 - INFO - \t mismatched_keys: []\n",
      "05/28/2024 18:27:41 - INFO - \t error_msgs: []\n",
      "05/28/2024 18:27:41 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n"
     ]
    }
   ],
   "source": [
    "# to be integrated\n",
    "from fastcoref import FCoref, LingMessCoref\n",
    "if 'coref_resolver' not in locals(): # prevent accidental re-run of cell\n",
    "    coref_resolver = LingMessCoref(device='cuda:0')\n",
    "\n",
    "def resolve_coreference(original_sent, text):\n",
    "    \"\"\"Perfrom coreference resolution and replace corresponding text.\n",
    "\n",
    "    Args:\n",
    "        original_sent (str): Sentence the text was derived froms\n",
    "        text (str): Target text\n",
    "    \"\"\"\n",
    "\n",
    "    text_ind = original_sent.find(text) # starting index of text in original text\n",
    "    coref_preds = coref_resolver.predict(texts=[original_sent])\n",
    "    coref_clusters = coref_preds[0].get_clusters(as_strings=False)\n",
    "    new_sent = []\n",
    "    new_text = []\n",
    "\n",
    "    # interate string left to right while appending current char to a new list\n",
    "    # if current index in one of the token in one of the clusters, add the replacement to the list, keep the text intact, to know what index are at\n",
    "    i = 0\n",
    "\n",
    "    # if referred word is a verb, use have to notice and discard the sentence.\n",
    "    while i < len(original_sent):\n",
    "        find_result = is_in_ref(i, coref_clusters)\n",
    "        if find_result[0]:\n",
    "            token = find_result[1]\n",
    "            token_ref = find_result[2]\n",
    "            new_sent.append(original_sent[token_ref[0]:token_ref[1]])\n",
    "            if (i >= text_ind and i < text_ind + len(text)):\n",
    "                if (text_ind <= token[0] and token[1] <= text_ind + len(text)):\n",
    "                    new_text.append(original_sent[token_ref[0]:token_ref[1]])\n",
    "                else:\n",
    "                    new_text.append(original_sent[i:text_ind + len(text)])\n",
    "            i = token[1]\n",
    "        else:\n",
    "            new_sent.append(original_sent[i])\n",
    "            if i >= text_ind and i < text_ind + len(text):\n",
    "                new_text.append(original_sent[i])\n",
    "            i += 1\n",
    "\n",
    "    return ''.join(new_sent), ''.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:27:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  1.40 examples/s]\n",
      "05/28/2024 18:27:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CorefResult(text=\"Transformers process input sequences in parallel, ...\", clusters=[['Transformers', 'them']])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coref test run    \n",
    "txt = \"Transformers process input sequences in parallel, making the them highly efficient for training and inference\"\n",
    "# sents = split_into_sentences(original_text)\n",
    "# src = find_source_sents(sents, txt, 5)\n",
    "# resolve_coreference(src, txt)\n",
    "coref_preds = coref_resolver.predict(texts=[txt])\n",
    "coref_clusters = coref_preds[0].get_clusters(as_strings=False)\n",
    "coref_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(original_text, text, retain_dm=False, retain_conj=False, retain_adv=False, add_subject_to_rel_clause=False):\n",
    "    \"\"\"Tranform raw text into a full clause to be fed to the question generation pipeline\n",
    "\n",
    "    Args:\n",
    "        text (str): raw text\n",
    "    Return:\n",
    "        (str): full clause from text\n",
    "    \"\"\"\n",
    "    sents = split_into_sentences(original_text)\n",
    "\n",
    "    # coreferen ce resolution\n",
    "    src_3_sents = find_source_sents(sents, text, 3)\n",
    "    src_3_sents, text = resolve_coreference(src_3_sents, text)\n",
    "    src_sent = find_source_sents(split_into_sentences(src_3_sents), text, 0)\n",
    "\n",
    "    # removal of irrelavent components\n",
    "    if not retain_dm:\n",
    "        src_sent, text = remove_leading_discourse_marker(src_sent, text)    \n",
    "    if not retain_conj:\n",
    "        src_sent, text = remove_leading_conjunction(src_sent, text)\n",
    "    if not retain_adv: \n",
    "        src_sent, text = remove_leading_adverb(src_sent, text)\n",
    "    src_sent = remove_leading_special_chars(src_sent)\n",
    "    text = remove_leading_special_chars(text)\n",
    "    # src_3_sents = remove_ending_special_chars(src_3_sents)\n",
    "    # text = remove_ending_special_chars(text)\n",
    "\n",
    "    # handle single relative clause\n",
    "    if is_one_clause(text, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(text)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            if cl_type == 2:\n",
    "                print(\"\\nText here: \", src_sent, text)\n",
    "                src_sent, text = unshorten_relative_clause(src_sent, text)\n",
    "            if add_subject_to_rel_clause:\n",
    "                # WORKING: temporary solution before fixing add_subject_to_relative_clause()\n",
    "                if add_subject_to_relative_clause(src_sent, text):\n",
    "                    src_sent, text = add_subject_to_relative_clause(src_sent, text)\n",
    "\n",
    "    return src_sent, text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def postprocess_question(ques):\n",
    "    \"\"\"Clean up the question after being generated.\n",
    "    Pipeline: Clean double spaces, clean extra punctuations,\\ \n",
    "    add extra space before question mark (for incomplete question model to run well).\n",
    "\n",
    "    Args:\n",
    "        ques (str): generated question\n",
    "    Returns:\n",
    "        str: new question\n",
    "    \"\"\"\n",
    "\n",
    "    puncts_to_remove = ['.', ',', '!']\n",
    "\n",
    "    ques_c = list(ques)\n",
    "    for i in range(len(ques_c) - 1, 0, -1):\n",
    "        if ques_c[i].isalnum():\n",
    "            break\n",
    "\n",
    "        if ques_c[i] in puncts_to_remove:\n",
    "            ques_c.pop(i)\n",
    "    \n",
    "    for i in range(len(ques_c) - 1, 0, -1):\n",
    "        if ques_c[i] == '?':\n",
    "            ques_c.insert(i, ' ')\n",
    "            break\n",
    "\n",
    "    new_ques = ''.join(ques_c)\n",
    "    new_ques = re.sub(r'\\s+', ' ', new_ques)\n",
    "    return new_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_answer(ans):\n",
    "    \"\"\"Clean up the answer after being generated.\n",
    "    Pipeline: Clean double spaces, clean extra punctuations, capitalize first word.\n",
    "\n",
    "    Args:\n",
    "        ans (str): generated answer\n",
    "    Returns:\n",
    "        str: new answer\n",
    "    \"\"\"\n",
    "\n",
    "    puncts_to_remove = ['.', ',', '!']\n",
    "\n",
    "    ans_c = list(ans)\n",
    "    has_punct = False\n",
    "    for i in range(len(ans_c) - 1, 0, -1):\n",
    "        if ans_c[i].isalnum():\n",
    "            break\n",
    "\n",
    "        if ans_c[i] in puncts_to_remove:\n",
    "            if not has_punct:\n",
    "                has_punct = True\n",
    "            else:\n",
    "                ans_c.pop(i)\n",
    "\n",
    "    for i in range(len(ans_c)):\n",
    "        if len(ans_c[i].strip()) == 0:\n",
    "            continue\n",
    "        ans_c[i] = ans_c[i].upper()\n",
    "        ans_c = ans_c[i:]\n",
    "        break\n",
    "\n",
    "    new_ans = ''.join(ans_c)\n",
    "    new_ans = re.sub(r'\\s+', ' ', new_ans)\n",
    "    return new_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING: \n",
    "- Handle non-clause (maybe just keep all, discard \"which + V\" maybe)\n",
    "- Handle missing information (two EDUs still don't make a sentence) -> maybe segment longer texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cause_question_type_0(nucleus, satellite): # WORKING: nucleus cause satellite (but now model interpret both directions, needs fixing)\n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting:exactly the same as type_1\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def cause_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which caused the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def cause_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on CAUSE relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(satellite):\n",
    "        new_sate = move_aux_to_beginning(satellite)\n",
    "    else: \n",
    "        new_sate = choose_and_replace_aux_for_verb(satellite)\n",
    "    question = \"Why \" + new_sate.strip() + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "                                             \n",
    "def generate_cause_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    if is_one_clause(satellite, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(satellite)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(satellite)\n",
    "            if rel_type == 0:\n",
    "                return cause_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return cause_question_type_1(nucleus, satellite)\n",
    "    else:\n",
    "        return (\"\", \"\")\n",
    "    return cause_question_type_2(nucleus, satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast relation: ask what's different between two subjects.\n",
    "# retain discourse markers\n",
    "    \n",
    "def make_contrast_question_with_two_clauses(nucleus, satellite):\n",
    "    n_subj = get_subj(nucleus)\n",
    "    s_subj = get_subj(satellite)\n",
    "   \n",
    "    if (n_subj is None) or (s_subj is None):\n",
    "        print(\"\\nCan't find subject!\\n\")\n",
    "        return (\"\", \"\")\n",
    "     \n",
    "    if n_subj.strip().lower() == s_subj.strip().lower():\n",
    "        print(\"\\nSame subjects for nucleus and satellite!\\n\")\n",
    "        return (\"\", \"\")\n",
    "    \n",
    "    question = \"What is the difference between \" + n_subj + \" and \" + s_subj + '?'\n",
    "    answer = nucleus.strip() + ' ' + satellite.strip()\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_contrast_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(nucleus, count_relative_clause=False) and is_one_clause(satellite, count_relative_clause=False):\n",
    "        return make_contrast_question_with_two_clauses(nucleus, satellite)\n",
    "    return (\"\", \"\") # more than 1 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition relation\n",
    "\n",
    "def condition_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting:exactly the same as type_1\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What condition\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def condition_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which conditiond the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(satellite)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = satellite.replace(rel_pro.strip(), \"What condition\", 1) + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def condition_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on condition relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(satellite):\n",
    "        new_sate = move_aux_to_beginning(satellite)\n",
    "    else: \n",
    "        new_sate = choose_and_replace_aux_for_verb(satellite)\n",
    "    question = \"In what condition \" + new_sate.strip() + '?'\n",
    "    answer = nucleus.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "                                             \n",
    "def generate_condition_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(satellite, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(satellite)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(satellite)\n",
    "            if rel_type == 0:\n",
    "                return condition_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return condition_question_type_1(nucleus, satellite)\n",
    "        else: # 1 clause, not relative clause \n",
    "            return condition_question_type_2(nucleus, satellite)\n",
    "    else:\n",
    "        return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enablement relation\n",
    "# difference to manner-means: enablement encapsulate manner-means, as all means can \"enable\" the goal,\n",
    "# but enablement also contains situational aid, an event lead (may not intentionally) to another event\n",
    "    \n",
    "# enablement relation\n",
    "\n",
    "def enablement_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting: exactly the same as type_1\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def enablement_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which enablementd the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def enablement_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(nucleus):\n",
    "        new_nuc = move_aux_to_beginning(nucleus)\n",
    "    else: \n",
    "        new_nuc = choose_and_replace_aux_for_verb(nucleus)\n",
    "    question = \"How \" + new_nuc.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def enablement_question_type_3(nucleus, satellite): \n",
    "    \"\"\"Make question based on enablement relationship\n",
    "    Type 2: satellite (result) is: relative clause but not start with relative pronoun (most probably adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    question = \"What can be done \" + nucleus.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_enablement_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "\n",
    "    if is_one_clause(nucleus, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(nucleus)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(nucleus)\n",
    "            if rel_type == 0:\n",
    "                return enablement_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return enablement_question_type_1(nucleus, satellite)\n",
    "        else:\n",
    "            if is_dependent_clause(nucleus_pair[0], nucleus):\n",
    "                return enablement_question_type_3(nucleus, satellite)\n",
    "            return enablement_question_type_2(nucleus, satellite)\n",
    "    return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manner-Means relation\n",
    "    \n",
    "# manner-means relation\n",
    "# difference to manner-means: manner-means encapsulate manner-means, as all means can \"enable\" the goal,\n",
    "# but manner-means also contains situational aid, an event lead (may not intentionally) to another event\n",
    "    \n",
    "# manner-means relation\n",
    "\n",
    "def means_question_type_0(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 0: satellite (result) is: relative clause: which + verb + clause (e.g. which made him happy.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    # experimenting: exactly the same as type_1\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What method \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "\n",
    "def means_question_type_1(nucleus, satellite):\n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 1: satellite (result) is: relative clause: which + verb + (not clause) (e.g. which caused the noise.)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "    doc = nlp(nucleus)\n",
    "    rel_pro = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            if \"PRON\" in token.pos_:\n",
    "                rel_pro = token.text\n",
    "                break\n",
    "        \n",
    "    assert len(rel_pro) > 0\n",
    "    question = nucleus.replace(rel_pro.strip(), \"What method \", 1) + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def means_question_type_2(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 2: satellite (result) is: full clause (not relative clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    if has_aux(nucleus):\n",
    "        new_nuc = move_aux_to_beginning(nucleus)\n",
    "    else: \n",
    "        new_nuc = choose_and_replace_aux_for_verb(nucleus)\n",
    "    question = \"By what method \" + new_nuc.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def means_question_type_3(nucleus, satellite): \n",
    "    \"\"\"Make question based on manner-means relationship\n",
    "    Type 2: satellite (result) is: relative clause but not start with relative pronoun (most probably adverbial clause)\n",
    "\n",
    "    Args:\n",
    "        nucleus (str): nucleus stripped of ending punctuation and spaces \n",
    "        satellite (str): satellite stripped of ending punctuation and spaces \n",
    "    Returns:p \n",
    "        tuple(ques, ans)\n",
    "    \"\"\"\n",
    "\n",
    "    question = \"What strategy can be employed \" + nucleus.strip() + '?'\n",
    "    answer = satellite.strip() + '.'\n",
    "\n",
    "    return (question, answer)\n",
    "\n",
    "def generate_means_question(nucleus_pair, satellite_pair):\n",
    "    nucleus = nucleus_pair[1]\n",
    "    satellite = satellite_pair[1]\n",
    "    \n",
    "    if is_one_clause(nucleus, count_relative_clause=False):\n",
    "        cl_type = check_relative_clause(nucleus)\n",
    "        if cl_type != 0: # is relative clause\n",
    "            rel_type = check_relative_clause_type(nucleus)\n",
    "            if rel_type == 0:\n",
    "                return means_question_type_0(nucleus, satellite)\n",
    "            elif rel_type == 1:\n",
    "                return means_question_type_1(nucleus, satellite)\n",
    "        else:\n",
    "            if is_dependent_clause(nucleus_pair[0], nucleus):\n",
    "                return means_question_type_3(nucleus, satellite)\n",
    "            return means_question_type_2(nucleus, satellite)\n",
    "    return (\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WORKING: for questions based on BACKGROUND relation, haven't adapted to new preprocessing pipeline, may not be suitable for question generation\n",
    "\n",
    "# def make_background_question_with_two_clauses(nucleus, satellite): \n",
    "#     question = \"Under what circumstance that \" + nucleus.strip() + '?'\n",
    "#     answer = satellite\n",
    "\n",
    "#     return (question, answer)\n",
    "\n",
    "# def generate_background_question(original_text, nucleus, satellite):\n",
    "#     nucleus = preprocessing_pipeline(original_text, nucleus, retain_dm=False, retain_conj=True, retain_adv=True) # NOTE: may not want to retain dm here, 'cause need only the dm between nuc and sate\n",
    "#     satellite = preprocessing_pipeline(original_text, satellite, retain_dm=False, retain_conj=True, retain_adv=True)\n",
    "    \n",
    "#     if nucleus is None or satellite is None:\n",
    "#         print(\"\\nCan't process nucleus and satellite!\\n\")\n",
    "#         return (\"\", \"\")\n",
    "    \n",
    "#     if is_one_clause(nucleus) and is_one_clause(satellite):\n",
    "#         return make_background_question_with_two_clauses(nucleus, satellite)\n",
    "#     else:\n",
    "#         return make_background_question_with_two_clauses(nucleus, satellite)\n",
    "#         return (\"\", \"\") # other cases, not case with two clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test run for Background\n",
    "# rel = 'Background'\n",
    "# for trip in df[df['new_relation'] == rel].iterrows():\n",
    "#     with open(output_path, 'a') as f:\n",
    "#         f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "\n",
    "#         f.write(\"\\nOriginal nucleus: \" + trip[1]['nucleus'] + '\\n')\n",
    "#         f.write(\"Original satellite: \" + trip[1]['satellite'] + '\\n')\n",
    "#         f.write('\\n')\n",
    "        \n",
    "#         ques, ans = generate_background_question(original_text, trip[1]['nucleus'], trip[1]['satellite'])\n",
    "#         if not ques.strip() or not ans.strip():\n",
    "#             continue\n",
    "        \n",
    "#         f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "#         f.write(\"Answer: \" + ans + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Question Generator (for random testings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_one_clause(\"This characteristic allows the model to learn the context of a word \", count_relative_clause=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:27:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.05 examples/s]\n",
      "05/28/2024 18:27:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
      "05/28/2024 18:27:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 138.28 examples/s]\n",
      "05/28/2024 18:27:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What condition is the condition to overfitting.?\n",
      "Answer: The model may learn too much about the dataset,.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# miscellaneous test run\n",
    "nuc = \"\"\"The model may learn too much about the dataset, \"\"\"\n",
    "sate = \"which is the condition to overfitting.\" \n",
    "org = nuc + sate\n",
    "\n",
    "nucleus_pair = preprocessing_pipeline(org, nuc, retain_dm=True, retain_adv=True, retain_conj=True)\n",
    "satellite_pair = preprocessing_pipeline(org, sate)\n",
    "\n",
    "if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "    print(\"Can't process nucleus and satellite!\\n\")\n",
    "\n",
    "ques, ans = generate_condition_question(nucleus_pair, satellite_pair)\n",
    "if not ques.strip() or not ans.strip():\n",
    "    print(\"Can't generate questions!\\n\")\n",
    "        \n",
    "print(\"\\nQuestion: \" + ques)\n",
    "print(\"Answer: \" + ans + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Incomplete Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INC_SOURCE_LENGTH = 750\n",
    "MAX_INC_TARGET_LENGTH = 64\n",
    "INC_PREFIX = \"complete incomplete question:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "inc_model_path = \"models/t5_base_incomplete_questions/checkpoint-21000\"\n",
    "inc_tokenizer = T5Tokenizer.from_pretrained(inc_model_path)\n",
    "inc_model = T5ForConditionalGeneration.from_pretrained(inc_model_path)\n",
    "\n",
    "inc_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_question(context, question, answer):\n",
    "    \"\"\"Complete question if needed, needs globally available model and tokenizer (\"inc_model\" and \"inc_tokenizer\")\n",
    "\n",
    "    Args:\n",
    "        context (str): \n",
    "        question (str): \n",
    "        answer (str): \n",
    "    Return:\n",
    "        str: new question\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = inc_tokenizer(text=f\"{INC_PREFIX} context: {context}, incomplete question: {question}, answer: {answer}\",\n",
    "                        max_length=MAX_INC_SOURCE_LENGTH,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt').to('cuda')\n",
    "        \n",
    "    output_sequences = inc_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=MAX_INC_TARGET_LENGTH\n",
    "    )\n",
    "\n",
    "    output = inc_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "How can organizations avoid wasting budget or displeasing customers?\n"
     ]
    }
   ],
   "source": [
    "# test run\n",
    "question = \"How can avoid wasting budget or displeasing customers?\"\n",
    "answer = \"Organizations should act on the answers only when there is high confidence in the output.\"\n",
    "\n",
    "new_question = complete_question(raw_original_text, question, answer)\n",
    "print(question.strip() != new_question)\n",
    "print(new_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distractors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIS_SOURCE_LENGTH = 600\n",
    "MAX_DIS_TARGET_LENGTH = 256\n",
    "PREFIX = \"make 3 distractors:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import from local dir\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "dis_model_path = \"models/t5_base_distractors_with_synthesized_dataset_custom_loss_sep_token\"\n",
    "\n",
    "dis_tokenizer = AutoTokenizer.from_pretrained(dis_model_path)\n",
    "dis_model = T5ForConditionalGeneration.from_pretrained(dis_model_path)\n",
    "dis_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def postprocess_distractor(dis):\n",
    "    \"\"\"Post process generated distractors.\n",
    "    Pipeline: Remove model's tags, remove redundant spaces.\n",
    "\n",
    "    Args:\n",
    "        dis (str): generated distractor\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned distractor\n",
    "    \"\"\"\n",
    "\n",
    "    new_dis = dis\n",
    "    special_tags = ['</s>', '<unk>', '<pad>']\n",
    "    for tag in special_tags:\n",
    "        new_dis = new_dis.replace(tag, '') \n",
    "\n",
    "    new_dis = re.sub(r'\\s+', ' ', new_dis)\n",
    "\n",
    "    new_dis_c = list(new_dis)\n",
    "    for i in range(len(new_dis_c)):\n",
    "        if len(new_dis_c[i].strip()) == 0:\n",
    "            continue\n",
    "        new_dis_c[i] = new_dis_c[i].upper()\n",
    "        new_dis_c = new_dis_c[i:]\n",
    "        break\n",
    "    return ''.join(new_dis_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def generate_3_distractors(context, question, answer):\n",
    "    \"\"\"Generate 3 distractors, needs globally available model and tokenizer (\"dis_model\" and \"dis_tokenizer\")\n",
    "\n",
    "    Args:\n",
    "        context (str): \n",
    "        question (str): \n",
    "        answer (str): \n",
    "    Return:\n",
    "        Tuple(dis1, dis2, dis3)\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = dis_tokenizer(text=f\"{PREFIX} context: {context}, question: {question}, answer: {answer}\", \n",
    "                        max_length=MAX_DIS_SOURCE_LENGTH,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt').to('cuda')\n",
    "        \n",
    "    output_sequences = dis_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=MAX_DIS_TARGET_LENGTH)[0]\n",
    "    \n",
    "    # find sep tokens, sep tokens separate among distractors\n",
    "    output_sequences = [token for token in output_sequences if token not in dis_tokenizer.convert_tokens_to_ids(['<pad>', '</s>'])]\n",
    "    sep_ids = [i for i, v in enumerate(output_sequences) if v == dis_tokenizer.convert_tokens_to_ids(['<sep>'])[0]]\n",
    "    try:\n",
    "        assert len(sep_ids) == 2\n",
    "    except:\n",
    "        print(\"Not enough seperation tokens were found!\")\n",
    "    \n",
    "    # remove other special tokens\n",
    "    dis1 = dis_tokenizer.batch_decode([output_sequences[:sep_ids[0]]])[0]\n",
    "    dis2 = dis_tokenizer.batch_decode([output_sequences[sep_ids[0] + 1:sep_ids[1]]])[0]\n",
    "    dis3 = dis_tokenizer.batch_decode([output_sequences[sep_ids[1] + 1:]])[0]\n",
    "    \n",
    "    return (dis1, dis2, dis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distractor 1: To translate human speech into a written format.\n",
      "Distractor 2: To improve the efficiency of customer service.\n",
      "Distractor 3: To improve the speed and precision of speech recognition.\n"
     ]
    }
   ],
   "source": [
    "question = \"Why do many mobile devices incorporate speech recognition into many mobile devices systems?\"\n",
    "answer = \"To conduct voice search-e.g. Siri-or improve accessibility for texting.\"\n",
    "\n",
    "dis1, dis2, dis3 = generate_3_distractors(raw_original_text, question, answer)\n",
    "\n",
    "print(\"\\nDistractor 1: \" + dis1)\n",
    "print(\"Distractor 2: \" + dis2)\n",
    "print(\"Distractor 3: \" + dis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "samples = pd.DataFrame(columns=['context', 'question', 'answer', 'dis1', 'dis2', 'dis3'])\n",
    "\n",
    "context = \"\"\"Depending on your budget, need for speed and precision required, each algorithm type—supervised, unsupervised, semi-supervised, or reinforcement—has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors. Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms—which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day:\n",
    "Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search—e.g. Siri—or improve accessibility for texting.\n",
    "Customer service:  Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants.\n",
    "\"\"\"\n",
    "questions = [\n",
    "            \"Why do many mobile devices incorporate speech recognition into their systems?\",\n",
    "            \"What method is used by many mobile devices to conduct voice search—e.g. Siri—or improve accessibility for texting\",\n",
    "            \"What can be the cause of error proneness of machine learning algorithms?\",\n",
    "            \"Why does the analysis of patterns and trends require little human intervention?\",\n",
    "            \"How can machine learning algorithms improve?\",\n",
    "            \"By what method can organizations avoid wasting budget or displeasing customers?\",\n",
    "            \"Why can customers and users enjoy a more personalized experience?\",\n",
    "            \"What method is used by speech recognition to translates human speech into a written format?\"\n",
    "            ]\n",
    "\n",
    "answers = [\n",
    "            \"To conduct voice search—e.g. Siri—or improve accessibility for texting.\",\n",
    "            \"They incorporate speech recognition into their systems\",\n",
    "            \"The low quality of input data.\",\n",
    "            \"Because users can just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.\",\n",
    "            \"With more input data over time\",\n",
    "            \"They should act on the answers only when there is high confidence in the output.\",\n",
    "            \"As the model learns more with every experience with that person.\",\n",
    "            \"Natural language processing.\"\n",
    "            ]\n",
    "           \n",
    "for ques, ans in zip(questions, answers):\n",
    "    dis1, dis2, dis3 = generate_3_distractors(context, ques, ans)\n",
    "    datapoint = {'context':[context], 'question':[ques], 'answer':[ans], 'dis1':[dis1], 'dis2':[dis2], 'dis3':[dis3]}\n",
    "    samples = pd.concat([samples, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Version:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>dis1</th>\n",
       "      <th>dis2</th>\n",
       "      <th>dis3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do many mobile devices incorporate speech recognition into their systems?</td>\n",
       "      <td>To conduct voice search—e.g. Siri—or improve accessibility for texting.</td>\n",
       "      <td>To translate human speech into a written format.</td>\n",
       "      <td>To identify patterns and trends in massive volumes of data.</td>\n",
       "      <td>To use decision trees to classify data into categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What method is used by many mobile devices to conduct voice search—e.g. Siri—or improve accessibility for texting</td>\n",
       "      <td>They incorporate speech recognition into their systems</td>\n",
       "      <td>They use natural language processing (NLP) to translate human speech into a written format</td>\n",
       "      <td>They use decision trees to identify patterns and trends in massive volumes of data</td>\n",
       "      <td>They can assemble and refine their own algorithms with more data input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can be the cause of error proneness of machine learning algorithms?</td>\n",
       "      <td>The low quality of input data.</td>\n",
       "      <td>The large sample size.</td>\n",
       "      <td>The lack of resources and a robust system.</td>\n",
       "      <td>The lack of confidence in the output.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why does the analysis of patterns and trends require little human intervention?</td>\n",
       "      <td>Because users can just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.</td>\n",
       "      <td>Because decision trees are easier to validate and audit than other decision predictors.</td>\n",
       "      <td>Because decision trees can be more unstable than other decision predictors.</td>\n",
       "      <td>Because the model learns more with every experience with that person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can machine learning algorithms improve?</td>\n",
       "      <td>With more input data over time</td>\n",
       "      <td>With little human intervention</td>\n",
       "      <td>With a small sample of data</td>\n",
       "      <td>With a robust and robust system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By what method can organizations avoid wasting budget or displeasing customers?</td>\n",
       "      <td>They should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>They should use decision trees to predict numerical values.</td>\n",
       "      <td>They should use decision trees to classify data into categories.</td>\n",
       "      <td>They should use decision trees to assemble and refine their own algorithms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why can customers and users enjoy a more personalized experience?</td>\n",
       "      <td>As the model learns more with every experience with that person.</td>\n",
       "      <td>As the model can predict numerical values and classify data into categories.</td>\n",
       "      <td>As the decision tree algorithms are easier to validate and audit than a neural network.</td>\n",
       "      <td>As the decision tree algorithms are more unstable than other decision predictors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What method is used by speech recognition to translates human speech into a written format?</td>\n",
       "      <td>Natural language processing.</td>\n",
       "      <td>Automatic speech recognition (ASR).</td>\n",
       "      <td>Decision tree algorithms.</td>\n",
       "      <td>Decision trees.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            question  \\\n",
       "0                                      Why do many mobile devices incorporate speech recognition into their systems?   \n",
       "1  What method is used by many mobile devices to conduct voice search—e.g. Siri—or improve accessibility for texting   \n",
       "2                                           What can be the cause of error proneness of machine learning algorithms?   \n",
       "3                                    Why does the analysis of patterns and trends require little human intervention?   \n",
       "4                                                                       How can machine learning algorithms improve?   \n",
       "5                                    By what method can organizations avoid wasting budget or displeasing customers?   \n",
       "6                                                  Why can customers and users enjoy a more personalized experience?   \n",
       "7                        What method is used by speech recognition to translates human speech into a written format?   \n",
       "\n",
       "                                                                                                                               answer  \\\n",
       "0                                                             To conduct voice search—e.g. Siri—or improve accessibility for texting.   \n",
       "1                                                                              They incorporate speech recognition into their systems   \n",
       "2                                                                                                      The low quality of input data.   \n",
       "3  Because users can just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.   \n",
       "4                                                                                                      With more input data over time   \n",
       "5                                                    They should act on the answers only when there is high confidence in the output.   \n",
       "6                                                                    As the model learns more with every experience with that person.   \n",
       "7                                                                                                        Natural language processing.   \n",
       "\n",
       "                                                                                         dis1  \\\n",
       "0                                            To translate human speech into a written format.   \n",
       "1  They use natural language processing (NLP) to translate human speech into a written format   \n",
       "2                                                                      The large sample size.   \n",
       "3     Because decision trees are easier to validate and audit than other decision predictors.   \n",
       "4                                                              With little human intervention   \n",
       "5                                 They should use decision trees to predict numerical values.   \n",
       "6                As the model can predict numerical values and classify data into categories.   \n",
       "7                                                         Automatic speech recognition (ASR).   \n",
       "\n",
       "                                                                                      dis2  \\\n",
       "0                              To identify patterns and trends in massive volumes of data.   \n",
       "1       They use decision trees to identify patterns and trends in massive volumes of data   \n",
       "2                                               The lack of resources and a robust system.   \n",
       "3              Because decision trees can be more unstable than other decision predictors.   \n",
       "4                                                              With a small sample of data   \n",
       "5                         They should use decision trees to classify data into categories.   \n",
       "6  As the decision tree algorithms are easier to validate and audit than a neural network.   \n",
       "7                                                                Decision tree algorithms.   \n",
       "\n",
       "                                                                                dis3  \n",
       "0                            To use decision trees to classify data into categories.  \n",
       "1             They can assemble and refine their own algorithms with more data input  \n",
       "2                                              The lack of confidence in the output.  \n",
       "3              Because the model learns more with every experience with that person.  \n",
       "4                                                    With a robust and robust system  \n",
       "5        They should use decision trees to assemble and refine their own algorithms.  \n",
       "6  As the decision tree algorithms are more unstable than other decision predictors.  \n",
       "7                                                                    Decision trees.  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"New Version:\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "samples.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>dis1</th>\n",
       "      <th>dis2</th>\n",
       "      <th>dis3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do many mobile devices incorporate speech recognition into their systems?</td>\n",
       "      <td>To conduct voice search—e.g. Siri—or improve accessibility for texting.</td>\n",
       "      <td>To translate human speech into a written format.</td>\n",
       "      <td>To improve customer service across websites and social media platforms.</td>\n",
       "      <td>To identify patterns and trends in massive volumes of data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What method is used by many mobile devices to conduct voice search—e.g. Siri—or improve accessibility for texting</td>\n",
       "      <td>They incorporate speech recognition into their systems</td>\n",
       "      <td>They use speech recognition to translate human speech into a written format</td>\n",
       "      <td>They use decision trees to identify patterns and trends in massive volumes of data</td>\n",
       "      <td>They can be more stable than other decision predictors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can be the cause of error proneness of machine learning algorithms?</td>\n",
       "      <td>The low quality of input data.</td>\n",
       "      <td>The fact that they are not robust enough to run.</td>\n",
       "      <td>The fact that they are too small to be tested.</td>\n",
       "      <td>The fact that they are not able to predict numerical values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why does the analysis of patterns and trends require little human intervention?</td>\n",
       "      <td>Because users can just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.</td>\n",
       "      <td>Because decision trees are easier to validate and audit than a neural network.</td>\n",
       "      <td>Because decision trees use a branching sequence of linked decisions that may be represented with a tree diagram.</td>\n",
       "      <td>Because decision trees can be more unstable than other decision predictors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can machine learning algorithms improve?</td>\n",
       "      <td>With more input data over time</td>\n",
       "      <td>With a large training datasets</td>\n",
       "      <td>With a robust system to run it</td>\n",
       "      <td>With a large sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By what method can organizations avoid wasting budget or displeasing customers?</td>\n",
       "      <td>They should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>They should use decision trees to identify patterns and trends in massive volumes of data.</td>\n",
       "      <td>They should feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.</td>\n",
       "      <td>They should produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why can customers and users enjoy a more personalized experience?</td>\n",
       "      <td>As the model learns more with every experience with that person.</td>\n",
       "      <td>Because decision trees are easier to validate and audit than a neural network.</td>\n",
       "      <td>Because decision trees use a branching sequence of linked decisions.</td>\n",
       "      <td>Because they can be more unstable than other decision predictors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What method is used by speech recognition to translates human speech into a written format?</td>\n",
       "      <td>It uses natural language processing.</td>\n",
       "      <td>It uses speech-to-text to translate human speech into a written format.</td>\n",
       "      <td>It uses speech-to-text to translate human speech into a written format.</td>\n",
       "      <td>It uses speech-to-text to translate human speech into a written format.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            question  \\\n",
       "0                                      Why do many mobile devices incorporate speech recognition into their systems?   \n",
       "1  What method is used by many mobile devices to conduct voice search—e.g. Siri—or improve accessibility for texting   \n",
       "2                                           What can be the cause of error proneness of machine learning algorithms?   \n",
       "3                                    Why does the analysis of patterns and trends require little human intervention?   \n",
       "4                                                                       How can machine learning algorithms improve?   \n",
       "5                                    By what method can organizations avoid wasting budget or displeasing customers?   \n",
       "6                                                  Why can customers and users enjoy a more personalized experience?   \n",
       "7                        What method is used by speech recognition to translates human speech into a written format?   \n",
       "\n",
       "                                                                                                                               answer  \\\n",
       "0                                                             To conduct voice search—e.g. Siri—or improve accessibility for texting.   \n",
       "1                                                                              They incorporate speech recognition into their systems   \n",
       "2                                                                                                      The low quality of input data.   \n",
       "3  Because users can just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.   \n",
       "4                                                                                                      With more input data over time   \n",
       "5                                                    They should act on the answers only when there is high confidence in the output.   \n",
       "6                                                                    As the model learns more with every experience with that person.   \n",
       "7                                                                                                It uses natural language processing.   \n",
       "\n",
       "                                                                                         dis1  \\\n",
       "0                                            To translate human speech into a written format.   \n",
       "1                 They use speech recognition to translate human speech into a written format   \n",
       "2                                            The fact that they are not robust enough to run.   \n",
       "3              Because decision trees are easier to validate and audit than a neural network.   \n",
       "4                                                              With a large training datasets   \n",
       "5  They should use decision trees to identify patterns and trends in massive volumes of data.   \n",
       "6              Because decision trees are easier to validate and audit than a neural network.   \n",
       "7                     It uses speech-to-text to translate human speech into a written format.   \n",
       "\n",
       "                                                                                                                      dis2  \\\n",
       "0                                                  To improve customer service across websites and social media platforms.   \n",
       "1                                       They use decision trees to identify patterns and trends in massive volumes of data   \n",
       "2                                                                           The fact that they are too small to be tested.   \n",
       "3         Because decision trees use a branching sequence of linked decisions that may be represented with a tree diagram.   \n",
       "4                                                                                           With a robust system to run it   \n",
       "5  They should feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms.   \n",
       "6                                                     Because decision trees use a branching sequence of linked decisions.   \n",
       "7                                                  It uses speech-to-text to translate human speech into a written format.   \n",
       "\n",
       "                                                                                        dis3  \n",
       "0                                To identify patterns and trends in massive volumes of data.  \n",
       "1                                     They can be more stable than other decision predictors  \n",
       "2                               The fact that they are not able to predict numerical values.  \n",
       "3                Because decision trees can be more unstable than other decision predictors.  \n",
       "4                                                                        With a large sample  \n",
       "5  They should produce a perfectly logical algorithm that is completely wrong or misleading.  \n",
       "6                          Because they can be more unstable than other decision predictors.  \n",
       "7                    It uses speech-to-text to translate human speech into a written format.  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old version of model without custom loss\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "samples.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "output_path = './questions_machine_learning'\n",
    "sents = split_into_sentences(original_text) # text split into sentences\n",
    "paras = split_into_paras(raw_original_text, deli='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.DataFrame(columns=['nucleus', 'satellite', 'question', 'answer', 'distractor1', 'distractor2', 'distractor3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 68.94 examples/s]\n",
      "05/28/2024 18:30:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
      "05/28/2024 18:30:16 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.81 examples/s]\n",
      "05/28/2024 18:30:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. changing the way we think about customer engagement across websites and social media platforms.\n",
      "<pad> distractor 1: Online chatbots are replacing virtual agents along the customer journey., distractor 2: Online chatbots are replacing virtual agents along the customer journey., distractor 3: Online chatbots are replacing virtual agents along the customer journey.</s>\n",
      "<pad> distractor 1: Because they can answer frequently asked questions (FAQs) about topics such as shipping., distractor 2: Because they can provide personalized advice, cross-selling products or suggesting sizes for users., distractor 3: Because they can help customers with tasks usually done by virtual assistants and voice assistants.</s>\n"
     ]
    }
   ],
   "source": [
    "# for Cause relation\n",
    "rel = 'Cause'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_cause_question(nucleus_pair, satellite_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "\n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)\n",
    "\n",
    "        # second question (if first question has order mixed up)\n",
    "        ques, ans = generate_cause_question(satellite_pair, nucleus_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "    \n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "\n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"Distractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:20 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "05/28/2024 18:30:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
      "05/28/2024 18:30:20 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 67.84 examples/s]\n",
      "05/28/2024 18:30:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Decision trees are more difficult to validate and audit than neural networks, distractor 2: Decision trees are more stable than other decision predictors, distractor 3: Decision trees are used for both prediction and classification problems</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: To ensure that the output is accurate and unbiased, distractor 2: To ensure that the output is accurate and unbiased, distractor 3: To ensure that the output is accurate and unbiased</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.46 examples/s]\n",
      "05/28/2024 18:30:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "05/28/2024 18:30:26 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 67.61 examples/s]\n",
      "05/28/2024 18:30:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Decision trees are more difficult to validate and audit than neural networks, distractor 2: Decision trees are more stable than other decision predictors, distractor 3: Decision trees are used for both prediction and classification problems</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Because decision trees are easier to validate and audit than a neural network, distractor 2: Because decision trees can be more unstable than other decision predictors, distractor 3: Because decision trees identifying patterns and trends in massive volumes of data</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.16 examples/s]\n",
      "05/28/2024 18:30:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n",
      "05/28/2024 18:30:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  identifying requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time. identifying requires little human intervention:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.18 examples/s]\n",
      "05/28/2024 18:30:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Because decision trees are easier to validate and audit than a neural network., distractor 2: Because decision trees can be more unstable than other decision predictors., distractor 3: Because customers and users can enjoy a more personalized experience.</s>\n",
      "<pad> distractor 1: Gather sufficient data and having a system robust enough to run it, distractor 2: Let the machine learning system assemble and refine its own algorithms, distractor 3: Enjoy a more personalized experience as the model learns more with every experience with that person</s>\n"
     ]
    }
   ],
   "source": [
    "# for Explanation relation\n",
    "rel = 'Explanation'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_cause_question(nucleus_pair, satellite_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "        \n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)\n",
    "\n",
    "        # second question\n",
    "        ques, ans = generate_cause_question(satellite_pair, nucleus_pair) # WORKING: order of cause and serveral other relations are not consistant, fix dataset\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "\n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"Distractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:35 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.93 examples/s]\n",
      "05/28/2024 18:30:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
      "05/28/2024 18:30:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.70 examples/s]\n",
      "05/28/2024 18:30:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
      "05/28/2024 18:30:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.99 examples/s]\n",
      "05/28/2024 18:30:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
      "05/28/2024 18:30:37 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 55.76 examples/s]\n",
      "05/28/2024 18:30:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "05/28/2024 18:30:38 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 102.12 examples/s]\n",
      "05/28/2024 18:30:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
      "05/28/2024 18:30:38 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 131.12 examples/s]\n",
      "05/28/2024 18:30:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# for Contrast relation\n",
    "rel = 'Contrast'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus'].strip()\n",
    "        satellite = trip[1]['satellite'].strip()\n",
    "        \n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, retain_dm=True, add_subject_to_rel_clause=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite, retain_dm=True, retain_adv=True, retain_conj=True, add_subject_to_rel_clause=True)\n",
    "        \n",
    "        if nucleus_pair[1] is None or nucleus_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_contrast_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            continue\n",
    "        \n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        \n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "        \n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:38 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.82 examples/s]\n",
      "05/28/2024 18:30:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s]\n",
      "05/28/2024 18:30:39 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.15 examples/s]\n",
      "05/28/2024 18:30:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Organizations should use a large training datasets., distractor 2: Organizations should gather sufficient data and have a system robust enough to run it., distractor 3: Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: When there is a large training dataset., distractor 2: When there is a strong enough system to run it., distractor 3: When there is a high probability of error.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 123.11 examples/s]\n",
      "05/28/2024 18:30:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]\n",
      "05/28/2024 18:30:44 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.00 examples/s]\n",
      "05/28/2024 18:30:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text here:  Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. depending on the input.\n",
      "<pad> distractor 1: The system should be robust enough to run it., distractor 2: The output of machine learning is not accurate., distractor 3: The output of machine learning is not reliable.</s>\n",
      "<pad> distractor 1: With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading., distractor 2: With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading., distractor 3: With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</s>\n"
     ]
    }
   ],
   "source": [
    "# for Condition relation\n",
    "\n",
    "rel = 'Condition'\n",
    "for trip in df[df['new_relation'] == rel].iterrows():\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"Original nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "        \n",
    "        if nucleus[1] is None or satellite[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "        \n",
    "        ques, ans = generate_condition_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "\n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)\n",
    "        \n",
    "        ques, ans = generate_condition_question(satellite_pair, nucleus_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "\n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        # generate distractors\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:48 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.62 examples/s]\n",
      "05/28/2024 18:30:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "05/28/2024 18:30:48 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 89.67 examples/s]\n",
      "05/28/2024 18:30:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: To translate human speech into a written format., distractor 2: To conduct voice search-e.g. Siri-or improve accessibility for texting., distractor 3: To conduct voice search-e.g. Siri-or improve accessibility for texting.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/28/2024 18:30:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Online chatbots are replacing human agents along the customer journey., distractor 2: Organizations should act only when there is high confidence in the output., distractor 3: Many organizations should act on the answers only when there is high confidence in the output.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.47 examples/s]\n",
      "05/28/2024 18:30:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
      "05/28/2024 18:30:53 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 106.87 examples/s]\n",
      "05/28/2024 18:30:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: To produce a perfectly logical algorithm that is completely wrong or misleading., distractor 2: To assemble and refine the machine learning system., distractor 3: To identify patterns and trends in massive volumes of data.</s>\n",
      "<pad> distractor 1: Organizations should use a large training datasets that are accurate and unbiased., distractor 2: Organizations should gather sufficient data and have a system robust enough to run it., distractor 3: Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.</s>\n"
     ]
    }
   ],
   "source": [
    "# for Enablement relation\n",
    "rel = 'Enablement'\n",
    "\n",
    "with open(output_path, 'a') as f:\n",
    "    for trip in df[df['new_relation'] == rel].iterrows():\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, retain_dm=True, retain_conj=True, retain_adv=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "       \n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_enablement_question(nucleus_pair, satellite_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        \n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)\n",
    "\n",
    "        ques, ans = generate_enablement_question(satellite_pair, nucleus_pair)\n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "            \n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "\n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "        \n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Manner-Means relation\n",
    "rel = 'Manner-Means'\n",
    "with open(output_path, 'a') as f:\n",
    "    for trip in df[df['new_relation'] == rel].iterrows():\n",
    "        nucleus = trip[1]['nucleus']\n",
    "        satellite = trip[1]['satellite']\n",
    "\n",
    "        f.write(\"\\nRELATION: \" + rel + '\\n')\n",
    "        f.write(\"\\nOriginal nucleus: \" + nucleus + '\\n')\n",
    "        f.write(\"Original satellite: \" + satellite + '\\n')\n",
    "\n",
    "        nucleus_pair = preprocessing_pipeline(original_text, nucleus, add_subject_to_rel_clause=True)\n",
    "        satellite_pair = preprocessing_pipeline(original_text, satellite)\n",
    "\n",
    "        if nucleus_pair[1] is None or satellite_pair[1] is None:\n",
    "            f.write(\"Can't process nucleus and satellite!\\n\")\n",
    "            continue\n",
    "\n",
    "        ques, ans = generate_means_question(nucleus_pair, satellite_pair) \n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        \n",
    "        f.write(\"\\nOriginal Question: \" + ques + '\\n')\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "        f.write(\"\\nNew Question: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        # generate distractors\n",
    "        para_id = get_para_id(paras, nucleus)\n",
    "        para = paras[para_id]\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)\n",
    "\n",
    "        ques, ans = generate_means_question(satellite_pair, nucleus_pair) \n",
    "        if not ques.strip() or not ans.strip():\n",
    "            f.write(\"Can't generate questions!\\n\")\n",
    "\n",
    "        ques = postprocess_question(ques)\n",
    "        ans = postprocess_answer(ans)\n",
    "        ques = complete_question(original_text, ques, ans)\n",
    "      \n",
    "        f.write(\"\\nQuestion: \" + ques + '\\n')\n",
    "        f.write(\"Answer: \" + ans + '\\n')\n",
    "\n",
    "        dis1, dis2, dis3 = generate_3_distractors(original_text, ques, ans)\n",
    "        f.write(\"\\nDistractor 1: \" + dis1 + '\\n')\n",
    "        f.write(\"Distractor 2: \" + dis2 + '\\n')\n",
    "        f.write(\"Distractor 3: \" + dis3 + '\\n')\n",
    "\n",
    "        f.write(\"\\nContext: \" + para + '\\n')\n",
    "    \n",
    "        datapoint = {'nucleus': [nucleus], 'satellite': [satellite], 'question': [ques], 'answer': [ans], 'distractor1': [dis1], 'distractor2': [dis2], 'distractor3': [dis3]}\n",
    "        questions = pd.concat([questions, pd.DataFrame(datapoint)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- For Why questions, answer needs to contain \"Because\" for distractors to run well.\\nThis runs well:\\n    ques = \"Why does machine learning require little human intervention?\"\\n    ans = \"Because users just need to feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.\"\\n\\nBut this doesn\\'t:\\n    ques = \"Why does machine learning require little human intervention?\"\\n    ans = \"Users just need to feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.\"\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- For Why questions, answer needs to contain \"Because\" for distractors to run well.\n",
    "This runs well:\n",
    "    ques = \"Why does machine learning require little human intervention?\"\n",
    "    ans = \"Because users just need to feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.\"\n",
    "\n",
    "But this doesn't:\n",
    "    ques = \"Why does machine learning require little human intervention?\"\n",
    "    ans = \"Users just need to feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> distractor 1: Organizations should use a large training datasets that are accurate and unbiased., distractor 2: Organizations should gather sufficient data and have a system robust enough to run it., distractor 3: Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Organizations should use a large training datasets that are accurate and unbiased.',\n",
       " 'Organizations should gather sufficient data and have a system robust enough to run it.',\n",
       " 'Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper\n",
    "ques = \"What can be done to avoid wasting budget or displeasing customers with machine learning?\"\n",
    "ans = \"Organizations should act on the answers only when there is high confidence in the output.\"\n",
    "\n",
    "generate_3_distractors(raw_original_text, ques, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with empty cells\n",
    "\n",
    "r_inds = list(np.arange(questions.shape[0]))\n",
    "for row in questions.iterrows():\n",
    "    for col in questions.columns:\n",
    "        if len(row[1][col].strip()) == 0:\n",
    "           r_inds.remove(row[0])\n",
    "final_questions = questions.iloc[r_inds, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleus</th>\n",
       "      <th>satellite</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>distractor1</th>\n",
       "      <th>distractor2</th>\n",
       "      <th>distractor3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey,</td>\n",
       "      <td>changing the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>What changes the way we think about customer engagement across websites and social media platforms according to the text?</td>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey.</td>\n",
       "      <td>Online chatbots are replacing virtual agents along the customer journey.</td>\n",
       "      <td>Online chatbots are replacing virtual agents along the customer journey.</td>\n",
       "      <td>Online chatbots are replacing virtual agents along the customer journey.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey,</td>\n",
       "      <td>changing the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>Why are online chatbots replacing human agents along the customer journey in Customer service?</td>\n",
       "      <td>Which changes the way we think about customer engagement across websites and social media platforms.</td>\n",
       "      <td>Because they can answer frequently asked questions (FAQs) about topics such as shipping.</td>\n",
       "      <td>Because they can provide personalized advice, cross-selling products or suggesting sizes for users.</td>\n",
       "      <td>Because they can help customers with tasks usually done by virtual assistants and voice assistants.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>, which of the following is the best title?</td>\n",
       "      <td></td>\n",
       "      <td>Decision trees are more difficult to validate and audit than neural networks</td>\n",
       "      <td>Decision trees are more stable than other decision predictors</td>\n",
       "      <td>Decision trees are used for both prediction and classification problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Why could with too small a sample, the machine learning system produce a perfectly logical algorithm that is completely wrong or misleading according to the text?</td>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: Speech recognition is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and Speech recognition is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into Many mobile devices systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>To ensure that the output is accurate and unbiased</td>\n",
       "      <td>To ensure that the output is accurate and unbiased</td>\n",
       "      <td>To ensure that the output is accurate and unbiased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>, which of the following is the best title?</td>\n",
       "      <td></td>\n",
       "      <td>Decision trees are more difficult to validate and audit than neural networks</td>\n",
       "      <td>Decision trees are more stable than other decision predictors</td>\n",
       "      <td>Decision trees are used for both prediction and classification problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Why should to avoid wasting budget or displeasing customers, organizations act on the answers only when there is high confidence in the output of machine learning?</td>\n",
       "      <td>Are just a few examples of machine learning you might encounter every day: Speech recognition: Speech recognition is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and Speech recognition is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into Many mobile devices systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.</td>\n",
       "      <td>Because decision trees are easier to validate and audit than a neural network</td>\n",
       "      <td>Because decision trees can be more unstable than other decision predictors</td>\n",
       "      <td>Because decision trees identifying patterns and trends in massive volumes of data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>And this analysis requires little human intervention:</td>\n",
       "      <td>just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>Why will machine learning feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which continually improve with more data input over time?</td>\n",
       "      <td>Which identifies requires little human intervention:.</td>\n",
       "      <td>Because decision trees are easier to validate and audit than a neural network.</td>\n",
       "      <td>Because decision trees can be more unstable than other decision predictors.</td>\n",
       "      <td>Because customers and users can enjoy a more personalized experience.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>And this analysis requires little human intervention:</td>\n",
       "      <td>just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>What identifies patterns and trends in massive volumes of data that machine learning identifies requires little human intervention:?</td>\n",
       "      <td>Feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.</td>\n",
       "      <td>Gather sufficient data and having a system robust enough to run it</td>\n",
       "      <td>Let the machine learning system assemble and refine its own algorithms</td>\n",
       "      <td>Enjoy a more personalized experience as the model learns more with every experience with that person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organizations should act on the answers</td>\n",
       "      <td>only when there is high confidence in the output.</td>\n",
       "      <td>In what condition should organizations do machine learning when there be high confidence in the output of machine learning?</td>\n",
       "      <td>Organizations should act on the answers.</td>\n",
       "      <td>Organizations should use a large training datasets.</td>\n",
       "      <td>Organizations should gather sufficient data and have a system robust enough to run it.</td>\n",
       "      <td>Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>organizations should act on the answers</td>\n",
       "      <td>only when there is high confidence in the output.</td>\n",
       "      <td>In what condition should organizations act on the answers to machine learning questions?</td>\n",
       "      <td>When there is high confidence in the output.</td>\n",
       "      <td>When there is a large training dataset.</td>\n",
       "      <td>When there is a strong enough system to run it.</td>\n",
       "      <td>When there is a high probability of error.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine learning can also be prone to error,</td>\n",
       "      <td>depending on the input.</td>\n",
       "      <td>What condition depends on the input of machine learning?</td>\n",
       "      <td>Machine learning can also be prone to error.</td>\n",
       "      <td>The system should be robust enough to run it.</td>\n",
       "      <td>The output of machine learning is not accurate.</td>\n",
       "      <td>The output of machine learning is not reliable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Machine learning can also be prone to error,</td>\n",
       "      <td>depending on the input.</td>\n",
       "      <td>In what condition can machine learning also be prone to error in machine learning?</td>\n",
       "      <td>Which depends on the input.</td>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Many mobile devices incorporate speech recognition into their systems</td>\n",
       "      <td>to conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "      <td>How do Many mobile devices incorporate speech recognition into their systems to conduct voice search?</td>\n",
       "      <td>To conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "      <td>To translate human speech into a written format.</td>\n",
       "      <td>To conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "      <td>To conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Many mobile devices incorporate speech recognition into their systems</td>\n",
       "      <td>to conduct voice search-e.g. Siri-or improve accessibility for texting.</td>\n",
       "      <td>What can be done to conduct voice search-e.g. Siri-or improve accessibility for texting according to the text?</td>\n",
       "      <td>Many mobile devices incorporate speech recognition into Many mobile devices systems.</td>\n",
       "      <td>Online chatbots are replacing human agents along the customer journey.</td>\n",
       "      <td>Organizations should act only when there is high confidence in the output.</td>\n",
       "      <td>Many organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>To avoid wasting budget or displeasing customers,</td>\n",
       "      <td>How should organizations act on the answers only when there is high confidence in the output of machine learning?</td>\n",
       "      <td>To avoid wasting budget or displeasing customers.</td>\n",
       "      <td>To produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "      <td>To assemble and refine the machine learning system.</td>\n",
       "      <td>To identify patterns and trends in massive volumes of data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>To avoid wasting budget or displeasing customers,</td>\n",
       "      <td>What can be done To avoid wasting budget or displeasing customers with machine learning?</td>\n",
       "      <td>Organizations should act on the answers only when there is high confidence in the output.</td>\n",
       "      <td>Organizations should use a large training datasets that are accurate and unbiased.</td>\n",
       "      <td>Organizations should gather sufficient data and have a system robust enough to run it.</td>\n",
       "      <td>Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        nucleus  \\\n",
       "0                                                                        Online chatbots are replacing human agents along the customer journey,   \n",
       "1                                                                        Online chatbots are replacing human agents along the customer journey,   \n",
       "2                       With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.   \n",
       "3                       With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.   \n",
       "4   To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.   \n",
       "5   To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.   \n",
       "6                                                                                         And this analysis requires little human intervention:   \n",
       "7                                                                                         And this analysis requires little human intervention:   \n",
       "8                                                                                                      organizations should act on the answers    \n",
       "9                                                                                                      organizations should act on the answers    \n",
       "10                                                                                                Machine learning can also be prone to error,    \n",
       "11                                                                                                Machine learning can also be prone to error,    \n",
       "12                                                                       Many mobile devices incorporate speech recognition into their systems    \n",
       "13                                                                       Many mobile devices incorporate speech recognition into their systems    \n",
       "14                                                   organizations should act on the answers only when there is high confidence in the output.    \n",
       "15                                                   organizations should act on the answers only when there is high confidence in the output.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   satellite  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            changing the way we think about customer engagement across websites and social media platforms.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            changing the way we think about customer engagement across websites and social media platforms.   \n",
       "2   To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "3   To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "4                                                                                                                                               Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "5                                                                                                                                               Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms -which will continually improve with more data input over time.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         only when there is high confidence in the output.    \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         only when there is high confidence in the output.    \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  depending on the input.    \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  depending on the input.    \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  to conduct voice search-e.g. Siri-or improve accessibility for texting.    \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  to conduct voice search-e.g. Siri-or improve accessibility for texting.    \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        To avoid wasting budget or displeasing customers,    \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        To avoid wasting budget or displeasing customers,    \n",
       "\n",
       "                                                                                                                                                                                                                   question  \\\n",
       "0                                                                                                 What changes the way we think about customer engagement across websites and social media platforms according to the text?   \n",
       "1                                                                                                                            Why are online chatbots replacing human agents along the customer journey in Customer service?   \n",
       "2                                                                                                                                                                               , which of the following is the best title?   \n",
       "3                                                        Why could with too small a sample, the machine learning system produce a perfectly logical algorithm that is completely wrong or misleading according to the text?   \n",
       "4                                                                                                                                                                               , which of the following is the best title?   \n",
       "5                                                       Why should to avoid wasting budget or displeasing customers, organizations act on the answers only when there is high confidence in the output of machine learning?   \n",
       "6   Why will machine learning feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which continually improve with more data input over time?   \n",
       "7                                                                                      What identifies patterns and trends in massive volumes of data that machine learning identifies requires little human intervention:?   \n",
       "8                                                                                               In what condition should organizations do machine learning when there be high confidence in the output of machine learning?   \n",
       "9                                                                                                                                  In what condition should organizations act on the answers to machine learning questions?   \n",
       "10                                                                                                                                                                 What condition depends on the input of machine learning?   \n",
       "11                                                                                                                                       In what condition can machine learning also be prone to error in machine learning?   \n",
       "12                                                                                                                    How do Many mobile devices incorporate speech recognition into their systems to conduct voice search?   \n",
       "13                                                                                                           What can be done to conduct voice search-e.g. Siri-or improve accessibility for texting according to the text?   \n",
       "14                                                                                                        How should organizations act on the answers only when there is high confidence in the output of machine learning?   \n",
       "15                                                                                                                                 What can be done To avoid wasting budget or displeasing customers with machine learning?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    answer  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Online chatbots are replacing human agents along the customer journey.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Which changes the way we think about customer engagement across websites and social media platforms.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "3   To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: Speech recognition is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and Speech recognition is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into Many mobile devices systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "5                                                                                                                                                    Are just a few examples of machine learning you might encounter every day: Speech recognition: Speech recognition is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and Speech recognition is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into Many mobile devices systems to conduct voice search-e.g. Siri-or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites ; messaging bots, using Slack and Facebook Messenger ; and tasks usually done by virtual assistants and voice assistants.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Which identifies requires little human intervention:.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Feed in the dataset of interest and let the machine learning system assemble and refine the machine learning system own algorithms -which will continually improve with more data input over time.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Organizations should act on the answers.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             When there is high confidence in the output.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Machine learning can also be prone to error.   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Which depends on the input.   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 To conduct voice search-e.g. Siri-or improve accessibility for texting.   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Many mobile devices incorporate speech recognition into Many mobile devices systems.   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       To avoid wasting budget or displeasing customers.   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Organizations should act on the answers only when there is high confidence in the output.   \n",
       "\n",
       "                                                                                                                distractor1  \\\n",
       "0                                                  Online chatbots are replacing virtual agents along the customer journey.   \n",
       "1                                  Because they can answer frequently asked questions (FAQs) about topics such as shipping.   \n",
       "2                                              Decision trees are more difficult to validate and audit than neural networks   \n",
       "3                                                                        To ensure that the output is accurate and unbiased   \n",
       "4                                              Decision trees are more difficult to validate and audit than neural networks   \n",
       "5                                             Because decision trees are easier to validate and audit than a neural network   \n",
       "6                                            Because decision trees are easier to validate and audit than a neural network.   \n",
       "7                                                        Gather sufficient data and having a system robust enough to run it   \n",
       "8                                                                       Organizations should use a large training datasets.   \n",
       "9                                                                                   When there is a large training dataset.   \n",
       "10                                                                            The system should be robust enough to run it.   \n",
       "11  With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.   \n",
       "12                                                                         To translate human speech into a written format.   \n",
       "13                                                   Online chatbots are replacing human agents along the customer journey.   \n",
       "14                                         To produce a perfectly logical algorithm that is completely wrong or misleading.   \n",
       "15                                       Organizations should use a large training datasets that are accurate and unbiased.   \n",
       "\n",
       "                                                                                                                distractor2  \\\n",
       "0                                                  Online chatbots are replacing virtual agents along the customer journey.   \n",
       "1                       Because they can provide personalized advice, cross-selling products or suggesting sizes for users.   \n",
       "2                                                             Decision trees are more stable than other decision predictors   \n",
       "3                                                                        To ensure that the output is accurate and unbiased   \n",
       "4                                                             Decision trees are more stable than other decision predictors   \n",
       "5                                                Because decision trees can be more unstable than other decision predictors   \n",
       "6                                               Because decision trees can be more unstable than other decision predictors.   \n",
       "7                                                    Let the machine learning system assemble and refine its own algorithms   \n",
       "8                                    Organizations should gather sufficient data and have a system robust enough to run it.   \n",
       "9                                                                           When there is a strong enough system to run it.   \n",
       "10                                                                          The output of machine learning is not accurate.   \n",
       "11  With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.   \n",
       "12                                                  To conduct voice search-e.g. Siri-or improve accessibility for texting.   \n",
       "13                                               Organizations should act only when there is high confidence in the output.   \n",
       "14                                                                      To assemble and refine the machine learning system.   \n",
       "15                                   Organizations should gather sufficient data and have a system robust enough to run it.   \n",
       "\n",
       "                                                                                                                distractor3  \n",
       "0                                                  Online chatbots are replacing virtual agents along the customer journey.  \n",
       "1                       Because they can help customers with tasks usually done by virtual assistants and voice assistants.  \n",
       "2                                                   Decision trees are used for both prediction and classification problems  \n",
       "3                                                                        To ensure that the output is accurate and unbiased  \n",
       "4                                                   Decision trees are used for both prediction and classification problems  \n",
       "5                                         Because decision trees identifying patterns and trends in massive volumes of data  \n",
       "6                                                     Because customers and users can enjoy a more personalized experience.  \n",
       "7                      Enjoy a more personalized experience as the model learns more with every experience with that person  \n",
       "8                        Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.  \n",
       "9                                                                                When there is a high probability of error.  \n",
       "10                                                                          The output of machine learning is not reliable.  \n",
       "11  With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading.  \n",
       "12                                                  To conduct voice search-e.g. Siri-or improve accessibility for texting.  \n",
       "13                           Many organizations should act on the answers only when there is high confidence in the output.  \n",
       "14                                                              To identify patterns and trends in massive volumes of data.  \n",
       "15                       Organizations should produce a perfectly logical algorithm that is completely wrong or misleading.  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
